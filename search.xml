<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Code Review方案]]></title>
    <url>%2Fposts%2F4f7bd265%2F</url>
    <content type="text"><![CDATA[概要Code Review是软件工程中重要的一环，特别是在大公司规范的流程中。大家也逐渐意识到Code Review的重要性以及它带来的好处，本文跟大家讨论一下Code Review的实践方案。作用Code Review的好处有很多，巴拉巴拉可以说一堆，但总的来说有以下几点：找bug提高代码质量相互学习实践方案Code Review并没有一个标准应该怎么去做，每个公司甚至每个团队可能都有自己的做法，下面我讲3种暂时看到的做用 gerrit之前用过一下，觉得比较麻烦，主要是流程上体验不好，commit 之后要CR通过才能真正的提交到 gitlab，如果进度比较赶或者多人协作，别人需要用到你的代码，这就会带来时间上的拖延Commit + Issue + Label1）添加Project Label：Review Done；2）设置做Code Review的默认分支Default branch，在Project Setting里面修改；3）通知团队，新任务，使用Issue登记内容，代码Commit时，填写“#Num”关联Issue；4）做完Code Review后，在Issue打上标签Review Done，并close issue，完成整个任务的流程；Merge Request + Label在mr里面，reivew完代码直接打上标签；总结我个人推荐方案2我觉得主要区别在CR的时间点上，gerrit 在每一次的提交，这个比较强制了，不够灵活；方案3要在合并到别的分支时；方案2则比较灵活。具体更详细的实践可以参考基于 GitLab 的简单项目管理与协作流程]]></content>
      <categories>
        <category>routine</category>
      </categories>
      <tags>
        <tag>code review</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ReentrantReadWriteLock]]></title>
    <url>%2Fposts%2Ff8dba914%2F</url>
    <content type="text"><![CDATA[概要应用场景使用实现原理总结参考资料]]></content>
      <categories>
        <category>java</category>
        <category>juc</category>
      </categories>
      <tags>
        <tag>juc</tag>
        <tag>reentrantreadwritelock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ReentrantLock]]></title>
    <url>%2Fposts%2F6e505175%2F</url>
    <content type="text"><![CDATA[概要ReentrantLock顾名思义是可重入锁，提供了公平性的机制，内部基于AbstractQueuedSynchronizer来实现。所以ReentrantLock只是AbstractQueuedSynchronizer的一个使用场景的实现。使用ReentrantLock的使用相信大家都很熟悉，主要是以下几个方法123456789101112//阻塞程序，直到成功的获取锁public void lock();//与lock()不同的地方是，它可以响应程序中断，如果被其他程序中断了，则抛出InterruptedException。public void lockInterruptibly() throws InterruptedException;//尝试获取锁，该方法会立即返回，并不会阻塞程序。如果获取锁成功则返回true，反之则返回false。public boolean tryLock();//尝试获取锁，如果能获取锁则直接返回true；否则阻塞等待，阻塞时长由传入的参数来决定，在等待的同时响应程序中断，如果发生了中断则抛出InterruptedException；如果在等待的时间中获取了锁则返回true，反之返回false。public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException;//释放锁public void unlock();//新建一个条件，一个Lock可以关联多个条件。public Condition newCondition();实现原理ReentrantLock的实现是基于AbstractQueuedSynchronizer的，如果不清楚可以看AQS的实现。如果你已经大概了解AQS的实现，那么了解ReentrantLock的实现对于你来说就会显得非常简单了。ReentrantLock持有一个内部类对象Sync的实例，上面的lock()、unlock()等方法都是调用到sync的方法的12345678910111213141516171819202122private final Sync sync;public void lock() &#123; sync.lock();&#125;public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1);&#125;public boolean tryLock() &#123; return sync.nonfairTryAcquire(1);&#125;public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout));&#125;public void unlock() &#123; sync.release(1);&#125;Sync的实现所以我们重点看看Sync的实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849//很重要的一点，继承了AbstractQueuedSynchronizerabstract static class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = -5179523762034025860L; //lock方法由NonfairSync和FairSync实现 abstract void lock(); //这里实现了一个不公平的的TryAcquire，放在Sync这个类的原因是，无论公平锁还是非公平锁，都会用到这个方法 final boolean nonfairTryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); //获取aqs的state状态，用来标记锁是否被获取了 int c = getState(); //等于0说明没有线程占用锁，然后通过cas尝试竞争一下锁，其实就是调用aqs的compareAndSetState方法，把state设置为1，如果成功，则标记当前线程获得锁 if (c == 0) &#123; if (compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; //如果state != 0，还有一种情况就是当前线程自己之前已经获得锁了，这次是再次进来临界区，所以要看看exclusiveOwnerThread是不是等于自己，如果是则state++。所以如果是重入锁的情况，会出现 state &gt; 1。 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; //否则就是获得锁失败 return false; &#125; //释放锁，因为释放锁的操作都是一样，所以放在Sync统一处理 protected final boolean tryRelease(int releases) &#123; //state -- int c = getState() - releases; //防止释放锁的线程不是获得锁的线程 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; //如果state == 0，如果锁被释放掉了。如果 state != 0，说明锁在被重入的情况 if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free; &#125;&#125;公平/非公平锁的实现ReentrantLock是提供锁的公平机制的，锁是否公平定义如下公平锁：新线程进来临界区争夺资源，如果之前有线程在排队，那么它必须紧接着排在队列后面不公平锁：新线程可以跟已经在排队的线程一起竞争，如果失败也是乖乖排队ReentrantLock在Sync的基础上实现了非公平的NonfairSync和公平的FairSync看看ReentrantLock的初始化123456789//默认使用非公平锁public ReentrantLock() &#123; sync = new NonfairSync();&#125;//通过带参数的构造函数决定使用公平锁还是非公平锁public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125;NonfairSync1234567891011121314151617static final class NonfairSync extends Sync &#123; private static final long serialVersionUID = 7316153563782823691L; //先去直接cas一下获得锁，碰一下运气，失败则调用nonfairTryAcquire方法，虽然失败了，但有可能是重入的情况，如果都不是，则乖乖排队把 final void lock() &#123; if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); else //aqs的acquire方法，里面会调用下面的tryAcquire方法，熟悉aqs大概知道，如果tryAcquire返回true则获得锁成功，如果失败则进入CLH队列排队去。 acquire(1); &#125; //aqs内部会调用这个方法 protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125;&#125;FairSync12345678910111213141516171819202122232425262728293031static final class FairSync extends Sync &#123; private static final long serialVersionUID = -3000897897090466540L; //直接调用aqs的acquire //可以跟上面的NonfairSync的lock方法对比一下有啥不同 final void lock() &#123; acquire(1); &#125; //aqs内部会调用这个方法 protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; //hasQueuedPredecessors是aqs自带的方法，表示看看AQS的队列有没有节点在排队，用来快速判断是否有别的线程在排队 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; //重入处理，跟上面的一样 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false; &#125;&#125;对比其实可以看出公平锁和非公平锁的差别在于，非公平锁在尝试获得锁的第一时间去尝试获得锁，这时如果锁没被占有，那么它将会跟排队的第一节节点进行竞争。非公平锁：效率和性能比较高，适于用有TPS要求的场景，但是会出现“饥饿”问题，即在排队的线程等了很久都没有获得锁公平锁：保证FIFO，不会出现“饥饿”问题ReentrantLock默认是非公平锁。重入的实现这个已经在上面已经提到过了12345678//重入处理else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); return true;&#125;在获得锁的同时会记录锁的持有者exclusiveOwnerThread，持有者再次获得锁时则可以不用竞争排队，无条件获得锁，不过锁的状态state会+1，用来记录重入的次数，因为在unlock()方法会把state减一，完全释放锁时state == 0。与synchronized区别ReentrantLock的功能与synchronized类似，经常拿来比较相同点互斥、阻塞型的即只有一个线程获得锁，其他线程必须在阻塞等待可重入性同一个线程可以再次获得锁，无需等待不同点相比来说，ReentrantLock显得更加“高级”一点。synchronized是Java的关键字，由JVM实现其功能，在字节码插入monitorenter指令和monitorexit指令。ReentrantLock则直接由Java代码实现。synchronized更加底层。持有的对象监视器不同ReentrantLock可中断ReentrantLock提供公平机制ReentrantLock可以绑定多个条件，即Condition对象，提供更加丰富的多线程并发骚操作。JDK1.6之后synchronize在语义上很清晰，进行很多优化，有适应自旋，锁消除，锁粗化，轻量级锁，偏向锁等等，在性能上并不比Lock差。综上，在性能差别不大的情况，根据自己的需求来选择，如果对锁的要求简单的话，可以直接用synchronized，如果复杂同步操作，则选择ReentrantLock。总结本文介绍基于AbstractQueuedSynchronizer的ReentrantLock的实现，通过源码可以看出重入性和公平性的实现，并对比了与synchronized的区别，阅读本文后希望大家对ReentrantLock的使用更加了然于心。]]></content>
      <categories>
        <category>java</category>
        <category>juc</category>
      </categories>
      <tags>
        <tag>juc</tag>
        <tag>reentrantlock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AQS]]></title>
    <url>%2Fposts%2Fdfdb52be%2F</url>
    <content type="text"><![CDATA[概要AQS即AbstractQueuedSynchronizer，作为Java的JUC（java.util.concurrent）包的核心基础类，为其他并发容器、工具类提供了底层的实现基础。本文讲述AQS的实现原理，以及如何使用AQS。AQS的实现源码基于JDK1.8没接触过的AQS的同学可能有点懵，不知道这是个什么东西。我们看看官方文档的描述Provides a framework for implementing blocking locks and related synchronizers (semaphores, events, etc) that rely on first-in-first-out (FIFO) wait queues. This class is designed to be a useful basis for most kinds of synchronizers that rely on a single atomic {@code int} value to represent state. Subclasses must define the protected methods that change this state, and which define what that state means in terms of this object being acquired or released. Given these, the other methods in this class carry out all queuing and blocking mechanics. Subclasses can maintain other state fields, but only the atomically updated {@code int} value manipulated using methods {@link #getState}, {@link#setState} and {@link #compareAndSetState} is tracked with respect to synchronization.AbstractQueuedSynchronizer其实是一个抽象模板类，它底层主要是用了一个FIFO队列和一个int的状态，并提供了一系列方法给子类去获取锁和释放锁，来处理阻塞情况。这样说还是有点抽象，举个例ReentrantLock的lock()和unlock()方法最终还是用到AQS的获取锁和释放锁，如果还是不明白的话，把ReentrantLock的实现一起来看，就会清晰很多。结构先看看AQS整体的结构会对它的实现有很大帮助官方描述Wait queue node class.The wait queue is a variant of a “CLH” (Craig, Landin, andHagersten) lock queue. CLH locks are normally used forspinlocks. We instead use them for blocking synchronizers, butuse the same basic tactic of holding some of the controlinformation about a thread in the predecessor of its node. A”status” field in each node keeps track of whether a threadshould block. A node is signalled when its predecessorreleases. Each node of the queue otherwise serves as aspecific-notification-style monitor holding a single waitingthread. The status field does NOT control whether threads aregranted locks etc though. A thread may try to acquire if it isfirst in the queue. But being first does not guarantee success;it only gives the right to contend. So the currently releasedcontender thread may need to rewait.To enqueue into a CLH lock, you atomically splice it in as newtail. To dequeue, you just set the head field.+——+ prev +—–+ +—–+head | | &lt;—- | | &lt;—- | | tail+——+ +—–+ +—–+Insertion into a CLH queue requires only a single atomicoperation on “tail”, so there is a simple atomic point ofdemarcation from unqueued to queued. Similarly, dequeuinginvolves only updating the “head”. However, it takes a bitmore work for nodes to determine who their successors are,in part to deal with possible cancellation due to timeoutsand interrupts.大概可以看出一个FIFO队列，也叫CLH队列，从尾部加入新的节点，head节点是获取到资源，正在运行或运行完成的节点或初始化的dummy节点，head后面的节点是正在排队、被阻塞的节点。Node每一个节点是一个Node类型对象Node的属性1234567891011121314151617181920212223242526272829//标记这个Node是共享模式static final Node SHARED = new Node();//标记这个Node是独占模式static final Node EXCLUSIVE = null;//Node的状态一共有4个//如果超时了（用的是带有时间限制的方法），或线程中断了，就会变成取消状态static final int CANCELLED = 1;//如果当前释放了同步状态或者被取消，则需要唤醒后续节点static final int SIGNAL = -1;//节点在等待队列中，节点线程等待在Condition上，当其他线程对Condition调用了signal()后，该节点将会从等待队列中转移到同步队列中，加入到同步状态的获取中static final int CONDITION = -2;//如果节点是共享模式，释放时为了继续唤醒后面的节点，需设置为此状态static final int PROPAGATE = -3;//Node的状态volatile int waitStatus;//前驱节点volatile Node prev;//后驱节点volatile Node next;//当前线程volatile Thread thread;//等待队列中的后续节点。如果当前节点是共享的，那么字段将是一个 SHARED 常量，也就是说节点类型（独占和共享）和等待队列中的后续节点共用同一个字段Node nextWaiter;共享/独占模式从Node的属性知道AQS分为exclusive独占模式和shared共享模式。所谓独占就是只能有一个线程进入到资源的临界区，其他线程需要排队等待；共享即允许多个线程进入临界区。最典型的就是读写锁ReentrantReadWriteLock，写操作是独占的，会block其他线程的读或写，而读操作与读操作则是不会block的。AQS对exclusive和shared模式分别有对应的方法12345678910111213//独占模式public final void acquire(int arg)public final void acquireInterruptibly(int arg)public final boolean tryAcquireNanos(int arg, long nanosTimeout)public final boolean release(int arg)//共享模式public final void acquireShared(int arg)public final void acquireSharedInterruptibly(int arg)public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout)public final boolean releaseShared(int arg)从命名看出，如果带上Shared字眼就是共享模式，不带就是独占模式；带有Interruptibly字眼的表示会响应中断，即如果线程被中断了，那么就会抛出InterruptedException，否则只会记录是否中断的标记会，然后继续处理；独占模式和共享模式下的三个方法处理逻辑都是差不多的，我们重点分别讲acquire和acquireShared。而其实acquire和acquireShared也是很类似的，所以接下来主要讲独占模式的acquire和release，但同时中间也会穿插说一下对共享模式的处理。acquire获取锁1234567public final void acquire(int arg) &#123; //执行tryAcquire方法，如果不成功，则生成一个EXCLUSIVE的节点，加到队列尾 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) //如果acquireQueued返回true的话，说明线程被中断了，则主动中断线程 selfInterrupt();&#125;tryAcquire方法是模版方法，由子类实现，因为怎样才算“获取锁成功”是由用户自己定义的，AQS做的只是当“获取锁不成功时”，把当前线程入队，即挂起。继续1234567891011121314151617181920212223242526272829303132333435private Node addWaiter(Node mode) &#123; //新建一个节点Node，mode可能是EXCLUSIVE或SHARED Node node = new Node(Thread.currentThread(), mode); Node pred = tail; //如果tail节点不为null，则尝试把node设置为新的tail //注意，这里如果compareAndSetTail成功的话则返回，如果不成功，也没关系，会在enq继续处理 if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; enq(node); return node; &#125; private Node enq(final Node node) &#123; //循环直到把node节点加入到尾部，因为总会成功的 for (;;) &#123; Node t = tail; //这里对head和tail节点做了lazy initialize，有竞争，即节点入队才初始化 if (t == null) &#123; if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; //把node节点设置为新的tail node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125; &#125;acquireQueued123456789101112131415161718192021222324final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; //中断标记 boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); //如果前驱节点是head，且获取锁成功，则把当前节点置为head节点 if (p == head &amp;&amp; tryAcquire(arg)) &#123; setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; //否则挂起 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125;“前驱节点是head，且获取锁成功”，这说明了head节点已经释放资源了（独占模式），当前节点可以获得锁。这也进一步说明了head节点不会自己主动释放掉，是由下一个节点把它干掉的一定是head节点的下一个节点优先获得锁继续看挂起的逻辑123456789101112131415161718private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) //如果SIGNAL返回true return true; if (ws &gt; 0) &#123; // 大于0即为CANCELLED状态，如果前驱节点是取消状态的话，则直接跳过它，继续往前找非取消的前驱节点 do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; //如果是0（初始化）或PROPAGATE，则置为SIGNAL compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; //如果前驱节点的状态不为SIGNAL都返回false return false;&#125;如果pred.waitStatus不是SIGNAL的话，那么也没所谓，因为在下面的else分支会把waitStatus置为SIGNAL了，注意在acquireQueued中shouldParkAfterFailedAcquire可能会被循环执行，即在第二次执行时waitStatus已经为SIGNAL了。12345//如果前驱节点为SIGNAL时，则park挂起阻塞。private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125;release释放锁1234567891011public final boolean release(int arg) &#123; //tryRelease为模板方法，由子类实现 if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) //unpark唤醒后续节点 unparkSuccessor(h); return true; &#125; return false;&#125;跟tryAcquire一个道理，是否能够释放资源应该由用户来决定，AQS做的只是当前节点释放资源后，对队列的处理。1234567891011121314151617181920private void unparkSuccessor(Node node) &#123; //当前节点的状态 int ws = node.waitStatus; //小于0可能是SIGNAL，PROPAGATE，CONDITION，这里的意思是把waitStatus重置为0 //其实这里把当前节点的状态置为0没有什么影响，因为在unpark后继节点后，在acquireQueued方法中会把当前节点干掉，所以这里影响不大 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); Node s = node.next; //如果后继节点为null或被取消了，则从尾到头开始遍历，找到“最前”的非取消状态的节点 if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; //然后unpark把它唤醒 if (s != null) LockSupport.unpark(s.thread);&#125;unparkSuccessor从后往前遍历问题这里相信大家有个疑问，为什么要从尾到头遍历，而不是从头开始？大家可以先思考一下引用一段Doug lea的AQS论文An AbstractQueuedSynchronizer queue node contains a next link to its successor. But because there are no applicabletechniques for lock-free atomic insertion of double-linked list nodes using compareAndSet, this link is not atomically set as part of insertion; it is simply assigned:pred.next = node;after the insertion. This is reflected in all usages. The next link is treated only as an optimized path. If a node’s successor doe not appear to exist (or appears to be cancelled) via its next field, it is always possible to start at the tail of the list and traverse backwards using the pred field to accurately check if there really is one.要看懂这段话，我们需要看回addWaiter方法。意思就是当新节点加入到尾部时，compareAndSetTail和pred.next = node无法保证原子性，而在cas操作之前node.prev = pred是执行的，即prev指针可用，而next指针有可能为null，也就没法遍历到最新加进来的节点，如图所示图解因为懒，所以把acquire和release都画在同一个图上shared共享模式上面都是独占模式的代码，我们看看共享模式下有什么不同点。acquireShared1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950//跟acquire很像public final void acquireShared(int arg) &#123; if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg);&#125;//acquireQueued也是很像，大部分代码都差不多private void doAcquireShared(int arg) &#123; final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; //tryAcquireShared返回大于0说明获得共享锁成功 int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; //独占和共享不同在于此 //共享模式下的节点如果下一个节点也是shared的话，也会唤醒它 setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125;private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; // Record old head for check below //因为当前节点已经获得锁了，设为head setHead(node); if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; //如果下一个节点是shared的话，则直接release if (s == null || s.isShared()) doReleaseShared(); &#125;&#125;由于tryAcquireShared返回是大于0的，所以propagate是大于0的。doReleaseShared12345678910111213141516171819202122private void doReleaseShared() &#123; //从head开始循环 for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; //（1） if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases unparkSuccessor(h); &#125; //（2） else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; //直到 h == head（3） if (h == head) // loop if head changed break; &#125;&#125;这里的代码比较难懂，需要说明一下:如果ws == Node.SIGNAL，说明当前节点需要唤醒后继节点，这没问题，为什么compareAndSetWaitStatus(h, Node.SIGNAL, 0)会失败呢？我们先继续往下看，假设cas成功了，那么会unpark后继节点，后继节点在doAcquireShared醒来后，会在setHeadAndPropagate做两件事，一是把head指向自己，二是还是调用doReleaseShared唤醒后继节点，那么这时候，就可能同时有多个线程去唤醒同一个节点，cas的操作就是要保证只有一个线程去成功唤醒。ws == 0，说明这是新加入的节点，如果compareAndSetWaitStatus(h, 0, Node.PROPAGATE)失败，说明这时又有新的节点加入，把它的前驱节点，即当前节点设置为SIGNAL，即-1，（看shouldParkAfterFailedAcquire），那么这时需要重新从head开始，看看有没有可能去唤醒这个新加入的后继节点。在第一点的时候就说了，可能会有很多线程在同时进行doReleaseShared，而节点的唤醒会把head更新，head在不停的变化，在一直“往后”走，所以如果发现当h == head时，说明没有需要唤醒的后继节点了。共享模式下的唤醒AQS的使用AQS是模板类，它主要实现了对CLH队列的入队、出队和唤醒、挂起操作，但是具体资源是如何分配的，那么这个是由子类决定的。我们看看要成为AQS的子类，要实现最重要的几个方法1234567//独占模式protected boolean tryAcquire(int arg)protected final boolean tryRelease(int releases)//共享模式protected final int tryAcquireShared(int unused)protected final boolean tryReleaseShared(int unused)从上述的源码，我们知道在进队列时会先调用tryAcquire或tryAcquireShared，返回true算获得锁成功，不会进队列，否则就会进队列等一系列操作。至于上述几个方法具体要怎么写，我们可以看一下AQS的java doc文档，或者参考一下ReentrantLock，ReentrantReadWriteLock，CountDownLatch、CyclicBarrier这几个经典例子。总结AQS作为Java并发工具包的核心基础类，我们去了解和掌握它是非常必要的。AQS使用CLH队列，通过Lock-Free算法，实现高并发的进队，出队操作。AQS是抽象模板类，子类一定要覆盖几个核心的方法来完成对资源临界区的加锁和解锁操作。AQS代码紧密严谨，简洁又美妙，能一行写出来绝不会写两行，几乎每一处的代码都可能跟其他地方有关联，这就是Doug Lea大神写出来代码。不过这引来一个问题，谁敢维护呢？参考资料http://novoland.github.io/%E5%B9%B6%E5%8F%91/2014/07/26/AQS%20%E5%92%8C%20%E9%AB%98%E7%BA%A7%E5%90%8C%E6%AD%A5%E5%99%A8.htmlhttps://javadoop.com/post/AbstractQueuedSynchronizer]]></content>
      <categories>
        <category>java</category>
        <category>juc</category>
      </categories>
      <tags>
        <tag>aqs</tag>
        <tag>AbstractQueuedSynchronizer</tag>
        <tag>juc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashedWheelTimer时间轮原理分析]]></title>
    <url>%2Fposts%2Fec8df8c%2F</url>
    <content type="text"><![CDATA[概要时间轮是一种非常惊艳的数据结构。其在Linux内核中使用广泛，是Linux内核定时器的实现方法和基础之一。Netty内部基于时间轮实现了一个HashedWheelTimer来优化I/O超时的检测，本文将详细分析HashedWheelTimer的使用及原理。背景由于Netty动辄管理100w+的连接，每一个连接都会有很多超时任务。比如发送超时、心跳检测间隔等，如果每一个定时任务都启动一个Timer，不仅低效，而且会消耗大量的资源。在Netty中的一个典型应用场景是判断某个连接是否idle，如果idle（如客户端由于网络原因导致到服务器的心跳无法送达），则服务器会主动断开连接，释放资源。得益于Netty NIO的优异性能，基于Netty开发的服务器可以维持大量的长连接，单台8核16G的云主机可以同时维持几十万长连接，及时掐掉不活跃的连接就显得尤其重要。看看官方文档说明：A optimized for approximated I/O timeout scheduling.You can increase or decrease the accuracy of the execution timing byspecifying smaller or larger tick duration in the constructor. In mostnetwork applications, I/O timeout does not need to be accurate. Therefore,the default tick duration is 100 milliseconds and you will not need to trydifferent configurations in most cases.大概意思是一种对“适当”I/O超时调度的优化。因为I/O timeout这种任务对时效性不需要准确。这种方案也不是Netty凭空造出来的，而是根据George Varghese和Tony Lauck在1996年的论文实现的，有兴趣的可以阅读一下。论文下载论文PPT应用场景HashedWheelTimer本质是一种类似延迟任务队列的实现，那么它的特点就是上述所说的，适用于对时效性不高的，可快速执行的，大量这样的“小”任务，能够做到高性能，低消耗。例如：心跳检测session、请求是否timeout业务场景则有：用户下单后发短信下单之后15分钟，如果用户不付款就自动取消订单简单使用如果之前没用过，先看看用法有一个大体的感受，12345678910111213141516171819202122@Slf4jpublic class HashedWheelTimerTest &#123; private CountDownLatch countDownLatch = new CountDownLatch(2); @Test public void test1() throws Exception &#123; //定义一个HashedWheelTimer，有16个格的轮子，每一秒走一个一个格子 HashedWheelTimer timer = new HashedWheelTimer(1, TimeUnit.SECONDS, 16); //把任务加到HashedWheelTimer里，到了延迟的时间就会自动执行 timer.newTimeout((timeout) -&gt; &#123; log.info("task1 execute"); countDownLatch.countDown(); &#125;, 500, TimeUnit.MILLISECONDS); timer.newTimeout((timeout) -&gt; &#123; log.info("task2 execute"); countDownLatch.countDown(); &#125;, 2, TimeUnit.SECONDS); countDownLatch.await(); timer.stop(); &#125;&#125;需要引入netty-all.jar包使用上跟ScheduledExecutorService差不多。实现原理源码基于netty-all.4.1.34.Final数据结构时间轮其实就是一种环形的数据结构，可以想象成时钟，分成很多格子，一个格子代码一段时间（这个时间越短，Timer的精度越高）。并用一个链表报错在该格子上的到期任务，同时一个指针随着时间一格一格转动，并执行相应格子中的到期任务。任务通过取摸决定放入那个格子。如下图所示：假设一个格子是1秒，则整个wheel能表示的时间段为8s，假如当前指针指向2，此时需要调度一个3s后执行的任务，显然应该加入到(2+3=5)的方格中，指针再走3次就可以执行了；如果任务要在10s后执行，应该等指针走完一个round零2格再执行，因此应放入4，同时将round（1）保存到任务中。检查到期任务时应当只执行round为0的，格子上其他任务的round应减1。再回头看看构造方法的三个参数分别代表tickDuration每一tick的时间timeUnittickDuration的时间单位ticksPerWheel就是轮子一共有多个格子，即要多少个tick才能走完这个wheel一圈。对于HashedWheelTimer的数据结构在介绍完源码之后有图解。初始化HashedWheelTimer整体代码不难，慢慢看应该都可以看懂我们从HashedWheelTimer的构造方法入手，先说明一下构造方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667//附上文档说明，自行阅读/** * Creates a new timer. * * @param threadFactory a &#123;@link ThreadFactory&#125; that creates a * background &#123;@link Thread&#125; which is dedicated to * &#123;@link TimerTask&#125; execution. * @param tickDuration the duration between tick * @param unit the time unit of the &#123;@code tickDuration&#125; * @param ticksPerWheel the size of the wheel * @param leakDetection &#123;@code true&#125; if leak detection should be enabled always, * if false it will only be enabled if the worker thread is not * a daemon thread. * @param maxPendingTimeouts The maximum number of pending timeouts after which call to * &#123;@code newTimeout&#125; will result in * &#123;@link java.util.concurrent.RejectedExecutionException&#125; * being thrown. No maximum pending timeouts limit is assumed if * this value is 0 or negative. * @throws NullPointerException if either of &#123;@code threadFactory&#125; and &#123;@code unit&#125; is &#123;@code null&#125; * @throws IllegalArgumentException if either of &#123;@code tickDuration&#125; and &#123;@code ticksPerWheel&#125; is &amp;lt;= 0 *///threadFactory默认是用Executors.defaultThreadFactory()，太懒了//tickDuration，unit，ticksPerWheel核心参数，之前已经说过了//leakDetection内存泄漏检查//maxPendingTimeouts准备执行的任务数，默认是-1，即不限制。如果并发量真的很高，可以设置一下，防止OOMpublic HashedWheelTimer( ThreadFactory threadFactory, long tickDuration, TimeUnit unit, int ticksPerWheel, boolean leakDetection, long maxPendingTimeouts) &#123; if (threadFactory == null) &#123; throw new NullPointerException("threadFactory"); &#125; if (unit == null) &#123; throw new NullPointerException("unit"); &#125; if (tickDuration &lt;= 0) &#123; throw new IllegalArgumentException("tickDuration must be greater than 0: " + tickDuration); &#125; if (ticksPerWheel &lt;= 0) &#123; throw new IllegalArgumentException("ticksPerWheel must be greater than 0: " + ticksPerWheel); &#125; //初始化时间轮（1） wheel = createWheel(ticksPerWheel); mask = wheel.length - 1; this.tickDuration = unit.toNanos(tickDuration); //要求tickDuration * wheel.length &lt; Long.MAX_VALUE，我猜测是因为担心有类似的计算而导致溢出（但实际我没找到） if (this.tickDuration &gt;= Long.MAX_VALUE / wheel.length) &#123; throw new IllegalArgumentException(String.format( "tickDuration: %d (expected: 0 &lt; tickDuration in nanos &lt; %d", tickDuration, Long.MAX_VALUE / wheel.length)); &#125; //创建Work执行线程（2） workerThread = threadFactory.newThread(worker); //默认是启动内存泄露检测（我还不是很清楚具体原理） leak = leakDetection || !workerThread.isDaemon() ? leakDetector.track(this) : null; this.maxPendingTimeouts = maxPendingTimeouts; //HashedWheelTimer实例数限制，因为HashedWheelTimer是一个非常消耗内存的对象，如果超过64个则会警告 if (INSTANCE_COUNTER.incrementAndGet() &gt; INSTANCE_COUNT_LIMIT &amp;&amp; WARNED_TOO_MANY_INSTANCES.compareAndSet(false, true)) &#123; reportTooManyInstances(); &#125;&#125;createWheel1234567891011121314151617181920212223242526private static HashedWheelBucket[] createWheel(int ticksPerWheel) &#123; if (ticksPerWheel &lt;= 0) &#123; throw new IllegalArgumentException( "ticksPerWheel must be greater than 0: " + ticksPerWheel); &#125; if (ticksPerWheel &gt; 1073741824) &#123; throw new IllegalArgumentException( "ticksPerWheel may not be greater than 2^30: " + ticksPerWheel); &#125; //格子数向2的N次方数靠齐 ticksPerWheel = normalizeTicksPerWheel(ticksPerWheel); HashedWheelBucket[] wheel = new HashedWheelBucket[ticksPerWheel]; for (int i = 0; i &lt; wheel.length; i ++) &#123; //初始化每一个bucket wheel[i] = new HashedWheelBucket(); &#125; return wheel;&#125;//循环直到小于2的N次方private static int normalizeTicksPerWheel(int ticksPerWheel) &#123; int normalizedTicksPerWheel = 1; while (normalizedTicksPerWheel &lt; ticksPerWheel) &#123; normalizedTicksPerWheel &lt;&lt;= 1; &#125; return normalizedTicksPerWheel;&#125;wheel其实是一个bucket数组HashedWheelBucket12345678910/*** Bucket that stores HashedWheelTimeouts. These are stored in a linked-list like datastructure to allow easy* removal of HashedWheelTimeouts in the middle. Also the HashedWheelTimeout act as nodes themself and so no* extra object creation is needed.*/private static final class HashedWheelBucket &#123; // Used for the linked-list datastructure private HashedWheelTimeout head; private HashedWheelTimeout tail;&#125;bucket的结构是一个带有头节点指针和尾节点指针的linked-listnewTimeoutHashedWheelTimer初始化后，看看怎样增加一个任务（在HashedWheelTimer内部统一叫HashedWheelTimeout，缩写timeout，从名字已经可以看出HashedWheelTimer的作用）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public Timeout newTimeout(TimerTask task, long delay, TimeUnit unit) &#123; if (task == null) &#123; throw new NullPointerException("task"); &#125; if (unit == null) &#123; throw new NullPointerException("unit"); &#125; //记录代处理数，这个数字没有实际作用，或可用于监控 long pendingTimeoutsCount = pendingTimeouts.incrementAndGet(); //如果大于maxPendingTimeouts则报错，默认-1，即不限制 if (maxPendingTimeouts &gt; 0 &amp;&amp; pendingTimeoutsCount &gt; maxPendingTimeouts) &#123; pendingTimeouts.decrementAndGet(); throw new RejectedExecutionException("Number of pending timeouts (" + pendingTimeoutsCount + ") is greater than or equal to maximum allowed pending " + "timeouts (" + maxPendingTimeouts + ")"); &#125; //（1） start(); //计算这个timeout的执行时间，公式=当前时间 + 延迟时间 - wheelTimer的启动时间，单位纳秒，很直观吧 long deadline = System.nanoTime() + unit.toNanos(delay) - startTime; //初始化timeout HashedWheelTimeout timeout = new HashedWheelTimeout(this, task, deadline); //timeouts是一个MpscQueue队列。这里注意了，新加入的timeout不是立即加到wheel中的，而是先加入到一个队列，在tick的时候再从队列取出来加入到wheel。 //原因是，我猜测一是做缓冲作用，二是避免在插入timeout和执行timeout时有并发的冲突，特别是对linked-list的操作，如果采用加锁的话，而执行该bucket所有timeout的时间不能保证，可能反而会阻塞到用户。 timeouts.add(timeout); return timeout;&#125;//（1）//start方法为了保证wheelTimer在运行的状态（如果是关闭状态，那么直接抛异常出去），且wheelTimer已经初始化完成//大家是不是很好奇wheelTimer的初始化为什么要在newTimeout，即加入第一个timeout后才去做。可以沿着延迟初始化或懒加载的思路去想，如果一个HashedWheelTimer初始化后一直没有timeout加入，在那里空转而白白浪费CPU资源就不好了。public void start() &#123; switch (WORKER_STATE_UPDATER.get(this)) &#123; case WORKER_STATE_INIT: if (WORKER_STATE_UPDATER.compareAndSet(this, WORKER_STATE_INIT, WORKER_STATE_STARTED)) &#123; //启动Worker workerThread.start(); &#125; break; case WORKER_STATE_STARTED: break; case WORKER_STATE_SHUTDOWN: throw new IllegalStateException("cannot be started once stopped"); default: throw new Error("Invalid WorkerState"); &#125; //因为Worker是异步执行的，会一直等待Worker的初始化 while (startTime == 0) &#123; try &#123; //是一个CountDownLatch startTimeInitialized.await(); &#125; catch (InterruptedException ignore) &#123; // Ignore - it will be ready very soon. &#125; &#125;&#125;HashedWheelTimeouttimeout的结构1234567891011121314151617181920212223242526272829303132333435private static final class HashedWheelTimeout implements Timeout &#123; //timeout的状态有初始化，取消，已执行 private static final int ST_INIT = 0; private static final int ST_CANCELLED = 1; private static final int ST_EXPIRED = 2; //用来支持CAS操作原子类 private static final AtomicIntegerFieldUpdater&lt;HashedWheelTimeout&gt; STATE_UPDATER = AtomicIntegerFieldUpdater.newUpdater(HashedWheelTimeout.class, "state"); //所属timer private final HashedWheelTimer timer; //需要执行的Runnable private final TimerTask task; //执行时间 private final long deadline; @SuppressWarnings(&#123;"unused", "FieldMayBeFinal", "RedundantFieldInitialization" &#125;) private volatile int state = ST_INIT; //时间轮的层数 long remainingRounds; //在linked-list中该节点指向的前后节点 HashedWheelTimeout next; HashedWheelTimeout prev; // The bucket to which the timeout was added HashedWheelBucket bucket; HashedWheelTimeout(HashedWheelTimer timer, TimerTask task, long deadline) &#123; this.timer = timer; this.task = task; this.deadline = deadline; &#125;&#125;Worker run一个HashedWheelTimer只有一个Worker线程。看看Worker的初始化1private final Worker worker = new Worker();Worker继承Runnable，我们看run方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213public void run() &#123; //获取启动的时间作为开始时间 startTime = System.nanoTime(); if (startTime == 0) &#123; // We use 0 as an indicator for the uninitialized value here, so make sure it's not 0 when initialized. startTime = 1; &#125; // Notify the other threads waiting for the initialization at start(). startTimeInitialized.countDown(); do &#123; //等待下一个tick（1） final long deadline = waitForNextTick(); if (deadline &gt; 0) &#123; //找到该处理的bucket下标，因为wheel.length是2的N次方，mask为length - 1，所以这里相当于取模操作，性能比%高 int idx = (int) (tick &amp; mask); //处理掉已经取消的timeout（2） processCancelledTasks(); //找到当前tick对应哪个bucket HashedWheelBucket bucket = wheel[idx]; //把队列的timeout放到wheel里（3） transferTimeoutsToBuckets(); //处理当前bucket所有的timeout（4） bucket.expireTimeouts(deadline); //tick加一 tick++; &#125; //注意一下处理的顺序，也讲究的，先处理掉被取消的timeout，再把队列的加进来，再处理，后面两步不能反转，因为有可能队列里的timeout是下一tick执行的 //循环直到wheelTimer被关闭 &#125; while (WORKER_STATE_UPDATER.get(HashedWheelTimer.this) == WORKER_STATE_STARTED); //wheelTimer被关闭后的处理 //取出每一个bucket里还没被执行的timeout，放到unprocessedTimeouts中 for (HashedWheelBucket bucket: wheel) &#123; bucket.clearTimeouts(unprocessedTimeouts); &#125; //把队列里的timeout放到unprocessedTimeouts中 //PS：这个unprocessedTimeouts暂时只是做记录用，做监控时或可用到 for (;;) &#123; HashedWheelTimeout timeout = timeouts.poll(); if (timeout == null) &#123; break; &#125; if (!timeout.isCancelled()) &#123; unprocessedTimeouts.add(timeout); &#125; &#125; //还要处理掉中间被取消的timeout processCancelledTasks(); &#125; //（1） private long waitForNextTick() &#123; //计算下一个tick的时间，很简单一看就懂 long deadline = tickDuration * (tick + 1); for (;;) &#123; final long currentTime = System.nanoTime() - startTime; //根据当前计算需要sleep的时间。这里加了999999是因为向上取整了1毫秒，假如距离下一个tick的时间为2000010纳秒，那如果sleep 2毫秒是不够的，所以需要多sleep 1毫秒。 long sleepTimeMs = (deadline - currentTime + 999999) / 1000000; //sleepTimeMs &lt;=0 说明下一个tick的时间到了，说明上一个tick执行的时间“太久”了，所以直接返回就好了，不需要sleep if (sleepTimeMs &lt;= 0) &#123; //currentTime == Long.MIN_VALUE 这个判断不是很理解 if (currentTime == Long.MIN_VALUE) &#123; return -Long.MAX_VALUE; &#125; else &#123; return currentTime; &#125; &#125; // Check if we run on windows, as if thats the case we will need // to round the sleepTime as workaround for a bug that only affect // the JVM if it runs on windows. // // See https://github.com/netty/netty/issues/356 //这里是为了处理在windows系统上的一个bug，如果sleep不够10ms则要取整 if (PlatformDependent.isWindows()) &#123; sleepTimeMs = sleepTimeMs / 10 * 10; &#125; //直接sleep等待 try &#123; Thread.sleep(sleepTimeMs); &#125; catch (InterruptedException ignored) &#123; //Worker被中断，如果是关闭了则返回负数，表示不会执行下一个tick if (WORKER_STATE_UPDATER.get(HashedWheelTimer.this) == WORKER_STATE_SHUTDOWN) &#123; return Long.MIN_VALUE; &#125; &#125; &#125; &#125; //（2） private void processCancelledTasks() &#123; for (;;) &#123; //cancelledTimeouts也是一个MpscQueue，调用timeout的cancel方法会把timeout加进去 //把取消的timeout取出来 HashedWheelTimeout timeout = cancelledTimeouts.poll(); if (timeout == null) &#123; // all processed break; &#125; try &#123; //移除掉（2.1） timeout.remove(); &#125; catch (Throwable t) &#123; if (logger.isWarnEnabled()) &#123; logger.warn("An exception was thrown while process a cancellation task", t); &#125; &#125; &#125; &#125; //（2.1） void remove() &#123; HashedWheelBucket bucket = this.bucket; if (bucket != null) &#123; //调用bucket的remove方法（2.2） bucket.remove(this); &#125; else &#123; timer.pendingTimeouts.decrementAndGet(); &#125; &#125; //（2.2） //类似链表删除节点的操作 public HashedWheelTimeout remove(HashedWheelTimeout timeout) &#123; HashedWheelTimeout next = timeout.next; // remove timeout that was either processed or cancelled by updating the linked-list if (timeout.prev != null) &#123; timeout.prev.next = next; &#125; if (timeout.next != null) &#123; timeout.next.prev = timeout.prev; &#125; if (timeout == head) &#123; // if timeout is also the tail we need to adjust the entry too if (timeout == tail) &#123; tail = null; head = null; &#125; else &#123; head = next; &#125; &#125; else if (timeout == tail) &#123; // if the timeout is the tail modify the tail to be the prev node. tail = timeout.prev; &#125; // null out prev, next and bucket to allow for GC. timeout.prev = null; timeout.next = null; timeout.bucket = null; timeout.timer.pendingTimeouts.decrementAndGet(); return next; &#125; //（3） private void transferTimeoutsToBuckets() &#123; //最多取队列的100000的元素出来 for (int i = 0; i &lt; 100000; i++) &#123; HashedWheelTimeout timeout = timeouts.poll(); if (timeout == null) &#123; // all processed break; &#125; //如果timeout被取消了则不做处理 if (timeout.state() == HashedWheelTimeout.ST_CANCELLED) &#123; // Was cancelled in the meantime. continue; &#125; //计算位于实践论的层数 long calculated = timeout.deadline / tickDuration; timeout.remainingRounds = (calculated - tick) / wheel.length; //就是timeout已经到期了，也不能放到之前的tick中 final long ticks = Math.max(calculated, tick); // Ensure we don't schedule for past. //计算所在bucket下标，并放进去 int stopIndex = (int) (ticks &amp; mask); HashedWheelBucket bucket = wheel[stopIndex]; //又是类似链表插入节点的操作 bucket.addTimeout(timeout); &#125; &#125; //（4） public void expireTimeouts(long deadline) &#123; HashedWheelTimeout timeout = head; //把bucket的所有timeout取出来执行 while (timeout != null) &#123; HashedWheelTimeout next = timeout.next; if (timeout.remainingRounds &lt;= 0) &#123; next = remove(timeout); if (timeout.deadline &lt;= deadline) &#123; //timeout的真正执行 timeout.expire(); &#125; else &#123; // The timeout was placed into a wrong slot. This should never happen. throw new IllegalStateException(String.format( "timeout.deadline (%d) &gt; deadline (%d)", timeout.deadline, deadline)); &#125; //该timeout被取消了则移除掉 &#125; else if (timeout.isCancelled()) &#123; next = remove(timeout); //否则层数减一，等待下一轮的到来 &#125; else &#123; timeout.remainingRounds --; &#125; timeout = next; &#125; &#125;图解画了个图给大家体会一下MpscQueue队列HashedWheelTimer用到的timeouts和cancelledTimeouts都是一种MpscQueue队列的数据结构。MpscQueue全称Multi-Producer Single-Consumer Queue，从名字看出，是一种适合于多个生产者，单个消费者的高并发场景的高性能的，无锁的队列，原来Netty是自己实现了一个，但在最新的版本用了JCTools的，大家有兴趣可以了解一下。多层时间轮当时间跨度很大时，提升单层时间轮的 tickDuration 可以减少空转次数，但会导致时间精度变低，层级时间轮既可以避免精度降低，又避免了指针空转的次数。如果有时间跨度较长的定时任务，则可以交给层级时间轮去调度。设想一下一个定时了 3 天，10 小时，50 分，30 秒的定时任务，在 tickDuration = 1s 的单层时间轮中，需要经过：3246060+106060+5060+30 次指针的拨动才能被执行。但在 wheel1 tickDuration = 1 天，wheel2 tickDuration = 1 小时，wheel3 tickDuration = 1 分，wheel4 tickDuration = 1 秒 的四层时间轮中，只需要经过 3+10+50+30 次指针的拨动。如图所示:缺点HashedWheelTimer也有一些缺点，在使用场景上要注意一下Netty的HashedWheelTimer只支持单层的时间轮当前一个任务执行时间过长的时候，会影响后续任务的到期执行时间的，也就是说其中的任务是串行执行的，所以，要求里面的任务都要短平快延迟任务方案对比HashedWheelTimer本质上也是一个延迟队列，我们跟其他延迟类解决方案对比一下数据库轮询比较常用的一种方法，数据先保存在数据库中，然后启动一个定时Job，根据时间或状态把数据捞出来，处理后再更新回数据库。这种方式很简单，不会引入其他的技术，开发周期短。如果数据量比较大，千万级甚至更多，插入频率很高的话，上面的方式在性能上会出现一些问题，查找和更新对会占用很多时间，轮询频率高的话甚至会影响数据入库。如果数据量进一步增大，那扫数据库肯定就不行了。另一方面，对于订单这类数据，我们也许会遇到分库分表，那上述方案就会变得过于复杂，得不偿失。不过，优点是数据得到持久化，有问题可以查看。DelayQueueDelayQueue本质是PriorityQueue，每次插入或删除任务都要调整堆，复杂度是O(logN)，相对HashedWheelTimer的O(1)来说有性能消耗。ScheduledExecutorService其本质也是类似DelayQueue，不过ScheduledExecutorService是多线程的方式执行，可以基本保证其他任务的准时进行。ScheduledExecutorService封装较好，方便使用，还支持周期性任务。总结HashedWheelTimer时间轮是一个高性能，低消耗的数据结构，它适合用非准实时，延迟的短平快任务，例如心跳检测。参考资料https://zacard.net/2016/12/02/netty-hashedwheeltimer/https://www.ctolib.com/topics-113116.htmlhttps://www.cnkirito.moe/timer/]]></content>
      <categories>
        <category>java</category>
        <category>netty</category>
      </categories>
      <tags>
        <tag>HashedWheelTimer</tag>
        <tag>时间轮</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Slf4j适配日志原理]]></title>
    <url>%2Fposts%2Fe31dfd0e%2F</url>
    <content type="text"><![CDATA[概要看了之前的文章Java日志体系总结后，相信大家对slf4j以及其他日志组件的关系有了一定理解。slf4j只是为日志的输出提供了统一接口，并没有具体的实现，就好像JDBC一样。那么，大家会不会好奇slf4j是怎么绑定/适配/桥接到log4j或者logback其他日志实现组件的呢？这篇文章为大家详细讲述。适配过程原理统计API接口，说明slf4j使用的是门面模式（Facade），然后我们就很容易猜测到大致的调用过程是，slf4j是通过自己的api去调用实现组件的api，这样来完成适配的。我们重点看看是怎么做到适配的。源码基于slf4j-api.1.7.25slf4j通用门面的实现调用slf4j时我们都是使用它的api，首先我们需要获取它的logger一般大家使用slf4j都是这样子的1234import org.slf4j.Logger;import org.slf4j.LoggerFactory;private Logger logger = LoggerFactory.getLogger(LogTest.class);getLogger我们对getLogger()方法源码跟踪下去123456789101112131415161718public static Logger getLogger(Class&lt;?&gt; clazz) &#123; Logger logger = getLogger(clazz.getName()); if (DETECT_LOGGER_NAME_MISMATCH) &#123; Class&lt;?&gt; autoComputedCallingClass = Util.getCallingClass(); if (autoComputedCallingClass != null &amp;&amp; nonMatchingClasses(clazz, autoComputedCallingClass)) &#123; Util.report(String.format("Detected logger name mismatch. Given name: \"%s\"; computed name: \"%s\".", logger.getName(), autoComputedCallingClass.getName())); Util.report("See " + LOGGER_NAME_MISMATCH_URL + " for an explanation"); &#125; &#125; return logger; &#125; public static Logger getLogger(String name) &#123; //获取logger的工厂来生成logger ILoggerFactory iLoggerFactory = getILoggerFactory(); return iLoggerFactory.getLogger(name); &#125;从ILoggerFactory的名字上来看，这是一个接口，而它又可以生成到具体实际的logger，那我们应该猜测到这个ILoggerFactory会跟其他日志实现相关，但是例如log4j，自己的实现肯定不会关心slf4j的呀，所以应该由适配jar包，即slf4j-log4j12.jar来实现。继续看代码1234567891011121314151617181920212223242526272829303132public static ILoggerFactory getILoggerFactory() &#123; //从ILoggerFactory的状态可以看出，ILoggerFactory只会一次初始化 if (INITIALIZATION_STATE == UNINITIALIZED) &#123; synchronized (LoggerFactory.class) &#123; //同步语句 + 双重判断，防止多次初始化 //如果还没初始化，则进行初始化 if (INITIALIZATION_STATE == UNINITIALIZED) &#123; INITIALIZATION_STATE = ONGOING_INITIALIZATION; performInitialization(); &#125; &#125; &#125; switch (INITIALIZATION_STATE) &#123; //初始化成功，即绑定成功，则从StaticLoggerBinder获取ILoggerFactory并返回 case SUCCESSFUL_INITIALIZATION: return StaticLoggerBinder.getSingleton().getLoggerFactory(); case NOP_FALLBACK_INITIALIZATION: return NOP_FALLBACK_FACTORY; case FAILED_INITIALIZATION: throw new IllegalStateException(UNSUCCESSFUL_INIT_MSG); case ONGOING_INITIALIZATION: return SUBST_FACTORY; &#125; throw new IllegalStateException("Unreachable code");&#125;//对ILoggerFactory的状态做说明static final int UNINITIALIZED = 0; //没初始化static final int ONGOING_INITIALIZATION = 1; //正在初始化static final int FAILED_INITIALIZATION = 2; //初始化失败static final int SUCCESSFUL_INITIALIZATION = 3; //初始化成功static final int NOP_FALLBACK_INITIALIZATION = 4; //无日志实现bindperformInitialization()方法看来是重点123456private final static void performInitialization() &#123; bind(); if (INITIALIZATION_STATE == SUCCESSFUL_INITIALIZATION) &#123; versionSanityCheck(); &#125;&#125;bind()方法12345678910111213141516171819202122232425262728293031323334353637383940414243private final static void bind() &#123; try &#123; Set&lt;URL&gt; staticLoggerBinderPathSet = null; if (!isAndroid()) &#123; //找出可能绑定的日志的path，其实即StaticLoggerBinder.class文件 staticLoggerBinderPathSet = findPossibleStaticLoggerBinderPathSet(); //如果找出多个的话则打印错误信息。（等下会演示） reportMultipleBindingAmbiguity(staticLoggerBinderPathSet); &#125; //通过获取单例来做初始化 StaticLoggerBinder.getSingleton(); INITIALIZATION_STATE = SUCCESSFUL_INITIALIZATION; //打印实际绑定的那个日志实现。（等下会演示） reportActualBinding(staticLoggerBinderPathSet); fixSubstituteLoggers(); replayEvents(); // release all resources in SUBST_FACTORY SUBST_FACTORY.clear(); &#125; catch (NoClassDefFoundError ncde) &#123; String msg = ncde.getMessage(); if (messageContainsOrgSlf4jImplStaticLoggerBinder(msg)) &#123; INITIALIZATION_STATE = NOP_FALLBACK_INITIALIZATION; Util.report("Failed to load class \"org.slf4j.impl.StaticLoggerBinder\"."); Util.report("Defaulting to no-operation (NOP) logger implementation"); Util.report("See " + NO_STATICLOGGERBINDER_URL + " for further details."); &#125; else &#123; failedBinding(ncde); throw ncde; &#125; &#125; catch (java.lang.NoSuchMethodError nsme) &#123; String msg = nsme.getMessage(); if (msg != null &amp;&amp; msg.contains("org.slf4j.impl.StaticLoggerBinder.getSingleton()")) &#123; INITIALIZATION_STATE = FAILED_INITIALIZATION; Util.report("slf4j-api 1.6.x (or later) is incompatible with this binding."); Util.report("Your binding is version 1.5.5 or earlier."); Util.report("Upgrade your binding to version 1.6.x."); &#125; throw nsme; &#125; catch (Exception e) &#123; failedBinding(e); throw new IllegalStateException("Unexpected initialization failure", e); &#125;&#125;StaticLoggerBinder类findPossibleStaticLoggerBinderPathSet()方法从hard code看重要性，org/slf4j/impl/StaticLoggerBinder.class就是slf4j日志适配的关键1234567891011121314151617181920212223242526//hard codeprivate static String STATIC_LOGGER_BINDER_PATH = "org/slf4j/impl/StaticLoggerBinder.class";static Set&lt;URL&gt; findPossibleStaticLoggerBinderPathSet() &#123; Set&lt;URL&gt; staticLoggerBinderPathSet = new LinkedHashSet&lt;URL&gt;(); try &#123; //获取LoggerFactory，即slf4j-apoi的类加载器 ClassLoader loggerFactoryClassLoader = LoggerFactory.class.getClassLoader(); Enumeration&lt;URL&gt; paths; //为null说明是由Bootstrap Classloader加载的，则转为App Classloader去加载 if (loggerFactoryClassLoader == null) &#123; paths = ClassLoader.getSystemResources(STATIC_LOGGER_BINDER_PATH); &#125; else &#123; //用跟slf4j一样的Classloader去加载 paths = loggerFactoryClassLoader.getResources(STATIC_LOGGER_BINDER_PATH); &#125; while (paths.hasMoreElements()) &#123; URL path = paths.nextElement(); staticLoggerBinderPathSet.add(path); &#125; &#125; catch (IOException ioe) &#123; Util.report("Error getting resources from path", ioe); &#125; return staticLoggerBinderPathSet;&#125;从类加载器的用法说明，org/slf4j/impl/StaticLoggerBinder.class要跟slf4j-api.jar包在同一个类加载器中，一般来说即要求放在同一路径下比较稳妥，当然也可以通过-classpath来指定。前面我们已经猜测org/slf4j/impl/StaticLoggerBinder应该是由各种适配器来实现的，我们来看看在IDE的类搜索，可以找到两个StaticLoggerBinder调试刚刚的源码，可以看到找到了两个StaticLoggerBinder.class文件那是因为我本机依赖了1234567891011&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt;&lt;/dependency&gt;所以只是看到logback和log4j的适配器包。slf4j是对每一种日志实现都有对应的一个适配实现。适配器包的具体内容我们等下再看。（PS：这不是一个好的依赖配置，等下会说）到这里我们已经找到了StaticLoggerBinder类了，StaticLoggerBinder是由各自的slf4j适配器包提供的。这里有个trick，既然StaticLoggerBinder在slf4j-api有，也在其他logback-classic或slf4j-log4j12有，那么怎么确保JVM只加载到适配器包中的StaticLoggerBinder？其实看看slf4j代码的pom.xml就发现，答案是打包时是没有StaticLoggerBinder打进去的，这样slf4j-api.jar包是没有StaticLoggerBinder类的，JVM在找类时只会找到其他jar包的StaticLoggerBinder。我们刚刚的源码到bind()方法的这一句1StaticLoggerBinder.getSingleton();这一句其实已经是调用适配包的代码，我们将会看看logback和log4j对应StaticLoggerBinder类的代码。对logback适配实现从上面的依赖我们看出，为什么slf4j对logback的适配是在logback-classic.jar包呢？logback-classic应该是logback的核心包才对，不应该关心slf4j的。那是因为slf4j和logback是同一个作者，所以才说logback是天然集成slf4j的。我们看看logback-classic.jar中的StaticLoggerBinder1234567891011121314151617181920212223static &#123; SINGLETON.init();&#125;public static StaticLoggerBinder getSingleton() &#123; return SINGLETON;&#125;void init() &#123; try &#123; try &#123; new ContextInitializer(defaultLoggerContext).autoConfig(); &#125; catch (JoranException je) &#123; Util.report("Failed to auto configure default logger context", je); &#125; // logback-292 if (!StatusUtil.contextHasStatusListener(defaultLoggerContext)) &#123; StatusPrinter.printInCaseOfErrorsOrWarnings(defaultLoggerContext); &#125; contextSelectorBinder.init(defaultLoggerContext, KEY); initialized = true; &#125; catch (Exception t) &#123; // see LOGBACK-1159 Util.report("Failed to instantiate [" + LoggerContext.class.getName() + "]", t); &#125;&#125;上面的就是logback的初始化了。12345678910public ILoggerFactory getLoggerFactory() &#123; if (!initialized) &#123; return defaultLoggerContext; &#125; if (contextSelectorBinder.getContextSelector() == null) &#123; throw new IllegalStateException("contextSelector cannot be null. See also " + NULL_CS_URL); &#125; return contextSelectorBinder.getContextSelector().getLoggerContext();&#125;getLoggerFactory()方法会返回logback的LoggerContext，而LoggerContext是继承slf4j的ILoggerFactory的，这样就适配到slf4j。Logger是从LoggerFactory取出的。看看LoggerContext的getLogger()方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public final Logger getLogger(final Class&lt;?&gt; clazz) &#123; return getLogger(clazz.getName());&#125;@Overridepublic final Logger getLogger(final String name) &#123; if (name == null) &#123; throw new IllegalArgumentException("name argument cannot be null"); &#125; // if we are asking for the root logger, then let us return it without // wasting time if (Logger.ROOT_LOGGER_NAME.equalsIgnoreCase(name)) &#123; return root; &#125; int i = 0; Logger logger = root; // check if the desired logger exists, if it does, return it // without further ado. Logger childLogger = (Logger) loggerCache.get(name); // if we have the child, then let us return it without wasting time if (childLogger != null) &#123; return childLogger; &#125; // if the desired logger does not exist, them create all the loggers // in between as well (if they don't already exist) String childName; while (true) &#123; int h = LoggerNameUtil.getSeparatorIndexOf(name, i); if (h == -1) &#123; childName = name; &#125; else &#123; childName = name.substring(0, h); &#125; // move i left of the last point i = h + 1; synchronized (logger) &#123; childLogger = logger.getChildByName(childName); if (childLogger == null) &#123; childLogger = logger.createChildByName(childName); loggerCache.put(childName, childLogger); incSize(); &#125; &#125; logger = childLogger; if (h == -1) &#123; return childLogger; &#125; &#125;&#125;这里涉及了logback很多逻辑，我们不太需要理会。这里主要看logback的Logger其实是继承了slf4j的Logger，这样就适配到slf4j。对log4j配置实现看了logback的适配，就猜到log4j的也差不多slf4j-log4j12的StaticLoggerBinder12345678910111213private StaticLoggerBinder() &#123; loggerFactory = new Log4jLoggerFactory(); try &#123; @SuppressWarnings("unused") Level level = Level.TRACE; &#125; catch (NoSuchFieldError nsfe) &#123; Util.report("This version of SLF4J requires log4j version 1.2.12 or later. See also http://www.slf4j.org/codes.html#log4j_version"); &#125; &#125; public ILoggerFactory getLoggerFactory() &#123; return loggerFactory; &#125;Log4jLoggerFactory()是继承了slf4j的ILoggerFactory。继续看getLogger方法。12345678910111213141516public Logger getLogger(String name) &#123; Logger slf4jLogger = loggerMap.get(name); if (slf4jLogger != null) &#123; return slf4jLogger; &#125; else &#123; org.apache.log4j.Logger log4jLogger; if (name.equalsIgnoreCase(Logger.ROOT_LOGGER_NAME)) log4jLogger = LogManager.getRootLogger(); else log4jLogger = LogManager.getLogger(name); Logger newInstance = new Log4jLoggerAdapter(log4jLogger); Logger oldInstance = loggerMap.putIfAbsent(name, newInstance); return oldInstance == null ? newInstance : oldInstance; &#125;&#125;这里又是把log4j的Logger包装成slf4j的Logger，适配到slf4j。图解画了个图总结一下上面代码说的类关系，大家感受一下。总结slf4j的适配原理是通过适配包的org/slf4j/impl/StaticLoggerBinder来做转承，适配包通过继承和使用slf4j-api的ILoggerFactory和Logger来完成适配。在最新的版本（我看的是1.8.0）已经改为使用Java的SPI机制来实现，StaticLoggerBinder类已经不用了，改为SLF4JServiceProvider，这样就真正的面向接口编程了，不用打包时忽略StaticLoggerBinder。参考资料Slf4j源码解析 - 无底层日志实现框架时的执行流程Java日志-SLF4J使用与源码分析]]></content>
      <categories>
        <category>java</category>
        <category>log</category>
      </categories>
      <tags>
        <tag>slf4j</tag>
        <tag>日志适配</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java日志体系总结]]></title>
    <url>%2Fposts%2F854fc091%2F</url>
    <content type="text"><![CDATA[概要本文的目的是搞清楚Java中各种日志Log之间是怎么的关系，如何作用、依赖，好让我们平时在工作中如果遇到“日志打不出”或者“日志jar包冲突”等之类的问题知道该如何入手解决，以及在各种场景下如何调整项目中的各个框架的日志输出，使得输出统一。Log日志体系在日常工作中我们可能看到项目中依赖的跟日志相关的jar包有很多，commons-logging.jar、log4j.jar、sl4j-api.jar、logback.jar等等，眼花缭乱。我们要正确的配置，使得jar包相互作用生效之前，就先要理清它们之间的关系。背景/发展史那就要从Java Log的发展历程开始说起。log4j（作者Ceki Gülcü）出来时就等到了广泛的应用（注意这里是直接使用），是Java日志事实上的标准，并成为了Apache的项目Apache要求把log4j并入到JDK，SUN拒绝，并在jdk1.4版本后增加了JUL（java.util.logging）毕竟是JDK自带的，JUL也有很多人用。同时还有其他日志组件，如SimpleLog等。这时如果有人想换成其他日志组件，如log4j换成JUL，因为api完全不同，就需要改动代码。Apache见此，开发了JCL（Jakarta Commons Logging），即commons-logging-xx.jar。它只提供一套通用的日志接口api，并不提供日志的实现。很好的设计原则嘛，依赖抽象而非实现。这样应用程序可以在运行时选择自己想要的日志实现组件。这样看上去也挺美好的，但是log4j的作者觉得JCL不好用，自己开发出slf4j，它跟JCL类似，本身不替供日志具体实现，只对外提供接口或门面。目的就是为了替代JCL。同时，还开发出logback，一个比log4j拥有更高性能的组件，目的是为了替代log4j。Apache参考了logback,并做了一系列优化，推出了log4j2关系/依赖大概了解心路历程后，再详细看看它们之间的关系、依赖。JCLcommons-logging已经停止更新，最后的状态如下所示：JCL支持日志组件不多，不过也有很人用的，例如Spring现在用的也越来越少了，也不多讲了SLF4J因为当时Java的日志组件比较混乱繁杂，Ceki Gülcü推出slf4j后，也相应为行业中各个主流日志组件推出了slf4j的适配图来源于官方文档图的意思为如果你想用slf4j作为日志门面的话，你如何去配合使用其他日志实现组件，这里说明一下（注意jar包名缺少了版本号，在找版本时也要注意版本之间是否兼容）slf4j + logbackslf4j-api.jar + logback-classic.jar + logback-core.jarslf4j + log4jslf4j-api.jar + slf4j-log4j12.jar + log4j.jarslf4j + julslf4j-api.jar + slf4j-jdk14.jar也可以只用slf4j无日志实现slf4j-api.jar + slf4j-nop.jarSLF4J的适配slf4j支持各种适配，无论你现在是用哪种日志组件，你都可以通过slf4j的适配器来使用上slf4j。只要你切换到了slf4j，那么再通过slf4j用上实现组件，即上面说的。图来源于官方文档其实总的来说，无论就是以下几种情况你在用JCL使用jcl-over-slf4j.jar适配你在用log4j使用log4j-over-slf4j.jar适配你在用JUL使用jul-to-slf4j.jar适配我在网上盗一张图，给大家一个整体的依赖图（懒得画了）让Spring统一输出这就是为了对slf4j的适配做一个例子说明。Spring是用JCL作为日志门面的，那我们的应用是slf4j + logback，怎么让Spring也用到logback作为日志输出呢？这样的好处就是我们可以统一项目内的其他模块、框架的日志输出（日志格式，日志文件，存放路径等，以及其他slf4j支持的功能）很简单，就是加入jcl-over-slf4j.jar就好了。我又盗了一个图来说明适配思路其实很简单你首先确认需要统一日志的模块、框架是使用哪个日志组件的，然后再找到sfl4j的适配器。记得去掉无用的日志实现组件，只保留你要用的。常见问题slf4j的日志加载会在程序启动时把日志打出来，所以一定要注意，它会说明加载是否成功，加载了那个日志实现。slf4j已经对错误作了说明官网说明下面讲一下可能经常遇到的问题Failed to load class org.slf4j.impl.StaticLoggerBinder没找到日志实现，如果你觉得你已经写上了对应的日志实现依赖了，那你要检查一下了，一般来说极有可能是版本不兼容。Multiple bindings找到多个日志实现，slf4j会找其中一个作为日志实现。代码规范阿里对此的代码规范：【强制】应用中不可直接使用日志系统（Log4j、Logback）中的 API，而应依赖使用日志框架 SLF4J 中的 API，使用门面模式的日志框架，有利于维护和各个类的日志处理方式统一。import org.slf4j.Logger;import org.slf4j.LoggerFactory;private static final Logger logger = LoggerFactory.getLogger(Abc.class);总结文章帮大家梳理了Java日志组件的关系，以及如何解决日常中常见日志相关的问题，希望对大家帮助。参考资料架构师必备，带你弄清混乱的JAVA日志体系！10分钟搞定–混乱的 Java 日志体系Java主流日志工具介绍和使用https://www.slf4j.org/]]></content>
      <categories>
        <category>java</category>
        <category>log</category>
      </categories>
      <tags>
        <tag>log</tag>
        <tag>java日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mockito的使用及实现原理]]></title>
    <url>%2Fposts%2F9758301d%2F</url>
    <content type="text"><![CDATA[概要Mockito是一个强大的mock工具，本文将重点讲述Mockito的基本使用及注意事项，以及其实现mock的原理。使用应用场景开发完成之后，我们都需要经过测试才敢把代码发布到线上。一个很普遍的问题是，我们要测试的类可能会有很多对上游依赖，这些依赖包括类、对象、资源、数据等等，正常来说如果我们缺少这些依赖的话，我们将无法完成测试。这时候，我们一般的处理方法是mock，mock本地方法的返回，mock上游接口的返回等等，使这些方法返回假定的数据，好让我们流程可以继续走下去，完成测试。Mock对于TDD来说也是很重要的一个功能。关于Mock在单元测试中的作用，可以看看Martin Fowler对它的讨论简单例子事例代码基于Mockito2.18.3版本。通常来说Mockito分为两大功能点，一是verify验证，一是stub打桩（我不知道怎么翻译好，跟立flag差不多意思）先看看一个入门的例子12345678910111213141516171819@Testpublic void mockitoTest()&#123; //生成一个mock对象 List&lt;String&gt; mockedList = Mockito.mock(List.class); //打印mock对象的类名，看看mock对象为何物 System.out.println(mockedList.getClass().getName()); //操作mock对象 mockedList.add("one"); mockedList.get(0); mockedList.clear(); //verify验证，mock对象是否发生过某些行为 //如果验证不通过，Mockito会抛出异常 Mockito.verify(mockedList).add("one"); Mockito.verify(mockedList).get(0); //stub打桩，指定mock对象某些行为的返回，也就是我们常用的mock数据 Mockito.when(mockedList.get(1)).thenReturn("13"); //这里打印出“13”（但我们知道mockedList实际是没有下标为1的元素，这就是mock的功能） System.out.println(mockedList.get(1));&#125;Mockito的使用很简单吧！相信经过上述代码的演示还有注释的说明，相信大家已经对Mockito有一个大概的认识。当然，上述代码只是演示了Mockito的一小部分功能，它还有更多、更强大的功能，我这里不将一一介绍。更多API请参考官方文档注解使用在我们的工程中，90%的情况都是基于Spring，使用JUnit作为单元测试框架，我们看看Mockito怎么与它们结合一起使用。看一个完整的JUnit单元测试类的例子（假设InjectMockService依赖MockServiceA和SpyServiceB）12345678910111213141516171819202122232425262728293031@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = &#123; "classpath*:applicationContext.xml" &#125;)public class MockitoTest &#123; @Autowired private CommonService commonService; @Mock private MockServiceA mockServiceA; @Autowired @Spy private SpyServiceB spyServiceB; @Autowired @InjectMocks private InjectMockService injectMockService; @Before public void mockInit()&#123; MockitoAnnotations.initMocks(this); MockServiceData(); //...and so on &#125; private void MockServiceData() &#123; Object mockDataYouWantReturn = generateMockData(); Mockito.when(mockServiceA.methodYouWantMock()).thenReturn(mockDataYouWantReturn); &#125;&#125;上述代码是我瞎编的，没有跑过。不过一般的使用场景也应该长的类似。对Mockito的注解说明一下：@Mock，你需要mock的对象，其原理跟上述提到的Mockito.mock(List.class);差不多，即把注解标记的这个对象转换成Mockito的对象@Spy，你需要进行部分mock的对象。这个Spy（翻译就是间谍啦）跟Mock相比，Mock是对对象的所有方法都进行mock处理的，即方法不会真正的执行，举之前的那个例子，mockedList.add(&quot;one&quot;);执行后不会把“one”加入到List中，但如果mockedList是一个Spy的话就可以，即把Mockito.mock(List.class);改为Mockito.spy(ArrayList.class);，那么add方法就会真正的执行，这里把List改为ArrayList是因为如果遇到abstract方法也不会执行的。Spy是有使用场景的，当我们需要mock一部分方法，而另外的方法需要正常执行时就需要用到Spy了，不然你就要mock全部用到的方法了@InjectMocks，你需要注入@Mock对象的对象，即@InjectMocks这个对象依赖其他mock对象。这个有点像依赖注入，它就是用来解决这个问题的。举个例子说明，ServiceB依赖ServiceA，你是需要测试ServiceB中的某个方法，但是这个方法依赖到ServiceA了，ServiceA的返回你不可控，你需要mock它，这时就要把@Mock作用于ServiceA，@InjectMocks作用于ServiceB。注意踩坑这是我在使用Mockito遇到的一些坑，希望大家在实践中也注意一下。@InjectMocks@InjectMocks的作用是把@Mock的对象注入到属性中去，我们如果只写成（假设InjectMockService依赖MockServiceA）12345 @InjectMocksprivate InjectMockService injectMockService; @Mock private MockServiceA mockServiceA;这样的话，虽然InjectMockService会做初始化，而且MockServiceA会被注入到InjectMockService里，但是InjectMockService中其他的依赖对象会为null，因为你都没做其他初始化动作嘛。这时你就需要跟Spring的注入一起用，加上@Autowired注解，如下所示123 @InjectMocks @Autowiredprivate InjectMockService injectMockService;从上Mockito的初始化得知，即上述代码的mockInit()方法，Mockito的初始化是在Spring的后面的，所以InjectMockService会被Spring初始化，然后再被Mockito修改依赖的Mock对象。深层次对象实际应用时，如果你想mock的对象在比较深的调用层次，那么做法可以是：获取依赖这个对象的对象（通过Spring的@Autowired），即mock对象的上一层对象，然后使用一些手段把mock对象替换调。例如使用ReflectionTestUtils.setField(upperObject, &quot;fieldName&quot;, mockObject);把mock设置进去替换掉原来的对象。Spy对象执行报错在上面的例子介绍的用法中Mockito.when(mockedList.get(1)).thenReturn(&quot;13&quot;);但是如果mockedList是一个Spy对象的话，可能会有问题。这是因为@Spy对象会真正的实际执行该方法（@Mock则不会），但这是你要mock的方法，那么就有可能有问题。所以如果你不想方法实际执行，需要改变一下用法：//不会调用stub的方法Mockito.doReturn(false).when(spyJack).go();与Spring AOP如果你Mock的对象被Spring AOP进行过处理，例如加了@Transactional或者自己做了切面等等，这时Spring会生成代理对象，这时要注意对你Mock对象有没有产生影响。实现原理源码基于Mockito2.18.3版本。上面介绍了Mockito的基本用法及注意事项。通过API的使用，大家一定很好奇Mockito究竟是怎么实现的。我们先尝试通过表象来推测其实现原理，然后再分析代码证实猜想。表象猜测如果你有多做测试，细心观察，就会发现通过Mockito生成的mock对象是一个“假”对象。对于文章开头的例子，我们可以发现mockedList.add(&quot;one&quot;);不会实际往list增加一个“one”的元素（Spy则会），所以add之后你再get也是得不到结果的。即你无论怎么操作list都是徒劳的。Mockito.verify(mockedList).add(&quot;one&quot;);这句很明显就是会校验list之前执行过的方法及入参。Mockito.when(mockedList.get(1)).thenReturn(&quot;13&quot;);这句看上有点奇怪，怎么会用mockedList.get(1)作为入参呢？其实想想就知道不可能的，所以这里应该也是跟上面一样，只是get方法做了记录，然后再return值。生成Mock对象通过上面的猜测，我们很容易猜到Mockito用了代理生成了mock对象。我们直接跟踪Mockito.mock方法，到MockitoCore的mock方法1234567891011public &lt;T&gt; T mock(Class&lt;T&gt; typeToMock, MockSettings settings) &#123; if (!MockSettingsImpl.class.isInstance(settings)) &#123; throw new IllegalArgumentException("Unexpected implementation of '" + settings.getClass().getCanonicalName() + "'\n" + "At the moment, you cannot provide your own implementations of that class."); &#125; MockSettingsImpl impl = MockSettingsImpl.class.cast(settings); MockCreationSettings&lt;T&gt; creationSettings = impl.build(typeToMock); //创建mock对象 T mock = createMock(creationSettings); mockingProgress().mockingStarted(mock, creationSettings); return mock;&#125;MockUtil的createMock方法123456789101112131415161718192021public static &lt;T&gt; T createMock(MockCreationSettings&lt;T&gt; settings) &#123; //创建一个MockHandler，很关键的一个类 MockHandler mockHandler = createMockHandler(settings); //创建mock对象，这里是调用SubclassByteBuddyMockMaker的createMock T mock = mockMaker.createMock(settings, mockHandler); Object spiedInstance = settings.getSpiedInstance(); if (spiedInstance != null) &#123; new LenientCopyTool().copyToMock(spiedInstance, mock); &#125; return mock;&#125;//MockHandlerFactory//这里包了很多层，但是handle最终是调用MockHandlerImpl的handle方法//MockHandlerImpl是核心中核心类，等下会讲到public static &lt;T&gt; MockHandler&lt;T&gt; createMockHandler(MockCreationSettings&lt;T&gt; settings) &#123; MockHandler&lt;T&gt; handler = new MockHandlerImpl&lt;T&gt;(settings); MockHandler&lt;T&gt; nullResultGuardian = new NullResultGuardian&lt;T&gt;(handler); return new InvocationNotifierHandler&lt;T&gt;(nullResultGuardian, settings);&#125;SubclassByteBuddyMockMaker123456789101112131415161718192021222324252627282930@Overridepublic &lt;T&gt; T createMock(MockCreationSettings&lt;T&gt; settings, MockHandler handler) &#123; //生成代理类，调用SubclassBytecodeGenerator的mockClass Class&lt;? extends T&gt; mockedProxyType = createMockType(settings); Instantiator instantiator = Plugins.getInstantiatorProvider().getInstantiator(settings); T mockInstance = null; try &#123; //为代理类生成实例对象 mockInstance = instantiator.newInstance(mockedProxyType); MockAccess mockAccess = (MockAccess) mockInstance; //MockMethodInterceptor-代理类的拦截器 mockAccess.setMockitoInterceptor(new MockMethodInterceptor(handler, settings)); return ensureMockIsAssignableToMockedType(settings, mockInstance); &#125; catch (ClassCastException cce) &#123; throw new MockitoException(join( "ClassCastException occurred while creating the mockito mock :", " class to mock : " + describeClass(settings.getTypeToMock()), " created class : " + describeClass(mockedProxyType), " proxy instance class : " + describeClass(mockInstance), " instance creation by : " + instantiator.getClass().getSimpleName(), "", "You might experience classloading issues, please ask the mockito mailing-list.", "" ), cce); &#125; catch (org.mockito.creation.instance.InstantiationException e) &#123; throw new MockitoException("Unable to create mock instance of type '" + mockedProxyType.getSuperclass().getSimpleName() + "'", e); &#125;&#125;SubclassBytecodeGenerator1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556@Overridepublic &lt;T&gt; Class&lt;? extends T&gt; mockClass(MockFeatures&lt;T&gt; features) &#123; String name = nameFor(features.mockedType); DynamicType.Builder&lt;T&gt; builder = byteBuddy.subclass(features.mockedType) .name(name) .ignoreAlso(isGroovyMethod()) .annotateType(features.stripAnnotations ? new Annotation[0] : features.mockedType.getAnnotations()) .implement(new ArrayList&lt;Type&gt;(features.interfaces)) .method(matcher) .intercept(to(DispatcherDefaultingToRealMethod.class)) .transform(withModifiers(SynchronizationState.PLAIN)) .attribute(features.stripAnnotations ? MethodAttributeAppender.NoOp.INSTANCE : INCLUDING_RECEIVER) .method(isHashCode()) .intercept(to(MockMethodInterceptor.ForHashCode.class)) .method(isEquals()) .intercept(to(MockMethodInterceptor.ForEquals.class)) .serialVersionUid(42L) .defineField("mockitoInterceptor", MockMethodInterceptor.class, PRIVATE) .implement(MockAccess.class) .intercept(FieldAccessor.ofBeanProperty()); if (features.serializableMode == SerializableMode.ACROSS_CLASSLOADERS) &#123; builder = builder.implement(CrossClassLoaderSerializableMock.class) .intercept(to(MockMethodInterceptor.ForWriteReplace.class)); &#125; if (readReplace != null) &#123; builder = builder.defineMethod("readObject", void.class, Visibility.PRIVATE) .withParameters(ObjectInputStream.class) .throwing(ClassNotFoundException.class, IOException.class) .intercept(readReplace); &#125; ClassLoader classLoader = new MultipleParentClassLoader.Builder() .append(features.mockedType) .append(features.interfaces) .append(currentThread().getContextClassLoader()) .append(MockAccess.class, DispatcherDefaultingToRealMethod.class) .append(MockMethodInterceptor.class, MockMethodInterceptor.ForHashCode.class, MockMethodInterceptor.ForEquals.class).build(MockMethodInterceptor.class.getClassLoader()); if (classLoader != features.mockedType.getClassLoader()) &#123; assertVisibility(features.mockedType); for (Class&lt;?&gt; iFace : features.interfaces) &#123; assertVisibility(iFace); &#125; builder = builder.ignoreAlso(isPackagePrivate() .or(returns(isPackagePrivate())) .or(hasParameters(whereAny(hasType(isPackagePrivate()))))); &#125; return builder.make() .load(classLoader, loader.resolveStrategy(features.mockedType, classLoader, name.startsWith(CODEGEN_PACKAGE))) .getLoaded();&#125;生成代理类的关键代码。Mockito使用的是ByteBuddy这个框架，它并不需要编译器的帮助，而是直接生成class，然后使用ClassLoader来进行加载，感兴趣的可以深入研究，其地址为:https://github.com/raphw/byte-buddy。如果你有使用过其他字节码生成框架，如Cglib或Javassist，就可以大概猜到这里做了什么事情。这里很重要的一点就是把MockMethodInterceptor作为代理类的拦截器。最后就是生成字节码然后动态加载到JVM中。Mockito生成的代理类那么Mockito利用ByteBuddy生成的代理类是长怎么样子的，才能知道它是怎么做拦截的。就好像你看到JDK Proxy生成的代理类，就会更清楚InvocationHandler的实现一样。还是文章开头的例子我们可以看到几点关键的持有一个MockMethodInterceptor对象继承了MockAccessList原来的方法都被DispatcherDefaultingToRealMethod拦截了代理拦截interceptor好，我们现在有目标了。DispatcherDefaultingToRealMethod是MockMethodInterceptor的内部类，最终它还是调用MockMethodInterceptor的doIntercept12345678910Object doIntercept(Object mock, Method invokedMethod, Object[] arguments, RealMethod realMethod, Location location) throws Throwable &#123; //最终调用的是MockHandler的handle方法 //MockHandler最终还是调用MockHandlerImpl的，上面提过了。 //MockHandlerImpl是核心，下面会讲 return handler.handle(createInvocation(mock, invokedMethod, arguments, realMethod, mockCreationSettings, location));&#125;verify说了mock对象是如何生成的，就可以开始说用法的实现了。上面我们猜测verify是对调用做了记录，下面我们来证实一下。verify startMockito的verify12345678910@CheckReturnValuepublic static &lt;T&gt; T verify(T mock) &#123; return MOCKITO_CORE.verify(mock, times(1));&#125;@CheckReturnValuepublic static VerificationMode times(int wantedNumberOfInvocations) &#123; //通过VerificationModeFactory创建了一个VerificationMode //VerificationMode在verify行为中是一个重要的概念。这里times表示次数，因为verify还可以校验调用了多少次 return VerificationModeFactory.times(wantedNumberOfInvocations);&#125;VerificationMode有很多中类型，代表了verify的种类。从名字中大概可以猜到有什么用，大家可以去尝试一下。继续跟踪verify到MockitoCore的verify1234567891011121314151617181920public &lt;T&gt; T verify(T mock, VerificationMode mode) &#123; if (mock == null) &#123; throw nullPassedToVerify(); &#125; MockingDetails mockingDetails = mockingDetails(mock); if (!mockingDetails.isMock()) &#123; throw notAMockPassedToVerify(mock.getClass()); &#125; MockHandler handler = mockingDetails.getMockHandler(); //通知listener mock = (T) VerificationStartedNotifier.notifyVerificationStarted( handler.getMockSettings().getVerificationStartedListeners(), mockingDetails); //初始化ThreadLocal，这里是MockingProgressImpl。这个对象的作用可以理解为mock的“进度”，无论verify还是stub都经过它 MockingProgress mockingProgress = mockingProgress(); VerificationMode actualMode = mockingProgress.maybeVerifyLazily(mode); //标记verify开始。new一个MockAwareVerificationMode，实际还是开头创建的那个VerificationMode，只是封装了一下。 mockingProgress.verificationStarted(new MockAwareVerificationMode(mock, actualMode, mockingProgress.verificationListeners())); return mock;&#125;MockingProgressImpl的verificationStarted12345678public void verificationStarted(VerificationMode verify) &#123; //校验一下状态 validateState(); //还会重置stub resetOngoingStubbing(); //把MockingProgressImpl的verificationMode设置为开头创建的那个 verificationMode = new Localized(verify);&#125;这里注意，MockingProgressImpl是ThreadLocal的，而且它的verificationMode只有一个，就说明verify之后紧接着的mock调用就是针对这次verify的，如果多次verify的话，后者会覆盖前者。verify start就这么多了，最重要的就是记录VerificationMode。verify match记录了VerificationMode，那么如果下次调用怎么去匹配是刚刚的verify的呢？上面说了所有mock对象的方法调用都会被MockMethodInterceptor拦截，而MockMethodInterceptor最终会调到MockHandlerImpl的handle方法，一直憋了很久的MockHandlerImpl终于要出场了。这里除了verify，还有stub的，因为这个方法是包含了mock相关的所有核心逻辑了。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283//Invocation即InterceptedInvocation，把代理类拦截时的方法调用即参数封装在一起//它包含一下几个对象：真正的方法realMethod，Mockito的方法MockitoMethod，参数arguments，以及mock对象mockRef/** private final MockReference&lt;Object&gt; mockRef; private final MockitoMethod mockitoMethod; private final Object[] arguments, rawArguments; private final RealMethod realMethod;*/public Object handle(Invocation invocation) throws Throwable &#123; //stub if (invocationContainer.hasAnswersForStubbing()) &#123; // stubbing voids with doThrow() or doAnswer() style InvocationMatcher invocationMatcher = matchersBinder.bindMatchers( mockingProgress().getArgumentMatcherStorage(), invocation ); invocationContainer.setMethodForStubbing(invocationMatcher); return null; &#125; //获取VerificationMode，VerificationMode至多一个 VerificationMode verificationMode = mockingProgress().pullVerificationMode(); InvocationMatcher invocationMatcher = matchersBinder.bindMatchers( mockingProgress().getArgumentMatcherStorage(), invocation ); //校验状态，如果处于不争取的状态，会抛异常 mockingProgress().validateState(); //如果之前调用过verify方法的话，这里就不为null // if verificationMode is not null then someone is doing verify() if (verificationMode != null) &#123; // We need to check if verification was started on the correct mock // - see VerifyingWithAnExtraCallToADifferentMockTest (bug 138) if (((MockAwareVerificationMode) verificationMode).getMock() == invocation.getMock()) &#123; VerificationDataImpl data = createVerificationData(invocationContainer, invocationMatcher); //最终调用VerificationMode的verify去验证 verificationMode.verify(data); return null; &#125; else &#123; // this means there is an invocation on a different mock. Re-adding verification mode // - see VerifyingWithAnExtraCallToADifferentMockTest (bug 138) mockingProgress().verificationStarted(verificationMode); &#125; &#125; //下面的代码等下会讲到 // prepare invocation for stubbing invocationContainer.setInvocationForPotentialStubbing(invocationMatcher); OngoingStubbingImpl&lt;T&gt; ongoingStubbing = new OngoingStubbingImpl&lt;T&gt;(invocationContainer); //记下ongoingStubbing，每次调用都会刷新最新的ongoingStubbing mockingProgress().reportOngoingStubbing(ongoingStubbing); // look for existing answer for this invocation StubbedInvocationMatcher stubbing = invocationContainer.findAnswerFor(invocation); notifyStubbedAnswerLookup(invocation, stubbing); if (stubbing != null) &#123; stubbing.captureArgumentsFrom(invocation); try &#123; //这里是对stub的返回，即thenReturn的返回，下面的代码会讲到 return stubbing.answer(invocation); &#125; finally &#123; //Needed so that we correctly isolate stubbings in some scenarios //see MockitoStubbedCallInAnswerTest or issue #1279 mockingProgress().reportOngoingStubbing(ongoingStubbing); &#125; &#125; else &#123; //下面代码意思是对mock对象的默认返回 //测试中我们知道，mock对象的每一个操作都是“无效”的，而且都会返回一个相应类型的默认值（stub除外）。 Object ret = mockSettings.getDefaultAnswer().answer(invocation); DefaultAnswerValidator.validateReturnValueFor(invocation, ret); //Mockito uses it to redo setting invocation for potential stubbing in case of partial mocks / spies. //Without it, the real method inside 'when' might have delegated to other self method //and overwrite the intended stubbed method with a different one. //This means we would be stubbing a wrong method. //Typically this would led to runtime exception that validates return type with stubbed method signature. invocationContainer.resetInvocationForPotentialStubbing(invocationMatcher); return ret; &#125; &#125;好，我们看看Times这个VerificationMode的verify方法12345678910111213@Overridepublic void verify(VerificationData data) &#123; //获取所有的调用 List&lt;Invocation&gt; invocations = data.getAllInvocations(); //获取的verify的调用 MatchableInvocation wanted = data.getTarget(); if (wantedCount &gt; 0) &#123; //两者做匹配 checkMissingInvocation(data.getAllInvocations(), data.getTarget()); &#125; checkNumberOfInvocations(invocations, wanted, wantedCount);&#125;MissingInvocationChecker123456789101112131415161718public static void checkMissingInvocation(List&lt;Invocation&gt; invocations, MatchableInvocation wanted) &#123; //匹配所有的调用和目标调用 List&lt;Invocation&gt; actualInvocations = findInvocations(invocations, wanted); //如果找到则“安全”返回return if (!actualInvocations.isEmpty())&#123; return; &#125; //否则会抛出异常 Invocation similar = findSimilarInvocation(invocations, wanted); if (similar == null) &#123; throw wantedButNotInvoked(wanted, invocations); &#125; Integer[] indexesOfSuspiciousArgs = getSuspiciouslyNotMatchingArgsIndexes(wanted.getMatchers(), similar.getArguments()); SmartPrinter smartPrinter = new SmartPrinter(wanted, similar, indexesOfSuspiciousArgs); throw argumentsAreDifferent(smartPrinter.getWanted(), smartPrinter.getActual(), similar.getLocation());&#125;通过调试发现在InvocationMatcher判断两个Invocation是否匹配12345@Override public boolean matches(Invocation candidate) &#123; //可以看出就是通过判断mock对象是否一样，方法及参数是否一样 return invocation.getMock().equals(candidate.getMock()) &amp;&amp; hasSameMethod(candidate) &amp;&amp; argumentsMatch(candidate); &#125;verify的过程就是这样了，如果找到匹配的Invocation则正常返回，找不到Mockito是会抛出异常提示信息，像assert那样子，大家可以尝试一下。stubstub就是可以指定返回，一般我们用的更多，从上面verify的实现过程，我们应该也能大概猜到stub也有点类似。when跟踪when方法直到MockitoCore的when123456789101112131415public &lt;T&gt; OngoingStubbing&lt;T&gt; when(T methodCall) &#123; //初始化MockingProgressImpl MockingProgress mockingProgress = mockingProgress(); //标记stub开始 mockingProgress.stubbingStarted(); //获取最新的ongoingStubbing，这个ongoingStubbing会在每次MockHandlerImpl的handle都会新建一个，然后set到ThreadLocal的mockingProgress中，所以这里取出来的就是上一次的调用，这里也证明了其实when的参数是没用的，只要mock对象有方法调用就可以了。 @SuppressWarnings("unchecked") OngoingStubbing&lt;T&gt; stubbing = (OngoingStubbing&lt;T&gt;) mockingProgress.pullOngoingStubbing(); if (stubbing == null) &#123; mockingProgress.reset(); throw missingMethodInvocation(); &#125; //返回OngoingStubbing return stubbing;&#125;when方法就是返回上次mock方法调用封装好的OngoingStubbing。thenReturnthenReturn是BaseStubbing的方法，其实它也是一个OngoingStubbingOngoingStubbing的继承关系123456789101112131415161718192021222324252627282930313233343536@Overridepublic OngoingStubbing&lt;T&gt; thenReturn(T value) &#123; return thenAnswer(new Returns(value));&#125;//OngoingStubbingImpl@Overridepublic OngoingStubbing&lt;T&gt; thenAnswer(Answer&lt;?&gt; answer) &#123; if(!invocationContainer.hasInvocationForPotentialStubbing()) &#123; throw incorrectUseOfApi(); &#125; //把这个answer加入到 invocationContainer.addAnswer(answer); return new ConsecutiveStubbing&lt;T&gt;(invocationContainer);&#125;//InvocationContainerImplpublic StubbedInvocationMatcher addAnswer(Answer answer, boolean isConsecutive) &#123; //获取stub的调用 Invocation invocation = invocationForStubbing.getInvocation(); //标记stub完成 mockingProgress().stubbingCompleted(); if (answer instanceof ValidableAnswer) &#123; ((ValidableAnswer) answer).validateFor(invocation); &#125; //把stub的调用和answer加到StubbedInvocationMatcher的list //这里的意思就是把调用和返回绑定，如果下次调用匹配到了，就返回对应的answer synchronized (stubbed) &#123; if (isConsecutive) &#123; stubbed.getFirst().addAnswer(answer); &#125; else &#123; stubbed.addFirst(new StubbedInvocationMatcher(invocationForStubbing, answer)); &#125; return stubbed.getFirst(); &#125;&#125;那么下次的调用怎么匹配到answer呢？还是在MockHandlerImpl的handle，这里只截图相关代码12345678910111213141516171819202122if (stubbing != null) &#123; stubbing.captureArgumentsFrom(invocation); try &#123; //就是返回stub的answer方法 return stubbing.answer(invocation); &#125; finally &#123; //Needed so that we correctly isolate stubbings in some scenarios //see MockitoStubbedCallInAnswerTest or issue #1279 mockingProgress().reportOngoingStubbing(ongoingStubbing); &#125; &#125;//StubbedInvocationMatcherpublic Object answer(InvocationOnMock invocation) throws Throwable &#123; //see ThreadsShareGenerouslyStubbedMockTest Answer a; //从之前放进来的answers获取最新的那个 synchronized(answers) &#123; a = answers.size() == 1 ? answers.peek() : answers.poll(); &#125; return a.answer(invocation);&#125;先看看Answer的继承关系，看看Mockito支持什么样的对stub的返回我们用回刚刚的例子，对应的Answer就是Returns1234public Object answer(InvocationOnMock invocation) throws Throwable &#123; //就是直接返回我们指定的值 return value;&#125;优点Mockito最大的优点是其简单，实用，优雅的API，这是作者的初衷。Java的Mock工具还有JMock，easymock等等，大家可以对比一下。总结本文介绍了Mockito的基本使用及注意事项，相信看了之后你已经可以在日常工作中用上。还源码分析了其实现mock的原理，通过源码看到，表面看上去挺神奇的一个东西，其实现也不是很难的，主要用到代理+状态来控制mock对象。参考资料https://infoq.cn/article/mockito-designhttps://blog.saymagic.cn/2016/09/17/understand-mockito.html]]></content>
      <categories>
        <category>java</category>
        <category>mockito</category>
      </categories>
      <tags>
        <tag>mockito</tag>
        <tag>mock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Excel大批量导入导出解决方案]]></title>
    <url>%2Fposts%2Fd093ca4e%2F</url>
    <content type="text"><![CDATA[概要Java对Excel的操作一般都是用POI，但是数据量大的话可能会导致频繁的FGC或OOM，这篇文章跟大家说下如果避免踩POI的坑，以及分别对于xls和xlsx文件怎么优化大批量数据的导入和导出。一次线上问题这是一次线上的问题，因为一个大数据量的Excel导出功能，而导致服务器频繁FGC，具体如图所示可以看出POI的对象以及相关的XML对象占用了绝大部分的内存消耗，频繁FGC说明这些对象一直存活，没有被回收。原因是由于导出的数据比较大量，大概有10w行 * 50列，由于后台直接用XSSFWorkbook导出，在导出结束前内存有大量的Row，Cell，Style等，以及基于XLSX底层存储的XML对象没有被释放。Excel的存储格式下面的优化内容涉及Excel的底层存储格式，所以要先跟大家讲一下。XLS03版的XLS采用的是一种名为BIFF8(Binary-Interchange-File-Format)，基于OLE2规范的二进制文件格式。大概就是一种结构很复杂的二进制文件，具体细节我也不是很清楚，大家也没必要去了解它，已经被淘汰了。想了解的话可以看看Excel XLS文件格式XLSX07版的XLSX则是采用OOXML(Office Open Xml)的格式存储数据。简单来说就是一堆xml文件用zip打包之后文件。这个对于大家来说就熟悉了，把xlsx文件后缀名改为zip后，再解压出来就可以看到文件结构，对每个文件以及里面内容的意思可以看看Excel 2007（一） - XML存储打开sheet1.xml，可以看到是描述第一个sheet的内容导出优化事例源码基于POI3.17版本XLSX由于xlsx底层使用xml存储，占用内存会比较大，官方也意识到这个问题，在3.8版本之后，提供了SXSSFWorkbook来优化写性能。官方说明使用SXSSFWorkbook使用起来特别的简单，只需要改一行代码就OK了。原来你的代码可能是长这样的1Workbook workbook = new XSSFWorkbook(inputStream);那么你只需要改成这样子，就可以用上SXSSFWorkbook了1Workbook workbook = new SXSSFWorkbook(new XSSFWorkbook(inputStream));原理其原理是可以定义一个window size（默认100），生成Excel期间只在内存维持window size那么多的行数Row，超时window size时会把之前行Row写到一个临时文件并且remove释放掉，这样就可以达到释放内存的效果。SXSSFSheet在创建Row时会判断并刷盘、释放超过window size的Row。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667@Override public SXSSFRow createRow(int rownum) &#123; int maxrow = SpreadsheetVersion.EXCEL2007.getLastRowIndex(); if (rownum &lt; 0 || rownum &gt; maxrow) &#123; throw new IllegalArgumentException("Invalid row number (" + rownum + ") outside allowable range (0.." + maxrow + ")"); &#125; // attempt to overwrite a row that is already flushed to disk if(rownum &lt;= _writer.getLastFlushedRow() ) &#123; throw new IllegalArgumentException( "Attempting to write a row["+rownum+"] " + "in the range [0," + _writer.getLastFlushedRow() + "] that is already written to disk."); &#125; // attempt to overwrite a existing row in the input template if(_sh.getPhysicalNumberOfRows() &gt; 0 &amp;&amp; rownum &lt;= _sh.getLastRowNum() ) &#123; throw new IllegalArgumentException( "Attempting to write a row["+rownum+"] " + "in the range [0," + _sh.getLastRowNum() + "] that is already written to disk."); &#125; SXSSFRow newRow=new SXSSFRow(this); _rows.put(rownum,newRow); allFlushed = false; //如果大于窗口的size，就会flush if(_randomAccessWindowSize&gt;=0&amp;&amp;_rows.size()&gt;_randomAccessWindowSize) &#123; try &#123; flushRows(_randomAccessWindowSize); &#125; catch (IOException ioe) &#123; throw new RuntimeException(ioe); &#125; &#125; return newRow; &#125; public void flushRows(int remaining) throws IOException &#123; //flush每一个row while(_rows.size() &gt; remaining) &#123; flushOneRow(); &#125; if (remaining == 0) &#123; allFlushed = true; &#125; &#125; private void flushOneRow() throws IOException &#123; Integer firstRowNum = _rows.firstKey(); if (firstRowNum!=null) &#123; int rowIndex = firstRowNum.intValue(); SXSSFRow row = _rows.get(firstRowNum); // Update the best fit column widths for auto-sizing just before the rows are flushed _autoSizeColumnTracker.updateColumnWidths(row); //写盘 _writer.writeRow(rowIndex, row); //然后把row remove掉，这里的_rows是一个TreeMap结构 _rows.remove(firstRowNum); lastFlushedRowNumber = rowIndex; &#125; &#125;我们再看看刷盘的具体操作SXSSFSheet在创建的时候，都会创建一个SheetDataWriter，刷盘动作正是由这个类完成的看下SheetDataWriter的初始化1234567891011121314151617181920212223242526272829303132public SheetDataWriter() throws IOException &#123; //创建临时文件 _fd = createTempFile(); //拿到文件的BufferedWriter _out = createWriter(_fd);&#125;//在本地创建了一个临时文件前缀为poi-sxssf-sheet，后缀为.xmlpublic File createTempFile() throws IOException &#123; return TempFile.createTempFile("poi-sxssf-sheet", ".xml");&#125;public static File createTempFile(String prefix, String suffix) throws IOException &#123; //用一个策略去创建文件 return strategy.createTempFile(prefix, suffix);&#125;//这个策略就是在执行路径先创建一个目录（如果不存在的话），然后再在里面创建一个随机唯一命名的文件public File createTempFile(String prefix, String suffix) throws IOException &#123; // Identify and create our temp dir, if needed createPOIFilesDirectory(); // Generate a unique new filename File newFile = File.createTempFile(prefix, suffix, dir); // Set the delete on exit flag, unless explicitly disabled if (System.getProperty(KEEP_FILES) == null) &#123; newFile.deleteOnExit(); &#125; // All done return newFile;&#125;POI就是把超过window size的Row刷到临时文件里，然后再把临时文件转为正常的xlsx文件格式输出。我们看看刷盘时写了什么，SheetDataWriter的writeRow方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135public void writeRow(int rownum, SXSSFRow row) throws IOException &#123; if (_numberOfFlushedRows == 0) _lowestIndexOfFlushedRows = rownum; _numberLastFlushedRow = Math.max(rownum, _numberLastFlushedRow); _numberOfCellsOfLastFlushedRow = row.getLastCellNum(); _numberOfFlushedRows++; beginRow(rownum, row); Iterator&lt;Cell&gt; cells = row.allCellsIterator(); int columnIndex = 0; while (cells.hasNext()) &#123; writeCell(columnIndex++, cells.next()); &#125; endRow();&#125;void beginRow(int rownum, SXSSFRow row) throws IOException &#123; _out.write("&lt;row"); writeAttribute("r", Integer.toString(rownum + 1)); if (row.hasCustomHeight()) &#123; writeAttribute("customHeight", "true"); writeAttribute("ht", Float.toString(row.getHeightInPoints())); &#125; if (row.getZeroHeight()) &#123; writeAttribute("hidden", "true"); &#125; if (row.isFormatted()) &#123; writeAttribute("s", Integer.toString(row.getRowStyleIndex())); writeAttribute("customFormat", "1"); &#125; if (row.getOutlineLevel() != 0) &#123; writeAttribute("outlineLevel", Integer.toString(row.getOutlineLevel())); &#125; if(row.getHidden() != null) &#123; writeAttribute("hidden", row.getHidden() ? "1" : "0"); &#125; if(row.getCollapsed() != null) &#123; writeAttribute("collapsed", row.getCollapsed() ? "1" : "0"); &#125; _out.write("&gt;\n"); this._rownum = rownum;&#125;void endRow() throws IOException &#123; _out.write("&lt;/row&gt;\n");&#125;public void writeCell(int columnIndex, Cell cell) throws IOException &#123; if (cell == null) &#123; return; &#125; String ref = new CellReference(_rownum, columnIndex).formatAsString(); _out.write("&lt;c"); writeAttribute("r", ref); CellStyle cellStyle = cell.getCellStyle(); if (cellStyle.getIndex() != 0) &#123; // need to convert the short to unsigned short as the indexes can be up to 64k // ideally we would use int for this index, but that would need changes to some more // APIs writeAttribute("s", Integer.toString(cellStyle.getIndex() &amp; 0xffff)); &#125; CellType cellType = cell.getCellTypeEnum(); switch (cellType) &#123; case BLANK: &#123; _out.write('&gt;'); break; &#125; case FORMULA: &#123; _out.write("&gt;&lt;f&gt;"); outputQuotedString(cell.getCellFormula()); _out.write("&lt;/f&gt;"); switch (cell.getCachedFormulaResultTypeEnum()) &#123; case NUMERIC: double nval = cell.getNumericCellValue(); if (!Double.isNaN(nval)) &#123; _out.write("&lt;v&gt;"); _out.write(Double.toString(nval)); _out.write("&lt;/v&gt;"); &#125; break; default: break; &#125; break; &#125; case STRING: &#123; if (_sharedStringSource != null) &#123; XSSFRichTextString rt = new XSSFRichTextString(cell.getStringCellValue()); int sRef = _sharedStringSource.addEntry(rt.getCTRst()); writeAttribute("t", STCellType.S.toString()); _out.write("&gt;&lt;v&gt;"); _out.write(String.valueOf(sRef)); _out.write("&lt;/v&gt;"); &#125; else &#123; writeAttribute("t", "inlineStr"); _out.write("&gt;&lt;is&gt;&lt;t"); if (hasLeadingTrailingSpaces(cell.getStringCellValue())) &#123; writeAttribute("xml:space", "preserve"); &#125; _out.write("&gt;"); outputQuotedString(cell.getStringCellValue()); _out.write("&lt;/t&gt;&lt;/is&gt;"); &#125; break; &#125; case NUMERIC: &#123; writeAttribute("t", "n"); _out.write("&gt;&lt;v&gt;"); _out.write(Double.toString(cell.getNumericCellValue())); _out.write("&lt;/v&gt;"); break; &#125; case BOOLEAN: &#123; writeAttribute("t", "b"); _out.write("&gt;&lt;v&gt;"); _out.write(cell.getBooleanCellValue() ? "1" : "0"); _out.write("&lt;/v&gt;"); break; &#125; case ERROR: &#123; FormulaError error = FormulaError.forInt(cell.getErrorCellValue()); writeAttribute("t", "e"); _out.write("&gt;&lt;v&gt;"); _out.write(error.getString()); _out.write("&lt;/v&gt;"); break; &#125; default: &#123; throw new IllegalStateException("Invalid cell type: " + cellType); &#125; &#125; _out.write("&lt;/c&gt;");&#125;可以看到临时文件里内容跟xlsx的文件格式是保持一致的。测试本地测试使用SXSSFWorkbook导出30w行 * 10列内存使用情况可以看出内存有被回收的情况，比较平稳。XLSPOI没有像XLSX那样对XLS的写做出性能的优化，原因是：官方认为XLS的不像XLSX那样占内存XLS一个Sheet最多也只能有65535行数据导入优化POI对导入分为3种模式，用户模式User Model，事件模式Event Model，还有Event User Model。用户模式（User Model）就类似于dom方式的解析，是一种high level api，给人快速、方便开发用的。缺点是一次性将文件读入内存，构建一颗Dom树。并且在POI对Excel的抽象中，每一行，每一个单元格都是一个对象。当文件大，数据量多的时候对内存的占用可想而知。用户模式就是类似用 WorkbookFactory.create(inputStream)，poi 会把整个文件一次性解析，生成全部的Sheet，Row，Cell以及对象，如果导入文件数据量大的话，也很可能会导致OOM。本地测试用户模式读取XLSX文件，数据量10w行 * 50列，内存使用如下事件模式（Event Model）就是SAX解析。Event Model使用的方式是边读取边解析，并且不会将这些数据封装成Row，Cell这样的对象。而都只是普通的数字或者是字符串。并且这些解析出来的对象是不需要一直驻留在内存中，而是解析完使用后就可以回收。所以相比于User Model，Event Model更节省内存，效率也更。但是作为代价，相比User Model功能更少，门槛也要高一些。我们需要去学习Excel存储数据的各个Xml中每个标签，标签中的属性的含义，然后对解析代码进行设计。User Event Model也是采用流式解析，但是不同于Event Model，POI基于Event Model为我们封装了一层。我们不再面对Element的事件编程,而是面向StartRow，EndRow，Cell等事件编程。而提供的数据，也不再像之前是原始数据，而是全部格式化好，方便开发者开箱即用。大大简化了我们的开发效率。XLSXPOI对XLSX支持Event Model和Event User ModelXLSX的Event Model使用最直接，权威就是参考官网例子简单来说就是需要继承DefaultHandler，覆盖其startElement，endElement方法。然后方法里获取你想要的数据。原理DefaultHandler相信熟悉的人都知道，这是JDK自带的对XML的SAX解析用到处理类，POI在进行SAX解析时，把读取到每个XML的元素时则会回调这两个方法，然后我们就可以获取到想用的数据了。我们回忆一下上面说到的XLSX存储格式中sheet存储数据的格式。再看看官方例子中的解析过程123456789101112131415161718192021222324252627282930313233343536373839@Overridepublic void startElement(String uri, String localName, String name, Attributes attributes) throws SAXException &#123; //c代表是一个单元格cell，判断c这个xml元素里面属性attribute t // c =&gt; cell if(name.equals("c")) &#123; // Print the cell reference System.out.print(attributes.getValue("r") + " - "); // Figure out if the value is an index in the SST String cellType = attributes.getValue("t"); nextIsString = cellType != null &amp;&amp; cellType.equals("s"); inlineStr = cellType != null &amp;&amp; cellType.equals("inlineStr"); &#125; // Clear contents cache lastContents = "";&#125;@Overridepublic void endElement(String uri, String localName, String name) throws SAXException &#123; // Process the last contents as required. // Do now, as characters() may be called more than once if(nextIsString) &#123; Integer idx = Integer.valueOf(lastContents); lastContents = lruCache.get(idx); if (lastContents == null &amp;&amp; !lruCache.containsKey(idx)) &#123; lastContents = new XSSFRichTextString(sst.getEntryAt(idx)).toString(); lruCache.put(idx, lastContents); &#125; nextIsString = false; &#125; //v 元素代表这个cell的内容 // v =&gt; contents of a cell // Output after we've seen the string contents if(name.equals("v") || (inlineStr &amp;&amp; name.equals("c"))) &#123; System.out.println(lastContents); &#125;&#125;可以看出你需要对XLSX的XML格式清楚，才能获取到你想要的东西。XLSX的Event User Model使用官方例子简单来说就是继承XSSFSheetXMLHandler.SheetContentsHandler，覆盖其startRow，endRow，cell，endSheet 等方法。POI每开始读行，结束读行，读取一个cell，结束读取一个sheet时回调的方法。从方法名上看Event User Model有更好的用户体验。原理其实Event User Model也是 Event Model的封装，在XSSFSheetXMLHandler（其实也是一个DefaultHandler来的）中持有一个SheetContentsHandler，在其startElement，endElement方法中会调用SheetContentsHandler的startRow，endRow，cell，endSheet等方法。我们看看XSSFSheetXMLHandler的startElement和endElement方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105 public void startElement(String uri, String localName, String qName, Attributes attributes) throws SAXException &#123; if (uri != null &amp;&amp; ! uri.equals(NS_SPREADSHEETML)) &#123; return; &#125; if (isTextTag(localName)) &#123; vIsOpen = true; // Clear contents cache value.setLength(0); &#125; else if ("is".equals(localName)) &#123; // Inline string outer tag isIsOpen = true; &#125; else if ("f".equals(localName)) &#123; // Clear contents cache formula.setLength(0); // Mark us as being a formula if not already if(nextDataType == xssfDataType.NUMBER) &#123; nextDataType = xssfDataType.FORMULA; &#125; // Decide where to get the formula string from String type = attributes.getValue("t"); if(type != null &amp;&amp; type.equals("shared")) &#123; // Is it the one that defines the shared, or uses it? String ref = attributes.getValue("ref"); String si = attributes.getValue("si"); if(ref != null) &#123; // This one defines it // TODO Save it somewhere fIsOpen = true; &#125; else &#123; // This one uses a shared formula // TODO Retrieve the shared formula and tweak it to // match the current cell if(formulasNotResults) &#123; logger.log(POILogger.WARN, "shared formulas not yet supported!"); &#125; /*else &#123; // It's a shared formula, so we can't get at the formula string yet // However, they don't care about the formula string, so that's ok! &#125;*/ &#125; &#125; else &#123; fIsOpen = true; &#125; &#125; else if("oddHeader".equals(localName) || "evenHeader".equals(localName) || "firstHeader".equals(localName) || "firstFooter".equals(localName) || "oddFooter".equals(localName) || "evenFooter".equals(localName)) &#123; hfIsOpen = true; // Clear contents cache headerFooter.setLength(0); &#125; else if("row".equals(localName)) &#123; String rowNumStr = attributes.getValue("r"); if(rowNumStr != null) &#123; rowNum = Integer.parseInt(rowNumStr) - 1; &#125; else &#123; rowNum = nextRowNum; &#125; //回调了SheetContentsHandler的startRow方法 output.startRow(rowNum); &#125; // c =&gt; cell else if ("c".equals(localName)) &#123; // Set up defaults. this.nextDataType = xssfDataType.NUMBER; this.formatIndex = -1; this.formatString = null; cellRef = attributes.getValue("r"); String cellType = attributes.getValue("t"); String cellStyleStr = attributes.getValue("s"); if ("b".equals(cellType)) nextDataType = xssfDataType.BOOLEAN; else if ("e".equals(cellType)) nextDataType = xssfDataType.ERROR; else if ("inlineStr".equals(cellType)) nextDataType = xssfDataType.INLINE_STRING; else if ("s".equals(cellType)) nextDataType = xssfDataType.SST_STRING; else if ("str".equals(cellType)) nextDataType = xssfDataType.FORMULA; else &#123; // Number, but almost certainly with a special style or format XSSFCellStyle style = null; if (stylesTable != null) &#123; if (cellStyleStr != null) &#123; int styleIndex = Integer.parseInt(cellStyleStr); style = stylesTable.getStyleAt(styleIndex); &#125; else if (stylesTable.getNumCellStyles() &gt; 0) &#123; style = stylesTable.getStyleAt(0); &#125; &#125; if (style != null) &#123; this.formatIndex = style.getDataFormat(); this.formatString = style.getDataFormatString(); if (this.formatString == null) this.formatString = BuiltinFormats.getBuiltinFormat(this.formatIndex); &#125; &#125; &#125;&#125;123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114 @Override public void endElement(String uri, String localName, String qName) throws SAXException &#123; if (uri != null &amp;&amp; ! uri.equals(NS_SPREADSHEETML)) &#123; return; &#125; String thisStr = null; // v =&gt; contents of a cell if (isTextTag(localName)) &#123; vIsOpen = false; // Process the value contents as required, now we have it all switch (nextDataType) &#123; case BOOLEAN: char first = value.charAt(0); thisStr = first == '0' ? "FALSE" : "TRUE"; break; case ERROR: thisStr = "ERROR:" + value; break; case FORMULA: if(formulasNotResults) &#123; thisStr = formula.toString(); &#125; else &#123; String fv = value.toString(); if (this.formatString != null) &#123; try &#123; // Try to use the value as a formattable number double d = Double.parseDouble(fv); thisStr = formatter.formatRawCellContents(d, this.formatIndex, this.formatString); &#125; catch(NumberFormatException e) &#123; // Formula is a String result not a Numeric one thisStr = fv; &#125; &#125; else &#123; // No formatting applied, just do raw value in all cases thisStr = fv; &#125; &#125; break; case INLINE_STRING: // TODO: Can these ever have formatting on them? XSSFRichTextString rtsi = new XSSFRichTextString(value.toString()); thisStr = rtsi.toString(); break; case SST_STRING: String sstIndex = value.toString(); try &#123; int idx = Integer.parseInt(sstIndex); XSSFRichTextString rtss = new XSSFRichTextString(sharedStringsTable.getEntryAt(idx)); thisStr = rtss.toString(); &#125; catch (NumberFormatException ex) &#123; logger.log(POILogger.ERROR, "Failed to parse SST index '" + sstIndex, ex); &#125; break; case NUMBER: String n = value.toString(); if (this.formatString != null &amp;&amp; n.length() &gt; 0) thisStr = formatter.formatRawCellContents(Double.parseDouble(n), this.formatIndex, this.formatString); else thisStr = n; break; default: thisStr = "(TODO: Unexpected type: " + nextDataType + ")"; break; &#125; // Do we have a comment for this cell? checkForEmptyCellComments(EmptyCellCommentsCheckType.CELL); XSSFComment comment = commentsTable != null ? commentsTable.findCellComment(new CellAddress(cellRef)) : null; //回调了SheetContentsHandler的cell方法 // Output output.cell(cellRef, thisStr, comment); &#125; else if ("f".equals(localName)) &#123; fIsOpen = false; &#125; else if ("is".equals(localName)) &#123; isIsOpen = false; &#125; else if ("row".equals(localName)) &#123; // Handle any "missing" cells which had comments attached checkForEmptyCellComments(EmptyCellCommentsCheckType.END_OF_ROW); //回调了SheetContentsHandler的endRow方法 // Finish up the row output.endRow(rowNum); // some sheets do not have rowNum set in the XML, Excel can read them so we should try to read them as well nextRowNum = rowNum + 1; &#125; else if ("sheetData".equals(localName)) &#123; // Handle any "missing" cells which had comments attached checkForEmptyCellComments(EmptyCellCommentsCheckType.END_OF_SHEET_DATA); &#125; else if("oddHeader".equals(localName) || "evenHeader".equals(localName) || "firstHeader".equals(localName)) &#123; hfIsOpen = false; output.headerFooter(headerFooter.toString(), true, localName); &#125; else if("oddFooter".equals(localName) || "evenFooter".equals(localName) || "firstFooter".equals(localName)) &#123; hfIsOpen = false; output.headerFooter(headerFooter.toString(), false, localName); &#125;&#125;代码有点多，一是为了展示一下XSSFSheetXMLHandler解析XML的过程，大家可以粗略看看二是可以看出Event User Model也是Event Model的封装测试本地测试使用Event User Model读取XLSX文件，数据量10w行 * 50列可以看出内存有回收的情况，比User Model好多了。XLSPOI对XLS支持Event Model使用官网例子需要继承HSSFListener，覆盖processRecord 方法，POI每读取到一个单元格的数据则会回调次方法。原理这里涉及BIFF8格式以及POI对其的封装，大家可以了解一下（因为其格式比较复杂，我也不是很清楚）总结POI优化了对XLSX的大批量写，以及支持对XLS和XLSX的SAX读，我们在实际开发时需要根据业务量来选择正确的处理，不然可能会导致OOM。希望这篇文章能给大家启发。另外阿里开源了一个easyexcel，其实做的事情也差不多，大家可以看下。参考资料https://www.jianshu.com/p/6d6772f339cbhttps://poi.apache.org/components/spreadsheet/how-to.html]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>poi</tag>
        <tag>excel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring-Retry重试实现原理]]></title>
    <url>%2Fposts%2F69a9647f%2F</url>
    <content type="text"><![CDATA[概要Spring实现了一套重试机制，功能简单实用。Spring Retry是从Spring Batch独立出来的一个功能，已经广泛应用于Spring Batch,Spring Integration, Spring for Apache Hadoop等Spring项目。本文将讲述如何使用Spring Retry及其实现原理。背景重试，其实我们其实很多时候都需要的，为了保证容错性，可用性，一致性等。一般用来应对外部系统的一些不可预料的返回、异常等，特别是网络延迟，中断等情况。还有在现在流行的微服务治理框架中，通常都有自己的重试与超时配置，比如dubbo可以设置retries=1，timeout=500调用失败只重试1次，超过500ms调用仍未返回则调用失败。如果我们要做重试，要为特定的某个操作做重试功能，则要硬编码，大概逻辑基本都是写个循环，根据返回或异常，计数失败次数，然后设定退出条件。 这样做，且不说每个操作都要写这种类似的代码，而且重试逻辑和业务逻辑混在一起，给维护和扩展带来了麻烦。从面向对象的角度来看，我们应该把重试的代码独立出来。使用介绍基本使用先举个例子：1234567891011121314151617181920212223242526272829303132@Configuration@EnableRetrypublic class Application &#123; @Bean public RetryService retryService()&#123; return new RetryService(); &#125; public static void main(String[] args) throws Exception&#123; ApplicationContext applicationContext = new AnnotationConfigApplicationContext("springretry"); RetryService service1 = applicationContext.getBean("service", RetryService.class); service1.service(); &#125;&#125;@Service("service")public class RetryService &#123; @Retryable(value = IllegalAccessException.class, maxAttempts = 5, backoff= @Backoff(value = 1500, maxDelay = 100000, multiplier = 1.2)) public void service() throws IllegalAccessException &#123; System.out.println("service method..."); throw new IllegalAccessException("manual exception"); &#125; @Recover public void recover(IllegalAccessException e)&#123; System.out.println("service retry after Recover =&gt; " + e.getMessage()); &#125;&#125;@EnableRetry - 表示开启重试机制@Retryable - 表示这个方法需要重试，它有很丰富的参数，可以满足你对重试的需求@Backoff - 表示重试中的退避策略@Recover - 兜底方法，即多次重试后还是失败就会执行这个方法Spring-Retry 的功能丰富在于其重试策略和退避策略，还有兜底，监听器等操作。然后每个注解里面的参数，都是很简单的，大家看一下就知道是什么意思，怎么用了，我就不多讲了。重试策略看一下Spring Retry自带的一些重试策略，主要是用来判断当方法调用异常时是否需要重试。（下文原理部分会深入分析实现）SimpleRetryPolicy默认最多重试3次TimeoutRetryPolicy默认在1秒内失败都会重试ExpressionRetryPolicy符合表达式就会重试CircuitBreakerRetryPolicy增加了熔断的机制，如果不在熔断状态，则允许重试CompositeRetryPolicy可以组合多个重试策略NeverRetryPolicy从不重试（也是一种重试策略哈）AlwaysRetryPolicy总是重试….等等退避策略看一下退避策略，退避是指怎么去做下一次的重试，在这里其实就是等待多长时间。（下文原理部分会深入分析实现）FixedBackOffPolicy默认固定延迟1秒后执行下一次重试ExponentialBackOffPolicy指数递增延迟执行重试，默认初始0.1秒，系数是2，那么下次延迟0.2秒，再下次就是延迟0.4秒，如此类推，最大30秒。ExponentialRandomBackOffPolicy在上面那个策略上增加随机性UniformRandomBackOffPolicy这个跟上面的区别就是，上面的延迟会不停递增，这个只会在固定的区间随机StatelessBackOffPolicy这个说明是无状态的，所谓无状态就是对上次的退避无感知，从它下面的子类也能看出来原理原理部分我想分开两部分来讲，一是重试机制的切入点，即它是如何使得你的代码实现重试功能的；二是重试机制的详细，包括重试的逻辑以及重试策略和退避策略的实现。切入点@EnableRetry12345678910111213141516@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@EnableAspectJAutoProxy(proxyTargetClass = false)@Import(RetryConfiguration.class)@Documentedpublic @interface EnableRetry &#123; /** * Indicate whether subclass-based (CGLIB) proxies are to be created as opposed * to standard Java interface-based proxies. The default is &#123;@code false&#125;. * * @return whether to proxy or not to proxy the class */ boolean proxyTargetClass() default false;&#125;我们可以看到@EnableAspectJAutoProxy(proxyTargetClass = false)这个并不陌生，就是打开Spring AOP功能。重点看看@Import(RetryConfiguration.class)@Import相当于注册这个Bean我们看看这个RetryConfiguration是个什么东西它是一个AbstractPointcutAdvisor，它有一个pointcut和一个advice。我们知道，在IOC过程中会根据PointcutAdvisor类来对Bean进行Pointcut的过滤，然后生成对应的AOP代理类，用advice来加强处理。看看RetryConfiguration的初始化:123456789101112@PostConstruct public void init() &#123; Set&lt;Class&lt;? extends Annotation&gt;&gt; retryableAnnotationTypes = new LinkedHashSet&lt;Class&lt;? extends Annotation&gt;&gt;(1); retryableAnnotationTypes.add(Retryable.class); //创建pointcut this.pointcut = buildPointcut(retryableAnnotationTypes); //创建advice this.advice = buildAdvice(); if (this.advice instanceof BeanFactoryAware) &#123; ((BeanFactoryAware) this.advice).setBeanFactory(beanFactory); &#125; &#125;12345678910111213protected Pointcut buildPointcut(Set&lt;Class&lt;? extends Annotation&gt;&gt; retryAnnotationTypes) &#123; ComposablePointcut result = null; for (Class&lt;? extends Annotation&gt; retryAnnotationType : retryAnnotationTypes) &#123; Pointcut filter = new AnnotationClassOrMethodPointcut(retryAnnotationType); if (result == null) &#123; result = new ComposablePointcut(filter); &#125; else &#123; result.union(filter); &#125; &#125; return result; &#125;上面代码用到了AnnotationClassOrMethodPointcut，其实它最终还是用到了AnnotationMethodMatcher来根据注解进行切入点的过滤。这里就是@Retryable注解了。123456789101112131415161718192021//创建advice对象，即拦截器 protected Advice buildAdvice() &#123; //下面关注这个对象 AnnotationAwareRetryOperationsInterceptor interceptor = new AnnotationAwareRetryOperationsInterceptor(); if (retryContextCache != null) &#123; interceptor.setRetryContextCache(retryContextCache); &#125; if (retryListeners != null) &#123; interceptor.setListeners(retryListeners); &#125; if (methodArgumentsKeyGenerator != null) &#123; interceptor.setKeyGenerator(methodArgumentsKeyGenerator); &#125; if (newMethodArgumentsIdentifier != null) &#123; interceptor.setNewItemIdentifier(newMethodArgumentsIdentifier); &#125; if (sleeper != null) &#123; interceptor.setSleeper(sleeper); &#125; return interceptor;&#125;AnnotationAwareRetryOperationsInterceptor继承关系可以看出AnnotationAwareRetryOperationsInterceptor是一个MethodInterceptor，在创建AOP代理过程中如果目标方法符合pointcut的规则，它就会加到interceptor列表中，然后做增强，我们看看invoke方法做了什么增强。12345678910@Override public Object invoke(MethodInvocation invocation) throws Throwable &#123; MethodInterceptor delegate = getDelegate(invocation.getThis(), invocation.getMethod()); if (delegate != null) &#123; return delegate.invoke(invocation); &#125; else &#123; return invocation.proceed(); &#125; &#125;这里用到了委托，主要是需要根据配置委托给具体“有状态”的interceptor还是“无状态”的interceptor。12345678910111213141516171819202122232425262728293031323334353637private MethodInterceptor getDelegate(Object target, Method method) &#123; if (!this.delegates.containsKey(target) || !this.delegates.get(target).containsKey(method)) &#123; synchronized (this.delegates) &#123; if (!this.delegates.containsKey(target)) &#123; this.delegates.put(target, new HashMap&lt;Method, MethodInterceptor&gt;()); &#125; Map&lt;Method, MethodInterceptor&gt; delegatesForTarget = this.delegates.get(target); if (!delegatesForTarget.containsKey(method)) &#123; Retryable retryable = AnnotationUtils.findAnnotation(method, Retryable.class); if (retryable == null) &#123; retryable = AnnotationUtils.findAnnotation(method.getDeclaringClass(), Retryable.class); &#125; if (retryable == null) &#123; retryable = findAnnotationOnTarget(target, method); &#125; if (retryable == null) &#123; return delegatesForTarget.put(method, null); &#125; MethodInterceptor delegate; //支持自定义MethodInterceptor，而且优先级最高 if (StringUtils.hasText(retryable.interceptor())) &#123; delegate = this.beanFactory.getBean(retryable.interceptor(), MethodInterceptor.class); &#125; else if (retryable.stateful()) &#123; //得到“有状态”的interceptor delegate = getStatefulInterceptor(target, method, retryable); &#125; else &#123; //得到“无状态”的interceptor delegate = getStatelessInterceptor(target, method, retryable); &#125; delegatesForTarget.put(method, delegate); &#125; &#125; &#125; return this.delegates.get(target).get(method); &#125;getStatefulInterceptor和getStatelessInterceptor都是差不多，我们先看看比较简单的getStatelessInterceptor。12345678910111213private MethodInterceptor getStatelessInterceptor(Object target, Method method, Retryable retryable) &#123; //生成一个RetryTemplate RetryTemplate template = createTemplate(retryable.listeners()); //生成retryPolicy template.setRetryPolicy(getRetryPolicy(retryable)); //生成backoffPolicy template.setBackOffPolicy(getBackoffPolicy(retryable.backoff())); return RetryInterceptorBuilder.stateless() .retryOperations(template) .label(retryable.label()) .recoverer(getRecoverer(target, method)) .build(); &#125;具体生成retryPolicy和backoffPolicy的规则，我们等下再回头来看。RetryInterceptorBuilder其实就是为了生成RetryOperationsInterceptor。RetryOperationsInterceptor也是一个MethodInterceptor，我们来看看它的invoke方法。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public Object invoke(final MethodInvocation invocation) throws Throwable &#123; String name; if (StringUtils.hasText(label)) &#123; name = label; &#125; else &#123; name = invocation.getMethod().toGenericString(); &#125; final String label = name; //定义了一个RetryCallback，其实看它的doWithRetry方法，调用了invocation的proceed()方法，是不是有点眼熟，这就是AOP的拦截链调用，如果没有拦截链，那就是对原来方法的调用。 RetryCallback&lt;Object, Throwable&gt; retryCallback = new RetryCallback&lt;Object, Throwable&gt;() &#123; public Object doWithRetry(RetryContext context) throws Exception &#123; context.setAttribute(RetryContext.NAME, label); /* * If we don't copy the invocation carefully it won't keep a reference to * the other interceptors in the chain. We don't have a choice here but to * specialise to ReflectiveMethodInvocation (but how often would another * implementation come along?). */ if (invocation instanceof ProxyMethodInvocation) &#123; try &#123; return ((ProxyMethodInvocation) invocation).invocableClone().proceed(); &#125; catch (Exception e) &#123; throw e; &#125; catch (Error e) &#123; throw e; &#125; catch (Throwable e) &#123; throw new IllegalStateException(e); &#125; &#125; else &#123; throw new IllegalStateException( "MethodInvocation of the wrong type detected - this should not happen with Spring AOP, " + "so please raise an issue if you see this exception"); &#125; &#125; &#125;; if (recoverer != null) &#123; ItemRecovererCallback recoveryCallback = new ItemRecovererCallback( invocation.getArguments(), recoverer); return this.retryOperations.execute(retryCallback, recoveryCallback); &#125; //最终还是进入到retryOperations的execute方法，这个retryOperations就是在之前的builder set进来的RetryTemplate。 return this.retryOperations.execute(retryCallback); &#125;无论是RetryOperationsInterceptor还是StatefulRetryOperationsInterceptor，最终的拦截处理逻辑还是调用到RetryTemplate的execute方法，从名字也看出来，RetryTemplate作为一个模板类，里面包含了重试统一逻辑。不过，我看这个RetryTemplate并不是很“模板”，因为它没有很多可以扩展的地方。重试逻辑及策略实现上面介绍了Spring Retry利用了AOP代理使重试机制对业务代码进行“入侵”。下面我们继续看看重试的逻辑做了什么。RetryTemplate的doExecute方法。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139protected &lt;T, E extends Throwable&gt; T doExecute(RetryCallback&lt;T, E&gt; retryCallback, RecoveryCallback&lt;T&gt; recoveryCallback, RetryState state) throws E, ExhaustedRetryException &#123; RetryPolicy retryPolicy = this.retryPolicy; BackOffPolicy backOffPolicy = this.backOffPolicy; //新建一个RetryContext来保存本轮重试的上下文 RetryContext context = open(retryPolicy, state); if (this.logger.isTraceEnabled()) &#123; this.logger.trace("RetryContext retrieved: " + context); &#125; // Make sure the context is available globally for clients who need // it... RetrySynchronizationManager.register(context); Throwable lastException = null; boolean exhausted = false; try &#123; //如果有注册RetryListener，则会调用它的open方法，给调用者一个通知。 boolean running = doOpenInterceptors(retryCallback, context); if (!running) &#123; throw new TerminatedRetryException( "Retry terminated abnormally by interceptor before first attempt"); &#125; // Get or Start the backoff context... BackOffContext backOffContext = null; Object resource = context.getAttribute("backOffContext"); if (resource instanceof BackOffContext) &#123; backOffContext = (BackOffContext) resource; &#125; if (backOffContext == null) &#123; backOffContext = backOffPolicy.start(context); if (backOffContext != null) &#123; context.setAttribute("backOffContext", backOffContext); &#125; &#125; //判断能否重试，就是调用RetryPolicy的canRetry方法来判断。 //这个循环会直到原方法不抛出异常，或不需要再重试 while (canRetry(retryPolicy, context) &amp;&amp; !context.isExhaustedOnly()) &#123; try &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug("Retry: count=" + context.getRetryCount()); &#125; //清除上次记录的异常 lastException = null; //doWithRetry方法，一般来说就是原方法 return retryCallback.doWithRetry(context); &#125; catch (Throwable e) &#123; //原方法抛出了异常 lastException = e; try &#123; //记录异常信息 registerThrowable(retryPolicy, state, context, e); &#125; catch (Exception ex) &#123; throw new TerminatedRetryException("Could not register throwable", ex); &#125; finally &#123; //调用RetryListener的onError方法 doOnErrorInterceptors(retryCallback, context, e); &#125; //再次判断能否重试 if (canRetry(retryPolicy, context) &amp;&amp; !context.isExhaustedOnly()) &#123; try &#123; //如果可以重试则走退避策略 backOffPolicy.backOff(backOffContext); &#125; catch (BackOffInterruptedException ex) &#123; lastException = e; // back off was prevented by another thread - fail the retry if (this.logger.isDebugEnabled()) &#123; this.logger .debug("Abort retry because interrupted: count=" + context.getRetryCount()); &#125; throw ex; &#125; &#125; if (this.logger.isDebugEnabled()) &#123; this.logger.debug( "Checking for rethrow: count=" + context.getRetryCount()); &#125; if (shouldRethrow(retryPolicy, context, state)) &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug("Rethrow in retry for policy: count=" + context.getRetryCount()); &#125; throw RetryTemplate.&lt;E&gt;wrapIfNecessary(e); &#125; &#125; /* * A stateful attempt that can retry may rethrow the exception before now, * but if we get this far in a stateful retry there's a reason for it, * like a circuit breaker or a rollback classifier. */ if (state != null &amp;&amp; context.hasAttribute(GLOBAL_STATE)) &#123; break; &#125; &#125; if (state == null &amp;&amp; this.logger.isDebugEnabled()) &#123; this.logger.debug( "Retry failed last attempt: count=" + context.getRetryCount()); &#125; exhausted = true; //重试结束后如果有兜底Recovery方法则执行，否则抛异常 return handleRetryExhausted(recoveryCallback, context, state); &#125; catch (Throwable e) &#123; throw RetryTemplate.&lt;E&gt;wrapIfNecessary(e); &#125; finally &#123; //处理一些关闭逻辑 close(retryPolicy, context, state, lastException == null || exhausted); //调用RetryListener的close方法 doCloseInterceptors(retryCallback, context, lastException); RetrySynchronizationManager.clear(); &#125; &#125;主要核心重试逻辑就是上面的代码了，看上去还是挺简单的。在上面，我们漏掉了RetryPolicy的canRetry方法和BackOffPolicy的backOff方法，以及这两个Policy是怎么来的。我们回头看看getStatelessInterceptor方法中的getRetryPolicy和getRetryPolicy方法。123456789101112131415161718192021222324252627282930313233343536373839404142private RetryPolicy getRetryPolicy(Annotation retryable) &#123; Map&lt;String, Object&gt; attrs = AnnotationUtils.getAnnotationAttributes(retryable); @SuppressWarnings("unchecked") Class&lt;? extends Throwable&gt;[] includes = (Class&lt;? extends Throwable&gt;[]) attrs.get("value"); String exceptionExpression = (String) attrs.get("exceptionExpression"); boolean hasExpression = StringUtils.hasText(exceptionExpression); if (includes.length == 0) &#123; @SuppressWarnings("unchecked") Class&lt;? extends Throwable&gt;[] value = (Class&lt;? extends Throwable&gt;[]) attrs.get("include"); includes = value; &#125; @SuppressWarnings("unchecked") Class&lt;? extends Throwable&gt;[] excludes = (Class&lt;? extends Throwable&gt;[]) attrs.get("exclude"); Integer maxAttempts = (Integer) attrs.get("maxAttempts"); String maxAttemptsExpression = (String) attrs.get("maxAttemptsExpression"); if (StringUtils.hasText(maxAttemptsExpression)) &#123; maxAttempts = PARSER.parseExpression(resolve(maxAttemptsExpression), PARSER_CONTEXT) .getValue(this.evaluationContext, Integer.class); &#125; if (includes.length == 0 &amp;&amp; excludes.length == 0) &#123; SimpleRetryPolicy simple = hasExpression ? new ExpressionRetryPolicy(resolve(exceptionExpression)) .withBeanFactory(this.beanFactory) : new SimpleRetryPolicy(); simple.setMaxAttempts(maxAttempts); return simple; &#125; Map&lt;Class&lt;? extends Throwable&gt;, Boolean&gt; policyMap = new HashMap&lt;Class&lt;? extends Throwable&gt;, Boolean&gt;(); for (Class&lt;? extends Throwable&gt; type : includes) &#123; policyMap.put(type, true); &#125; for (Class&lt;? extends Throwable&gt; type : excludes) &#123; policyMap.put(type, false); &#125; boolean retryNotExcluded = includes.length == 0; if (hasExpression) &#123; return new ExpressionRetryPolicy(maxAttempts, policyMap, true, exceptionExpression, retryNotExcluded) .withBeanFactory(this.beanFactory); &#125; else &#123; return new SimpleRetryPolicy(maxAttempts, policyMap, true, retryNotExcluded); &#125; &#125;嗯～，代码不难，这里简单做一下总结好了。就是通过@Retryable注解中的参数，来判断具体使用文章开头说到的哪个重试策略，是SimpleRetryPolicy还是ExpressionRetryPolicy等。123456789101112131415161718192021222324252627282930313233343536373839404142434445private BackOffPolicy getBackoffPolicy(Backoff backoff) &#123; long min = backoff.delay() == 0 ? backoff.value() : backoff.delay(); if (StringUtils.hasText(backoff.delayExpression())) &#123; min = PARSER.parseExpression(resolve(backoff.delayExpression()), PARSER_CONTEXT) .getValue(this.evaluationContext, Long.class); &#125; long max = backoff.maxDelay(); if (StringUtils.hasText(backoff.maxDelayExpression())) &#123; max = PARSER.parseExpression(resolve(backoff.maxDelayExpression()), PARSER_CONTEXT) .getValue(this.evaluationContext, Long.class); &#125; double multiplier = backoff.multiplier(); if (StringUtils.hasText(backoff.multiplierExpression())) &#123; multiplier = PARSER.parseExpression(resolve(backoff.multiplierExpression()), PARSER_CONTEXT) .getValue(this.evaluationContext, Double.class); &#125; if (multiplier &gt; 0) &#123; ExponentialBackOffPolicy policy = new ExponentialBackOffPolicy(); if (backoff.random()) &#123; policy = new ExponentialRandomBackOffPolicy(); &#125; policy.setInitialInterval(min); policy.setMultiplier(multiplier); policy.setMaxInterval(max &gt; min ? max : ExponentialBackOffPolicy.DEFAULT_MAX_INTERVAL); if (this.sleeper != null) &#123; policy.setSleeper(this.sleeper); &#125; return policy; &#125; if (max &gt; min) &#123; UniformRandomBackOffPolicy policy = new UniformRandomBackOffPolicy(); policy.setMinBackOffPeriod(min); policy.setMaxBackOffPeriod(max); if (this.sleeper != null) &#123; policy.setSleeper(this.sleeper); &#125; return policy; &#125; FixedBackOffPolicy policy = new FixedBackOffPolicy(); policy.setBackOffPeriod(min); if (this.sleeper != null) &#123; policy.setSleeper(this.sleeper); &#125; return policy; &#125;嗯～，一样的味道。就是通过@Backoff注解中的参数，来判断具体使用文章开头说到的哪个退避策略，是FixedBackOffPolicy还是UniformRandomBackOffPolicy等。那么每个RetryPolicy都会重写canRetry方法，然后在RetryTemplate判断是否需要重试。我们看看SimpleRetryPolicy的1234567@Override public boolean canRetry(RetryContext context) &#123; Throwable t = context.getLastThrowable(); //判断抛出的异常是否符合重试的异常 //还有，是否超过了重试的次数 return (t == null || retryForException(t)) &amp;&amp; context.getRetryCount() &lt; maxAttempts; &#125;同样，我们看看FixedBackOffPolicy的退避方法。123456789protected void doBackOff() throws BackOffInterruptedException &#123; try &#123; //就是sleep固定的时间 sleeper.sleep(backOffPeriod); &#125; catch (InterruptedException e) &#123; throw new BackOffInterruptedException("Thread interrupted while sleeping", e); &#125; &#125;至此，重试的主要原理以及逻辑大概就是这样了。RetryContext我觉得有必要说说RetryContext，先看看它的继承关系。可以看出对每一个策略都有对应的Context。在Spring Retry里，其实每一个策略都是单例来的。我刚开始直觉是对每一个需要重试的方法都会new一个策略，这样重试策略之间才不会产生冲突，但是一想就知道这样就可能多出了很多策略对象出来，增加了使用者的负担，这不是一个好的设计。Spring Retry采用了一个更加轻量级的做法，就是针对每一个需要重试的方法只new一个上下文Context对象，然后在重试时，把这个Context传到策略里，策略再根据这个Context做重试，而且Spring Retry还对这个Context做了cache。这样就相当于对重试的上下文做了优化。总结Spring Retry通过AOP机制来实现对业务代码的重试”入侵“，RetryTemplate中包含了核心的重试逻辑，还提供了丰富的重试策略和退避策略。参考资料http://www.10tiao.com/html/164/201705/2652898434/1.htmlhttps://www.jianshu.com/p/58e753ca0151https://paper.tuisec.win/detail/90bd660fad92183]]></content>
      <categories>
        <category>java</category>
        <category>spring</category>
      </categories>
      <tags>
        <tag>spring-retry</tag>
        <tag>retry</tag>
        <tag>重试机制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[让线程“暂停”的方式对比]]></title>
    <url>%2Fposts%2F4a4dcc9%2F</url>
    <content type="text"><![CDATA[概要其实对这四种方式都知道，但是有时看到人家代码时就会想为什么要采用这种方式来阻塞呢？用其他的行不行？问题其实是对这四种方式的使用场景不熟悉，我从编程的角度来整理一下。介绍yieldThread.yield()大家都知道，它会放弃当前的CPU时间片，退下来让给别的线程运行，但你看它是没有时间参数的，所以这个线程下次被调度的时间点是不定的。如果对暂停的时间没有要求，可以使用这个，你并不要期望这个线程能暂停多久。sleepThread.sleep()大家都知道，效果跟Thread.yield()一样，不过sleep可以指定时间，什么时候醒过来继续运行。JDK1.5开始推荐使用TimeUnit的sleep方法，其实是一样的，只是增强了可读性。wait / notifywait 和 notify 是基于对象锁的竞争。大家都知道，synchronized关键让进入临界区的线程获得了该对象的锁，即在Mark Word头写上这个线程的ID（偏向锁），如果其他线程来了，会先检查有没有线程在使用这个锁。如果要使用wait / notify，你得先有一个临界区，进入临界区的线程有资格，其他的线程需要“暂停”。所以其实你的操作都是围绕这个对象锁的，你对线程是没有感知的。park / unparkLockSupport的park和unpark是基于对线程暂停和唤醒，这听上去有点废话，大家其实可以理解为是对线程的“命令”，确实大多数网上对unpark的翻译是“许可”，即叫你停就停，动就动。既然你要操作线程，你必然要能够感知到所有相关的线程的。总结漏了ReentrantLock/Condition，其实这跟wait / notify差不多，也是基于“对象锁”的；yield 自己随意“暂停”；sleep 自己有目的的“暂停”；wait / notify 基于对象锁做运行或等待；park / unpark 基于（其他）线程的“命令”，所以它没有一个“锁”的概念；]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>阻塞</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解Future及FutureTask的实现]]></title>
    <url>%2Fposts%2F5dd69f23%2F</url>
    <content type="text"><![CDATA[概要Future是一种异步计算的模式，本文带你理解一下什么是Future，以及基本的FutureTask的实现原理。作用如果在一个方法中要执行另一个操作（任务），但是这个操作会耗时很久，而且你后面还需要用到这个操作的返回结果或者必须等到这个操作结束你才能走下去，你会怎样做？可能大家都会想到异步去执行，即新建一个线程去做这个事情，但是这样的话，你后面的操作就要放到这个异步线程那里，你的方法就变成异步的了，对你原来的返回造成了影响。这时候，Future就发挥作用了，有些地方说它是一种模式，其实，它就是对一个异步操作的封装，它会返回一个“凭证”给你，你可以用这个“凭证”在需要的时候获取到这个异步操作的结果，一般来说这个“凭证”就是future。原理FutureTask就是Future的基本实现，下面我们就从代码分析一下实现的原理。源码基本JDK1.8。Future接口我们先看看Future的定义，即你拿到这个“凭证”之后你能干点什么。1234567891011121314public interface Future&lt;V&gt; &#123; //取消这次任务 boolean cancel(boolean mayInterruptIfRunning); //看看是否取消了 boolean isCancelled(); //看看是否完成了 boolean isDone(); //获取结果 V get() throws InterruptedException, ExecutionException; //时间内获取结果，超时则抛异常 V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125;使用如果没用过的，这里简单演示一下Future怎么使用，大家有个感性认识。123456789101112131415161718private static ExecutorService threadPool = Executors.newCachedThreadPool(); public static void main(String[] args) throws Exception &#123; //通过线程池提交任务，并返回一个future Future&lt;String&gt; future = threadPool.submit(new AsyncTask()); //通过future获取结果。get之前一直阻塞直到有结果返回。 String result = future.get(); System.out.println(result); &#125; public class AsyncTask implements Callable&lt;String&gt; &#123; @Override public String call() throws Exception &#123; TimeUnit.SECONDS.sleep(5); return "ok"; &#125; &#125;继承关系FutureTask是一个RunnableFuture，这个很好理解，就是Runnable+Future了。提交任务从任务的提交入手分析源码。AbstractExecutorService的submit方法。123456789public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; if (task == null) throw new NullPointerException(); //这里封装了一下callable变成一个RunnableFuture RunnableFuture&lt;T&gt; ftask = newTaskFor(task); //注意线程池执行的是RunnableFuture，因为这个Future继承Runnable，所以它是可执行的。 execute(ftask); //返回future return ftask; &#125;submit方法也是支持Runnable的。ExecutorService内部会把Runnable转成Callable，只不过Runnable的返回值为null。FutureTask的属性/状态先看下FutureTask的一些内部属性，才好了解它是怎么运行的。1234567891011121314151617181920212223242526272829//重要属性“状态”state定义为volatile，为了在高并发下能够获取到最新的值private volatile int state; //为state定义了7个状态，看名字都挺好了解的。 private static final int NEW = 0; private static final int COMPLETING = 1; //正常结束 private static final int NORMAL = 2; private static final int EXCEPTIONAL = 3; private static final int CANCELLED = 4; private static final int INTERRUPTING = 5; private static final int INTERRUPTED = 6; //状态之间的转换 * Possible state transitions: * NEW -&gt; COMPLETING -&gt; NORMAL * NEW -&gt; COMPLETING -&gt; EXCEPTIONAL * NEW -&gt; CANCELLED * NEW -&gt; INTERRUPTING -&gt; INTERRUPTED */ //用户提交的真正任务 private Callable&lt;V&gt; callable; //返回结果 private Object outcome; // non-volatile, protected by state reads/writes //记录跑任务的那个线程，只有一个在运行。取消时可以中断这个线程的行为。 private volatile Thread runner; /** Treiber stack of waiting threads */ //这个属性比较重要，后面讲的比较多。记录WaitNode链表的头部，volatile。WaitNode链表是等待结果的线程集合，即这个任务还没跑完时，但同时有很多持有这个future的线程调用了get方法获取结果。 private volatile WaitNode waiters;run方法当这个RunnableFuture提交到线程池后，它做了什么。1234567891011121314151617181920212223242526272829303132333435363738public void run() &#123; //为了防止future重复运行，需要判断是NEW状态。 //同时记录runner属性 //这里UNSAFE的CAS操作在JUC里用的比较多，不展开了（我的原则是，不是这个话题的内容不过多展开，保持专注和精简。） if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return; try &#123; Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; state == NEW) &#123; V result; boolean ran; try &#123; //执行用户的callable result = c.call(); ran = true; &#125; catch (Throwable ex) &#123; result = null; ran = false; //如果callable运行异常了，这里会把这个异常吃掉，然后调用setException方法 setException(ex); &#125; if (ran) //正常结束就是设置结果 set(result); &#125; &#125; finally &#123; // runner must be non-null until state is settled to // prevent concurrent calls to run() runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts int s = state; if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); &#125; &#125;值得注意的是，如果原来的callable任务运行异常了，那么在run方法中会直接catch掉，然后在get的时候才抛出来。这么也是为了做错误隔离，为了callable的异常不会影响到future的运行。setException方法12345678910protected void setException(Throwable t) &#123; if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) &#123; //把结果设为异常 outcome = t; //更新状态为EXCEPTIONAL UNSAFE.putOrderedInt(this, stateOffset, EXCEPTIONAL); // final state //finishCompletion作为一个结束动作 finishCompletion(); &#125; &#125;set方法12345678910protected void set(V v) &#123; if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) &#123; //设置结果 outcome = v; //更新状态为NORMAL UNSAFE.putOrderedInt(this, stateOffset, NORMAL); //同样调用了finishCompletion方法 finishCompletion(); &#125; &#125;setException方法和set方法都是protected，不能随意调用，不过子类可以改变它的行为。COMPLETING状态？在上面说到的7个状态中有一个COMPLETING的状态，它表示新建NEW和正常结束NORMAL或异常结束EXCEPTIONAL中间的这么一个状态，在set和setException用到了，会先把NEW状态更新为COMPLETING，再把COMPLETING更新为对应的结果状态。刚开始我认为这个状态是没必要的。因为这个FutureTask只会有一个线程在运行它，不存在竞争，而且看代码也知道，作者没对竞争失败做处理，那么set和setException的CAS操作是肯定会成功的，所以我觉得把COMPLETING变成NEW也是可以的。但是细想如果直接把1UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)变成1UNSAFE.compareAndSwapInt(this, stateOffset, NEW, NORMAL)但是后面还有一步赋值操作。1outcome = v并发下，这时如果有其他线程在CAS后想获取结果，就返回null了。finishCompletion方法1234567891011121314151617181920212223242526272829//如果这个future正常结束，异常结束，被取消了，都会调用这个方法。private void finishCompletion() &#123; // assert state &gt; COMPLETING; //这里会不停的拿头部节点做遍历，直到头部节点为null。这是为了防止在并发下有新的节点新插入进来。 for (WaitNode q; (q = waiters) != null;) &#123; //CAS把WaitNode链表的头部设为null。 if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) &#123; for (;;) &#123; Thread t = q.thread; if (t != null) &#123; q.thread = null; //唤醒WaitNode的线程，唤醒的线程继续在awaitDone方法里做循环。 LockSupport.unpark(t); &#125; WaitNode next = q.next; //直到next为null，完成链表的遍历 if (next == null) break; q.next = null; // unlink to help gc q = next; &#125; break; &#125; &#125; //这个done方法是预留方法，子类可以继承它来做点别的。 done(); callable = null; // to reduce footprint &#125;get方法get方法是重点。因为作者设计FutureTask是支持高并发的，而且用了Lock-Free无锁算法，所以阅读起来会比较费劲。123456public V get() throws InterruptedException, ExecutionException &#123; int s = state; if (s &lt;= COMPLETING) s = awaitDone(false, 0L); return report(s); &#125;WaitNode链表继续看下去之前，先看看WaitNode的定义。很简单，只有一个Thread和next指针。Thread就是指当前需要获取future结果的那个线程。WaitNode通过next指针形成一条链表。12345static final class WaitNode &#123; volatile Thread thread; volatile WaitNode next; WaitNode() &#123; thread = Thread.currentThread(); &#125; &#125;这是在Lock-Free中常见的数据结构，看上去是不是有点像AQS呢？1234567891011/* * Revision notes: This differs from previous versions of this * class that relied on AbstractQueuedSynchronizer, mainly to * avoid surprising users about retaining interrupt status during * cancellation races. Sync control in the current design relies * on a &quot;state&quot; field updated via CAS to track completion, along * with a simple Treiber stack to hold waiting threads. * * Style note: As usual, we bypass overhead of using * AtomicXFieldUpdaters and instead directly use Unsafe intrinsics. */实际上，官方也说了，之前版本的实现是用了AQS的，原因是…（这个原因我不是很懂是啥意思），现在改为Treiber stack算法了。awaitDone方法123456789101112131415161718192021222324252627282930313233343536373839404142434445private int awaitDone(boolean timed, long nanos) throws InterruptedException &#123; final long deadline = timed ? System.nanoTime() + nanos : 0L; WaitNode q = null; boolean queued = false; //死循环直到s &gt; COMPLETING或者超时，当然这个不是真的死循环，大部分情况下线程是会挂起的。 for (;;) &#123; //如果线程是被中断了，则从链表移除当前节点，然后抛异常 if (Thread.interrupted()) &#123; removeWaiter(q); throw new InterruptedException(); &#125; int s = state; //从上面7个状态看出，当s &gt; COMPLETING都是结束的状态，要不正常结束，异常，取消等。可见合理的状态值设计带来的方便。 if (s &gt; COMPLETING) &#123; if (q != null) q.thread = null; return s; &#125; //这里就是为了防止上面我说的，结果赋值时并发下其他线程获取不到值的情况，所以让这个线程yield一下，再做一次循环，说不定下次就是s &gt; COMPLETING呢。 else if (s == COMPLETING) // cannot time out yet Thread.yield(); else if (q == null) //新建一个WaitNode，准备进链表 q = new WaitNode(); else if (!queued) //CAS把WaitNode节点插入到链表的头部，如果失败则下次继续插入 queued = UNSAFE.compareAndSwapObject(this, waitersOffset, q.next = waiters, q); //如果get方法设置了超时时间，则会进入这个分支，如果超时了，也会返回state。还没超时则挂起，挂起的时间为时间差。 else if (timed) &#123; nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) &#123; //超时需要从链表移除当前节点 removeWaiter(q); return state; &#125; LockSupport.parkNanos(this, nanos); &#125; //注意这里，是最后的步骤，即当s &lt; COMPLETING，已经插入链表了，不是超时的情况 else LockSupport.park(this); &#125; &#125;awaitDone方法返回的是state状态的值。要注意if else执行的顺序，先是判断中断状态，其次判断state的完成状态，再是新建节点，然后插入，最后才是挂起。用for循环去尝试当CAS失败的情况。插入节点的只有这个方法，所以我们可以知道，链表的结构如下：removeWaiter方法的作用是当中断或超时时移除当前的WaitNode。这个方法有点不好理解。12345678910111213141516171819202122private void removeWaiter(WaitNode node) &#123; if (node != null) &#123; node.thread = null; retry: for (;;) &#123; // restart on removeWaiter race for (WaitNode pred = null, q = waiters, s; q != null; q = s) &#123; s = q.next; if (q.thread != null) pred = q; else if (pred != null) &#123; pred.next = s; if (pred.thread == null) // check for race continue retry; &#125; else if (!UNSAFE.compareAndSwapObject(this, waitersOffset, q, s)) continue retry; &#125; break; &#125; &#125; &#125;我们画个图，分情况来理解一下如果q.thread != null因为进来时已经直接把node.thread = null，说明q已经不是当前的node，q是其他线程插入进来的node，这时需要把s，q，pred继续往左移动。如果q.thread == null &amp;&amp; pred != null这时可以把pred的next指向s了，即删除了q。但是如果pred.thread == null，说明pred的线程也把它自己的节点删除了（删除节点的情况除了removeWaiter，还有正常获取结果后也会），所以pred已经没用了，需要重新来找到新的pred。如果q.thread == null &amp;&amp; pred == null说明前面的节点都被删除了，已经没用了，把s直接置为头部。report方法比较简单了1234567891011private V report(int s) throws ExecutionException &#123; Object x = outcome; if (s == NORMAL) //task正常执行就返回结果 return (V)x; if (s &gt;= CANCELLED) //取消则抛异常 throw new CancellationException(); //否则抛出task运行的异常 throw new ExecutionException((Throwable)x); &#125;cancel方法12345678910111213141516171819202122232425//mayInterruptIfRunning参数，取消的同时可以中断runner线程的运行。public boolean cancel(boolean mayInterruptIfRunning) &#123; //状态更新为INTERRUPTING或CANCELLED if (!(state == NEW &amp;&amp; UNSAFE.compareAndSwapInt(this, stateOffset, NEW, mayInterruptIfRunning ? INTERRUPTING : CANCELLED))) return false; try &#123; // in case call to interrupt throws exception //中断 if (mayInterruptIfRunning) &#123; try &#123; Thread t = runner; if (t != null) //调用线程的interrupt方法来中断线程 t.interrupt(); &#125; finally &#123; // final state UNSAFE.putOrderedInt(this, stateOffset, INTERRUPTED); &#125; &#125; &#125; finally &#123; //取消也要把watiers清空掉 finishCompletion(); &#125; return true; &#125;缺点FutureTask有明显的下面两个缺点：重复提交并发会有重复提交的可能，虽然在内部有对状态NEW的判断，但那只是针对那个FutureTask实例的，我们看到，在submit方法中每次提交任务都会new 一个FutureTask出来的。不过现在已经有一个解决方案Memoizer其实很简单，就是用一个key来记录这次的Future，然后放在一个Map里，下次用到时再从Map里取出来。批量任务Future每次只能提交一个任务，而且获取结果之前会一直阻塞，这点也是很不友好的。综上，FutureTask只是提供了一个基本的功能实现，远远不能满足要求高的我们，guava的ListenableFuture和JDK1.8的CompletableFuture都是对Future的增强，前者提供监听器处理结果，后者更加强大，提供链式调用，同步、异步结果返回不同的组合方式来帮助你处理复杂的业务场景。总结源码部分已经介绍的7788了。因为采用了无锁算法，所以实现起来看上去代码比较复杂，看代码时要意识到这个，多想想在高并发下链表会出现怎样的情况，我没有把所有可能出现的情况都罗列出来，所以要靠读者自己多思考。总的来说，Future通过循环判断state状态，挂起、唤醒线程的操作，来实现异步阻塞，通过一个WaitNode链表来处理并发的情况。]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>future</tag>
        <tag>futuretask</tag>
        <tag>异步</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TypeToken原理及泛型擦除]]></title>
    <url>%2Fposts%2Fa6e1c381%2F</url>
    <content type="text"><![CDATA[概要借助对TypeToken原理的分析，加强对泛型擦除的理解，使得我们能够知道什么时候，通过什么方式可以获取到泛型的类型。泛型擦除众所周知，Java的泛型只在编译时有效，到了运行时这个泛型类型就会被擦除掉，即List&lt;String&gt;和List&lt;Integer&gt;在运行时其实都是List&lt;Object&gt;类型。为什么选择这种实现机制？不擦除不行么？在Java诞生10年后，才想实现类似于C++模板的概念，即泛型。Java的类库是Java生态中非常宝贵的财富，必须保证向后兼容（即现有的代码和类文件依旧合法）和迁移兼容（泛化的代码和非泛化的代码可互相调用）基于上面这两个背景和考虑，Java设计者采取了“类型擦除”这种折中的实现方式。同时正正有这个这么“坑”的机制，令到我们无法在运行期间随心所欲的获取到泛型参数的具体类型。TypeToken使用使用过Gson的同学都知道在反序列化时需要定义一个TypeToken类型，像这样1234private Type type = new TypeToken&lt;List&lt;Map&lt;String, Foo&gt;&gt;&gt;()&#123;&#125;.getType();//调用fromJson方法时把type传过去，如果type的类型和json保持一致，则可以反序列化出来gson.fromJson(json, type);三个问题为什么要用TypeToken来定义反序列化的类型？正如上面说的，如果直接把List&lt;Map&lt;String, Foo&gt;&gt;的类型传过去，但是因为运行时泛型被擦除了，所以得到的其实是List&lt;Object&gt;，那么后面的Gson就不知道要转成Map&lt;String, Foo&gt;类型了，这时Gson会默认转成LinkedTreeMap类型。为什么带有大括号{}？这个大括号就是精髓所在。大家都知道，在Java语法中，在这个语境，{}是用来定义匿名类，这个匿名类是继承了TypeToken类，它是TypeToken的子类。为什么要通过子类来获取泛型的类型？这是TypeToken能够获取到泛型类型的关键，这是一个巧妙的方法。这个想法是这样子的，既然像List&lt;String&gt;这样中的泛型会被擦除掉，那么我用一个子类SubList extends List&lt;String&gt;这样的话，在JVM内部中会不会把父类泛型的类型给保存下来呢？我这个子类需要继承的父类的泛型都是已经确定了的呀，果然，JVM是有保存这部分信息的，它是保存在子类的Class信息中，具体看：https://stackoverflow.com/questions/937933/where-are-generic-types-stored-in-java-class-files那么我们怎么获取这部分信息呢？还好，Java有提供API出来：123Type mySuperClass = foo.getClass().getGenericSuperclass(); Type type = ((ParameterizedType)mySuperClass).getActualTypeArguments()[0];System.out.println(type);分析一下这段代码，Class类的getGenericSuperClass()方法的注释是：Returns the Type representing the direct superclass of the entity (class, interface, primitive type or void) represented by thisClass.If the superclass is a parameterized type, the Type object returned must accurately reflect the actual type parameters used in the source code. The parameterized type representing the superclass is created if it had not been created before. See the declaration of ParameterizedType for the semantics of the creation process for parameterized types. If thisClass represents either theObject class, an interface, a primitive type, or void, then null is returned. If this object represents an array class then theClass object representing theObject class is returned概括来说就是对于带有泛型的class，返回一个ParameterizedType对象，对于Object、接口和原始类型返回null，对于数 组class则是返回Object.class。ParameterizedType是表示带有泛型参数的类型的Java类型，JDK1.5引入了泛型之 后，Java中所有的Class都实现了Type接口，ParameterizedType则是继承了Type接口，所有包含泛型的Class类都会实现 这个接口。自己调试一下就知道它返回的是什么了。原理核心的方法就是刚刚说的那两句，剩下的就很简单了。我们看看TypeToken的getType方法1234public final Type getType() &#123; //直接返回type return type; &#125;看type的初始化123456789101112131415161718//注意这里用了protected关键字，限制了只有子类才能访问protected TypeToken() &#123; this.type = getSuperclassTypeParameter(getClass()); this.rawType = (Class&lt;? super T&gt;) $Gson$Types.getRawType(type); this.hashCode = type.hashCode(); &#125; //getSuperclassTypeParameter方法 //这几句就是上面的说到 static Type getSuperclassTypeParameter(Class&lt;?&gt; subclass) &#123; Type superclass = subclass.getGenericSuperclass(); if (superclass instanceof Class) &#123; throw new RuntimeException(&quot;Missing type parameter.&quot;); &#125; ParameterizedType parameterized = (ParameterizedType) superclass; //这里注意一下，返回的是Gson自定义的，在$Gson$Types里面定义的TypeImpl等，这个类都是继承Type的。 return $Gson$Types.canonicalize(parameterized.getActualTypeArguments()[0]); &#125;总结在了解原理之后，相信大家都知道怎么去获取泛型的类型了。参考资料https://www.cnblogs.com/doudouxiaoye/p/5688629.html]]></content>
      <categories>
        <category>java</category>
        <category>guava</category>
      </categories>
      <tags>
        <tag>typetoken</tag>
        <tag>泛型</tag>
        <tag>泛型擦除</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal的使用及原理]]></title>
    <url>%2Fposts%2Fd7ec7cff%2F</url>
    <content type="text"><![CDATA[概要如果你还不知道threadlocal，那你就要了解一下，相信你一定会用到它。作用threadlocal最大作用就是提供线程级别的变量生命周期。试想，如果你需要一个变量在一个线程的生命周期内都可以访问到，在不使用threadlocal的前提下你会怎么做？你或许这样做提供一个类级别或者静态变量但是这个方法大家很容易就想到在高并发时会出问题。把这个局部变量一直传递下去但是如果你要调用的方法层次很深呢？难道你对每个方法都增加一个参数吗？显然不实际。所以threadlocal就是提供了一个可行的方案，使得这个变量可以随时访问到，并且不会跟其他线程产生冲突。使用threadlocal的使用很简单，就是一个get, set。123456789101112131415161718public class ThreadLocalTest &#123; //定义一个ThreadLocal的变量, 需要指定类型 public static ThreadLocal&lt;String&gt; threadLocal = new InheritableThreadLocal&lt;&gt;(); @Before public void init()&#123; #set值进去 threadLocal.set("test"); &#125; @Test public void test() &#123; //在需要时get出来 System.out.println("threadLocal's value=" + threadLocal.get()); &#125; &#125;实现原理set我们先从set方法入手看看做了手脚。1234567891011121314151617181920212223public void set(T value) &#123; //取出当前线程 Thread t = Thread.currentThread(); //根据当前线程获取ThreadLocalMap。从getMap方法可以看到这个ThreadLocalMap就是保存在Thread对象里面 ThreadLocalMap map = getMap(t); if (map != null） #map已经存在就是set进去 map.set(this, value); else #不存在新建一个map createMap(t, value); &#125; //getMap方法 ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals; &#125; //createMap方法 //注意，这里的this指的是ThreadLocal对象 void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue); &#125;我们再看看ThreadLocalMap的创建及其他方法。ThreadLocalMap是定义在ThreadLocal里的一个静态类。123456789ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; table = new Entry[INITIAL_CAPACITY]; //通过ThreadLocal的hashCode确定index，这个我们稍后再说 int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); //重点，把ThreadLocal对象作为key存到了ThreadLocalMap的Entry里 table[i] = new Entry(firstKey, firstValue); size = 1; setThreshold(INITIAL_CAPACITY); &#125;set方法比较简单，跟普通的Map差不多，把key和value set进去。里面还包含了清理key为null的Entry对象的一些操作。1234567891011121314151617181920212223242526272829303132private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; // We don't use a fast path as with get() because it is at // least as common to use set() to create new entries as // it is to replace existing ones, in which case, a fast // path would fail more often than not. Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; e.value = value; return; &#125; if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash(); &#125;get1234567891011121314151617public T get() &#123; //取当前线程 Thread t = Thread.currentThread(); //取出线程的ThreadLocalMap，跟上面是一样的 ThreadLocalMap map = getMap(t); if (map != null) &#123; //根据当前对象ThreadLocal取出ThreadLocalMap.Entry ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; //如果map为null则做初始化，跟上面的createMap差不多 return setInitialValue(); &#125;图解关系可以看出相同的ThreadLocal在不同的线程有不同的值。主要记住ThreadLocal是作为ThreadLocalMap的key，可能开始有点绕，但是慢慢思考，理清它们的关系就行了。两个问题内存泄漏 ？这是一个对ThreadLocal来说老生常谈的问题了。那使用ThreadLocal为什么会导致内存泄漏？还有我们应该怎么去避免？是我们应该关注的两个点。原因首先，我这里假设大家对java的内存回收机制和引用（Reference）有一定的了解。如果不知道，请自行google了。我们先看看ThreadLocalMap的Entry的定义123456789//对key使用了WeakReferencestatic class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125;为什么要使用WeakReference？网上很多的说法都说是使用了弱引用就会被GC一句带过，我觉得很多都说得不清不楚的。我通过自己的理解向大家解析一下：其实很简单，从变量的作用域及引用关系的角度出发思考。试想如果一个ThreadLocal定义为一个类实例的变量或者是一个方法内的局部变量，那么当这个类实例被销毁了或方法退出了，在理想的情况下，垃圾回收器应该回收掉这个ThreadLocal是吧，毕竟它的生命周期已经完结了，但是如果这时ThreadLocalMap还是持有这个ThreadLocal的强引用的话，这个ThreadLocal就不会被回收，直到这个ThreadLocalMap被销毁或者这个线程被销毁。说白了，从上面那个图看出，这样的设计导致的结果是这个ThreadLocal的生命周期跟线程的生命周期挂上钩了。同时，这里又会出现另外一种内存泄漏的问题，即使ThreadLocal回收了，但是value没有被回收，还是会导致内存泄漏。但是你没办法把value设置为WeakReference，因为value不是你的，不归你管。如何防止ThreadLocal采用如下解决内存泄漏，看expungeStaleEntry方法。12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * Expunge a stale entry by rehashing any possibly colliding entries * lying between staleSlot and the next null slot. This also expunges * any other stale entries encountered before the trailing null. See * Knuth, Section 6.4 * * @param staleSlot index of slot known to have null key * @return the index of the next null slot after staleSlot * (all between staleSlot and this slot will have been checked * for expunging). */ private int expungeStaleEntry(int staleSlot) &#123; Entry[] tab = table; int len = tab.length; // expunge entry at staleSlot tab[staleSlot].value = null; tab[staleSlot] = null; size--; // Rehash until we encounter null Entry e; int i; for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; tab[i] = null; size--; &#125; else &#123; int h = k.threadLocalHashCode &amp; (len - 1); if (h != i) &#123; tab[i] = null; // Unlike Knuth 6.4 Algorithm R, we must scan until // null because multiple entries could have been stale. while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; &#125; &#125; &#125; return i; &#125;在ThreadLocal的源码你会看到很多清洗数据的代码最终都会调用到这个方法。这个方法主要逻辑，简单来说就是当key为null，把value也设置为null，从而让value也被回收。这个方法的触发点有很多，当对ThreadLocal进行set，get，remove等操作时都会。容器(如tomcat，netty)一般都是使用线程池处理用户到请求，此时用ThreadLocal要特别注意内存泄漏的问题，一个请求结束了，处理它的线程也结束，但此时这个线程并没有死掉，它只是归还到了线程池中，这时候应该清理掉属于它的ThreadLocal信息。所以我们使用ThreadLocal一个比较好的习惯是在finally块调用remove方法。hashcode和0x61c88647？既然ThreadLocal用map就避免不了冲突的产生。在ThreadLocalMap的构造方法中，我们可以看到以下代码123//table的下标的计算方式int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1);table[i] = new Entry(firstKey, firstValue);1234567891011121314//threadLocalHashCode的定义private final int threadLocalHashCode = nextHashCode();private static int nextHashCode() &#123; return nextHashCode.getAndAdd(HASH_INCREMENT); &#125; /** * The difference between successively generated hash codes - turns * implicit sequential thread-local IDs into near-optimally spread * multiplicative hash values for power-of-two-sized tables. */ //HASH_INCREMENT的十进制为1640531527 private static final int HASH_INCREMENT = 0x61c88647;从代码可以看出每个ThreadLocal的实例的threadLocalHashCode的差值为0x61c88647这么多，那为什么要这样做呢？这个魔数的选取与斐波那契散列有关，0x61c88647对应的十进制为1640531527。斐波那契散列的乘数可以用(long) ((1L &lt;&lt; 31) * (Math.sqrt(5) - 1))可以得到2654435769，如果把这个值给转为带符号的int，则会得到-1640531527。换句话说(1L &lt;&lt; 32) - (long) ((1L &lt;&lt; 31) * (Math.sqrt(5) - 1))得到的结果就是1640531527也就是0x61c88647。通过理论与实践，当我们用0x61c88647作为魔数累加为每个ThreadLocal分配各自的ID也就是threadLocalHashCode再与2的幂取模，得到的结果分布很均匀。ThreadLocalMap使用的是线性探测法，均匀分布的好处在于很快就能探测到下一个临近的可用slot，从而保证效率。。为了优化效率。简单来说就是在table[]的size为2的次幂情况下，取模会得到均匀分布。一个优化点从上面得知，ThreadLocal的Map可能会产生冲突，解决冲突的办法是线性探测。而Netty的FastThreadLocal的利用了一个自增序号来作为下标，避免了冲突的产生。123456789101112public FastThreadLocal() &#123; index = InternalThreadLocalMap.nextVariableIndex(); &#125; public static int nextVariableIndex() &#123; int index = nextIndex.getAndIncrement(); if (index &lt; 0) &#123; nextIndex.decrementAndGet(); throw new IllegalStateException(&quot;too many thread-local indexed variables&quot;); &#125; return index; &#125;参考资料https://juejin.im/post/5b5ecf9de51d45190a434308]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>threadlocal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[理解RateLimiter]]></title>
    <url>%2Fposts%2Ffe5da4a5%2F</url>
    <content type="text"><![CDATA[概要为了对系统资源的保护或者在网关限制流量，我们一般用到限流算法。Google开源工具包Guava提供了限流工具类RateLimiter，该类基于令牌桶算法实现流量限制，使用十分方便。RateLimiter原理分析令牌桶算法令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。实现原理RateLimiter有两种限流模式，一种为稳定模式(SmoothBursty:令牌生成速度恒定)，一种为渐进模式(SmoothWarmingUp:令牌生成速度缓慢提升直到维持在一个稳定值)。以下代码基于基本 guava:26.0-jre。看看关键类的继承图SmoothBursty限流效果先看看效果，对这个工具有一个感性认识RateLimiter.create(5.0) 表示每秒产生5个令牌。输出的意思是这次获取令牌所需要等待的时间。属性继承自SmoothRateLimiter的有以下属性1234567891011121314151617/** The currently stored permits. */ double storedPermits; /** The maximum number of stored permits. */ double maxPermits; /** * The interval between two unit requests, at our stable rate. E.g., a stable rate of 5 permits * per second has a stable interval of 200ms. */ double stableIntervalMicros; /** * The time when the next request (no matter its size) will be granted. After granting a request, * this is pushed further in the future. Large requests push this further than small requests. */ private long nextFreeTicketMicros = 0L; // could be either in the past or futurestoredPermits - 当前桶里有多少令牌。maxPermits - 桶可以最大存储多少令牌。stableIntervalMicros - 生成一个令牌的间隔，单位微秒。nextFreeTicketMicros - 这个比较难理解，也是关键，意思是下一个请求允许获取到令牌的微秒数。初始化12345678910public static RateLimiter create(double permitsPerSecond) &#123; return create(permitsPerSecond, SleepingStopwatch.createFromSystemTimer()); &#125; @VisibleForTesting static RateLimiter create(double permitsPerSecond, SleepingStopwatch stopwatch) &#123; RateLimiter rateLimiter = new SmoothBursty(stopwatch, 1.0 /* maxBurstSeconds */); rateLimiter.setRate(permitsPerSecond); return rateLimiter; &#125;SmoothBursty的两个构造参数，一个是stopwatch，这个类的作用是能够获取从初始化时到现在的时间，另一个参数 maxBurstSeconds是 hard code 为 1。123456789101112131415161718public final void setRate(double permitsPerSecond) &#123; checkArgument( permitsPerSecond &gt; 0.0 &amp;&amp; !Double.isNaN(permitsPerSecond), "rate must be positive"); //这里用了 synchronized 锁，锁的范围是这个 rateLimiter 实例。 synchronized (mutex()) &#123; doSetRate(permitsPerSecond, stopwatch.readMicros()); &#125; &#125; @Override final void doSetRate(double permitsPerSecond, long nowMicros) &#123; //resync 方法，它的作用是计算 storedPermits，等下会讲到； resync(nowMicros); //计算 stableIntervalMicros，单位是微秒，用1秒 / 入参的令牌数，意思就是每多少微秒生成一个令牌； double stableIntervalMicros = SECONDS.toMicros(1L) / permitsPerSecond; this.stableIntervalMicros = stableIntervalMicros; doSetRate(permitsPerSecond, stableIntervalMicros); &#125;setRate方法用来初始化令牌生成速率；123456789101112131415@Override void doSetRate(double permitsPerSecond, double stableIntervalMicros) &#123; double oldMaxPermits = this.maxPermits; //这里涉及一个重要的属性 maxPermits，它表示桶最大的存储令牌的数量，注意maxBurstSeconds hard code为1 maxPermits = maxBurstSeconds * permitsPerSecond; if (oldMaxPermits == Double.POSITIVE_INFINITY) &#123; // if we don't special-case this, we would get storedPermits == NaN, below storedPermits = maxPermits; &#125; else &#123; storedPermits = (oldMaxPermits == 0.0) ? 0.0 // initial state : storedPermits * maxPermits / oldMaxPermits; &#125; &#125;doSetRate 是模版方法，我们先看 SmoothBursty 的，等下讲到 SmoothWarmingUp 时会讲它的 doSetRate。这个方法有两个地方用到，一是初始化时，二是调用 RateLimiter 的实例方法 setRate 动态调整速率时。延迟计算初始化就这么简单了。可能有人在想既然是令牌桶算法，应该有个类似定时器的东东来持续往桶放令牌才对啊，我刚开始也是这么想的，看了代码觉得自己还是太嫩了，如果开启一个定时器无可厚非，但如果系统需要N个不同速率的桶来针对不同的场景或用户，就会极大的消耗系统资源。RateLimiter用了一种类似于延迟计算的方法，把桶里令牌数量的计算放在下一个请求中计算，即桶里的令牌数 storedPermits 不是实时更新的，而是等到下一个请求过来时才更新的，具体我们来看看消费令牌的过程。获取令牌acquire主要有两个方法，一是 acquire，一是 tryAcquire。区别是如果桶里没有令牌，前者会阻塞，后者会直接返回 false。我们先看看 acquire 方法12345678910111213141516171819202122@CanIgnoreReturnValue //这个方法主要是获取令牌的同时，返回需要等待的时间，主要就是reserve方法，至于 stopwatch.sleepMicrosUninterruptibly 大家理解为 sleep 就好了。 public double acquire(int permits) &#123; long microsToWait = reserve(permits); stopwatch.sleepMicrosUninterruptibly(microsToWait); return 1.0 * microsToWait / SECONDS.toMicros(1L); &#125; final long reserve(int permits) &#123; checkPermits(permits //这里用 synchronized 锁，所以下面的逻辑大家不用考虑由并发产生的问题； synchronized (mutex()) &#123; //stopwatch.readMicros() 的作用是获取从初始化到现在的系统时间微秒数。 return reserveAndGetWaitLength(permits, stopwatch.readMicros()); &#125; &#125; //获取令牌并等待 final long reserveAndGetWaitLength(int permits, long nowMicros) &#123; long momentAvailable = reserveEarliestAvailable(permits, nowMicros); return max(momentAvailable - nowMicros, 0); &#125;reserveEarliestAvailable 是整个 RateLimiter 的核心方法，它是 SmoothRateLimite 的一个模板方法。123456789101112131415161718@Override final long reserveEarliestAvailable(int requiredPermits, long nowMicros) &#123; resync(nowMicros); long returnValue = nextFreeTicketMicros; //storedPermitsToSpend 是可以消费的令牌数，最多也就取 storedPermits 这么多了； double storedPermitsToSpend = min(requiredPermits, this.storedPermits); //freshPermits 字面意思新鲜的令牌，我们理解为还没生成的或者将来会生成的令牌。假如我要10个令牌，但是桶里现在只有5个令牌，那么 freshPermits 值为 5 = 10 - 5； double freshPermits = requiredPermits - storedPermitsToSpend; //然后就通过 freshPermits 计算出需要等待的时间 waitMicros。storedPermitsToWaitTime 是一个模板方法，对 SmoothBursty 来说这个没啥用，它始终返回 0，所以 waitMicros = freshPermits * stableIntervalMicros； long waitMicros = storedPermitsToWaitTime(this.storedPermits, storedPermitsToSpend) + (long) (freshPermits * stableIntervalMicros); //更新 nextFreeTicketMicros，追加 waitMicros； this.nextFreeTicketMicros = LongMath.saturatedAdd(nextFreeTicketMicros, waitMicros); //storedPermits 追减用掉的令牌； this.storedPermits -= storedPermitsToSpend; return returnValue; &#125;reserveEarliestAvailable的返回值，注意了，这里返回的是更新前的 nextFreeTicketMicros，也就是上一个请求更新的 nextFreeTicketMicros。那么这个 waitMicros 等待时间也不是当前请求需要等待的时间，而是下一个请求需要等待的时间，这个涉及到 RateLimiter 一个很重要的设计理念，就是“预消费”，通俗点理解即“前人消费，后人买单”，理解好这点，是使用和理解 RateLimiter 的关键。我举一个例子来助于理解，桶的速率为每秒产生5个令牌，现在桶里有4个令牌，现在过来一个请求需要10个令牌，那么这个请求会被无阻塞允许，不需要等待，同时又过来一个请求，现在桶里已经没有令牌了，而且上一个请求还“欠下”6个令牌，那么这个请求需要等待 (10 - 4) / 5 秒的时间，才被允许执行。1234567891011121314151617//刚刚说的延迟计算令牌数就在这里。这个方法是用来计算 storedPermits （桶里的令牌数），nowMicros 是当前的微秒数，nextFreeTicketMicros 上面说过了。void resync(long nowMicros) &#123; // if nextFreeTicket is in the past, resync to now if (nowMicros &gt; nextFreeTicketMicros) &#123; double newPermits = (nowMicros - nextFreeTicketMicros) / coolDownIntervalMicros(); //令牌数不能超过 maxPermits； storedPermits = min(maxPermits, storedPermits + newPermits); //把 nextFreeTicketMicros 置为当前时间。 nextFreeTicketMicros = nowMicros; &#125; &#125; //coolDownIntervalMicros 是一个模板方法，看 SmoothBursty 的，值等于 stableIntervalMicros @Override double coolDownIntervalMicros() &#123; return stableIntervalMicros; &#125;所以resync的意思就是如果当前时间大于 nextFreeTicketMicros，就用当前时间 - nextFreeTicketMicros / 每 stableIntervalMicros 生成一个令牌，即这个时间差可以生成多少个令牌；我用一个图来表示会更加清晰为什么要“预消费”RateLimiter 它是这样想的：Last, but not least: consider a RateLimiter with rate of 1 permit per second, currently completely unused, and an expensive acquire(100) request comes. It would be nonsensical to just wait for 100 seconds, and /then/ start the actual task. Why wait without doing anything? A much better approach is to /allow/ the request right away (as if it was an acquire(1) request instead), and postpone /subsequent/ requests as needed. In this version, we allow starting the task immediately, and postpone by 100 seconds future requests, thus we allow for work to get done in the meantime instead of waiting idly.大概意思是，假设令牌产生的速率为1秒一个，系统平时是很空闲的，突然来了一个 expensive acquire(100) 的请求，难道我要瞎等100秒才执行吗？这毫无意义，不能充分利用资源啊，所以干脆可以直接允许好了，不要做无谓的等待。简单来说就是为了突发性。消费场景分析我们分情况分析一下就清楚了：nowMicros &gt; nextFreeTicketMicros这种场景发生在刚初始化时，或者桶里的令牌还有剩余。如果请求所需令牌 &lt; 桶里的即桶里令牌满足这次消费的话，那么 nextFreeTicketMicros 会移动到 nowMicros 的位置令牌数 storedPermits = 原来 - 消费的 + 这段时间增加的。如果请求所需令牌 &gt;= 桶里的这时会优先把桶里的令牌全部拿走，那么 storedPermits 就等于0了。如果还不够，就会发生预消费，那么 nextFreeTicketMicros 会后移，移动多少？就是需要产生“溢出”令牌数的时间。nowMicros &lt; nextFreeTicketMicros在上面有一个场景 nextFreeTicketMicros 会后移，移动了多少不知道，要看上一个请求，那么如果这段时间内有请求过来呢？这时当前的请求就要为上一个请求“买单”了，它需要等待到 nextFreeTicketMicros 这个时刻才能允许执行，但此时桶里令牌数是 0 的，所以这个请求也是会预消费的。SmoothWarmingUpSmoothBursty 是以一个固定的速率来产生令牌的，它具有突发性，这个可能适用大多数场景。而 SmoothWarmingUp 考虑的是譬如一个系统刚启动，但如果这时有大量请求过来，因为突发性，这些请求都会被允许，但此时系统可能没有那么多资源去响应，所以需要一个“热身”时间，SmoothWarmingUp 就派上用场了。它跟 SmoothBursty 的大概思路都是差不多的，只是个别地方有差别，主要就是之前提到几个模板方法，我们来看看。限流效果SmoothWarmingUp 的效果是刚开始产生令牌的速率比较慢，随着请求过来，会进入“热身”期，速率逐渐提升到 permitsPerSecond 这个速度；但是如果没有请求了，又会“冷却”下去，请求过来又要从“热身”开始。初始化初始化也是调用 create，不过参数列表有点不同12345678910111213141516171819202122232425262728//permitsPerSecond 是“热身”后的稳定速率； //warmupPeriod 是“热身”时间，如果这段时间内持续有请求过来消费令牌，就会达到一个稳定的速率，这时跟 SmoothBursty 效果一样； //unit 是 warmupPeriod 的单位； public static RateLimiter create(double permitsPerSecond, long warmupPeriod, TimeUnit unit) &#123; checkArgument(warmupPeriod &gt;= 0, "warmupPeriod must not be negative: %s", warmupPeriod); //coldFactor hard code 为 3； return create( permitsPerSecond, warmupPeriod, unit, 3.0, SleepingStopwatch.createFromSystemTimer()); &#125; @VisibleForTesting static RateLimiter create( double permitsPerSecond, long warmupPeriod, TimeUnit unit, double coldFactor, SleepingStopwatch stopwatch) &#123; RateLimiter rateLimiter = new SmoothWarmingUp(stopwatch, warmupPeriod, unit, coldFactor); rateLimiter.setRate(permitsPerSecond); return rateLimiter; &#125; SmoothWarmingUp( SleepingStopwatch stopwatch, long warmupPeriod, TimeUnit timeUnit, double coldFactor) &#123; super(stopwatch); this.warmupPeriodMicros = timeUnit.toMicros(warmupPeriod); this.coldFactor = coldFactor; &#125;“热身”速率函数及说明由于接下来涉及到一些计算，我们先看看“热身”函数的定义及图像123456789101112131415161718192021222324252627282930313233343536373839/** * This implements the following function where coldInterval = coldFactor * stableInterval. * * &lt;pre&gt; * ^ throttling * | * cold + / * interval | /. * | / . * | / . ← &quot;warmup period&quot; is the area of the trapezoid between * | / . thresholdPermits and maxPermits * | / . * | / . * | / . * stable +----------/ WARM . * interval | . UP . * | . PERIOD. * | . . * 0 +----------+-------+--------------→ storedPermits * 0 thresholdPermits maxPermits * &lt;/pre&gt; * * Before going into the details of this particular function, let&apos;s keep in mind the basics: * * &lt;ol&gt; * &lt;li&gt;The state of the RateLimiter (storedPermits) is a vertical line in this figure. * &lt;li&gt;When the RateLimiter is not used, this goes right (up to maxPermits) * &lt;li&gt;When the RateLimiter is used, this goes left (down to zero), since if we have * storedPermits, we serve from those first * &lt;li&gt;When _unused_, we go right at a constant rate! The rate at which we move to the right is * chosen as maxPermits / warmupPeriod. This ensures that the time it takes to go from 0 to * maxPermits is equal to warmupPeriod. * &lt;li&gt;When _used_, the time it takes, as explained in the introductory class note, is equal to * the integral of our function, between X permits and X-K permits, assuming we want to * spend K saved permits. * &lt;/ol&gt; * * &lt;p&gt;In summary, the time it takes to move to the left (spend K permits), is equal to the area of * the function of width == K.首先不要被吓到，还是很简单的，我来说明一下。x 轴是 storedPermits，即桶里的令牌数。轴上主要刻有两个值，一是thresholdPermits，这个等下会讲到；一个是maxPermits；y 轴是生成一个令牌的间隔，单位微秒。轴上主要刻有两个值，一是stable interval；一个是 cold interval，coldInterval = coldFactor * stableInterval，由于 coldFactor hard code 为 3，所以 coldInterval 等于3倍的 stable interval。warmup period 是入参的“热身”时间。由这几个值构成的左边的长方形和右边的梯形。由于 x 轴是令牌数，y 轴是生成令牌的间隔，所以它们的乘积是一个时间。doSetRate方法1234567891011121314151617181920212223@Override void doSetRate(double permitsPerSecond, double stableIntervalMicros) &#123; double oldMaxPermits = maxPermits; //coldIntervalMicros - 固定 stableIntervalMicros * 3，这里的stableIntervalMicros跟SmoothBursty一样。 double coldIntervalMicros = stableIntervalMicros * coldFactor; //thresholdPermits - 桶里令牌数的阈值，低于这个值之后就会进入稳定速率期；但高于这个值，又会回到“热身”期。 thresholdPermits = 0.5 * warmupPeriodMicros / stableIntervalMicros; //maxPermits - 意思也是桶里允许最多的令牌 maxPermits = thresholdPermits + 2.0 * warmupPeriodMicros / (stableIntervalMicros + coldIntervalMicros); //slope - 斜率，就是你在图形上看到那条斜线的斜率，这时用来方便已知 storedPermits 时，求出当前的 coldIntervalMicros。条件都已知了，斜率的计算不多说。 slope = (coldIntervalMicros - stableIntervalMicros) / (maxPermits - thresholdPermits); if (oldMaxPermits == Double.POSITIVE_INFINITY) &#123; // if we don't special-case this, we would get storedPermits == NaN, below storedPermits = 0.0; &#125; else &#123; //还有一点注意，这里初始化时，桶里的令牌数为满，跟 SmoothBursty 不一样。 storedPermits = (oldMaxPermits == 0.0) ? maxPermits // initial state is cold : storedPermits * maxPermits / oldMaxPermits; &#125; &#125;这里对几个参数的计算说明一下：thresholdPermits为什么 thresholdPermits = 0.5 * warmupPeriodMicros / stableIntervalMicros？先看看官方的注释Assuming we have saturated demand, the time to go from maxPermits to thresholdPermits isequal to warmupPeriod. And the time to go from thresholdPermits to 0 is warmupPeriod/2. (Thereason that this is warmupPeriod/2 is to maintain the behavior of the original implementationwhere coldFactor was hard coded as 3.)根据官方的注释，说“热身”的时间是稳定时间的2倍（我这里表述不准确），即梯形面积为长方形面积的2倍，要保持跟 coldFactor 写死为3一样，原因是希望令牌速率提升的幅度跟它所需要的时间的比例保持一致（这点我不知道理解的对不对，希望有人帮我佐证）因为梯形面积是已知的，又知道长方形的面积和一条边长，容易求得 thresholdPermits。maxPermits为什么 maxPermits = thresholdPermits + 2.0 * warmupPeriodMicros / (stableIntervalMicros + coldIntervalMicros) ？这个简单，利用梯形面积公式求出高，然后再加上 thresholdPermits。消费令牌的主要逻辑在 reserveEarliestAvailable 方法，里面有一个模板方法 storedPermitsToWaitTime，我们看看 SmoothWarmingUp 的实现。1234567891011121314151617181920212223242526272829@Override long storedPermitsToWaitTime(double storedPermits, double permitsToTake) &#123; //availablePermitsAboveThreshold 表示多于 thresholdPermits 的可用令牌数； double availablePermitsAboveThreshold = storedPermits - thresholdPermits; long micros = 0; // measuring the integral on the right part of the function (the climbing line) //如果 availablePermitsAboveThreshold &gt; 0，说明还在“热身”期，令牌的数量需要控制在 thresholdPermits； if (availablePermitsAboveThreshold &gt; 0.0) &#123; //permitsAboveThresholdToTake 表示这次允许取的最大的令牌数； double permitsAboveThresholdToTake = min(availablePermitsAboveThreshold, permitsToTake); // TODO(cpovirk): Figure out a good name for this variable. //length 表示在大梯形中，以 permitsToTime(availablePermitsAboveThreshold) 为右边的底部，以 permitsToTime(availablePermitsAboveThreshold - permitsAboveThresholdToTake) 为左边的底部，构成的小梯形中，这两条边的和，用于下面的计算； double length = permitsToTime(availablePermitsAboveThreshold) + permitsToTime(availablePermitsAboveThreshold - permitsAboveThresholdToTake); //micros 就是计算小梯形的面积了，permitsAboveThresholdToTake 就是这个小梯形的高了； micros = (long) (permitsAboveThresholdToTake * length / 2.0); permitsToTake -= permitsAboveThresholdToTake; &#125; // measuring the integral on the left part of the function (the horizontal line) //如果多于 thresholdPermits 的令牌数不够，那么就会进入稳定期，使用稳定的速率。 micros += (long) (stableIntervalMicros * permitsToTake); return micros; &#125; //permitsToTime 就是利用斜率求出 y 轴的值。 private double permitsToTime(double permits) &#123; return stableIntervalMicros + permits * slope; &#125;看一下图像就清楚了从 storedPermitsToWaitTime 看出，SmoothWarmingUp 会优先取出超过 thresholdPermits 的令牌，但即使有令牌可用，还是会阻塞请求，以这样来防止启动时的突发性。随着请求增加，令牌的减少，桶的令牌会达到 thresholdPermits，这时就相当于“热身”完了，跟 SmoothBursty 一样。但如果一直没有请求来消费令牌，令牌数增加，就会从新进去“热身”期了。coolDownIntervalMicros在 resync 方法中，还有一个模板方法 coolDownIntervalMicros，在 SmoothWarmingUp 的实现中为1234@Override double coolDownIntervalMicros() &#123; return warmupPeriodMicros / maxPermits; &#125;这个方法是用于得出从上一个请求到当请求的时间内，可以生成令牌的时间间隔，在 SmoothBursty 的实现中它就是 stableIntervalMicros。但在这里我不明白为什么要这样计算（梯形面积 / maxPermits 得出是什么？？？），如果有人知道，希望你留言告知我这个数学渣。setRate的公平性考虑RateLimiter 可以动态调整产生令牌的速率，但是这里涉及一个问题，如何处理当前被阻塞的请求以及后续请求？先看看官方的注释:1234567891011121314/** * Updates the stable rate of this &#123;@code RateLimiter&#125;, that is, the &#123;@code permitsPerSecond&#125; * argument provided in the factory method that constructed the &#123;@code RateLimiter&#125;. Currently * throttled threads will &lt;b&gt;not&lt;/b&gt; be awakened as a result of this invocation, thus they do not * observe the new rate; only subsequent requests will. * * &lt;p&gt;Note though that, since each request repays (by waiting, if necessary) the cost of the * &lt;i&gt;previous&lt;/i&gt; request, this means that the very next request after an invocation to &#123;@code * setRate&#125; will not be affected by the new rate; it will pay the cost of the previous request, * which is in terms of the previous rate. * * &lt;p&gt;The behavior of the &#123;@code RateLimiter&#125; is not modified in any other way, e.g. if the &#123;@code * RateLimiter&#125; was configured with a warmup period of 20 seconds, it still has a warmup period of * 20 seconds after this method invocation.注释的意思说了当前被阻塞的线程不会因此醒过来，它们对速率的改变没有感知，接下来的请求才会适应新的速率。Note though that, since each request repays (by waiting, if necessary) the cost of the previous request, this means that the very next request after an invocation to {@codesetRate} will not be affected by the new rate; it will pay the cost of the previous request, which is in terms of the previous rate.其中这句话不好理解，我的理解是，假设速率降低了，如果需要对当前被阻塞的请求做调整的话，那么它们的阻塞时间会增加（这里假设的结果是增加），由于连锁反应，最后导致 nextFreeTicketMicros 会后移，这就对于改变速率后的请求不公平了。所以 RateLimiter 的做法是当前阻塞的请求还是按照原来时间等待，后续的请求用新的速率，这样实现也比较简单，对后续的请求也公平。tryAcquire补充说明一下tryAcquire，这方法实际应用比acquire 方法还要实用。12345678910111213141516171819202122232425public boolean tryAcquire(int permits, long timeout, TimeUnit unit) &#123; long timeoutMicros = max(unit.toMicros(timeout), 0); checkPermits(permits); long microsToWait; synchronized (mutex()) &#123; long nowMicros = stopwatch.readMicros(); if (!canAcquire(nowMicros, timeoutMicros)) &#123; return false; &#125; else &#123; microsToWait = reserveAndGetWaitLength(permits, nowMicros); &#125; &#125; stopwatch.sleepMicrosUninterruptibly(microsToWait); return true; &#125; //判断就是 canAcquire 方法，很简单，就是判断 nextFreeTicketMicros 的位置，因为你最多也就需要等待到 nextFreeTicketMicros 这么长的时间嘛。 private boolean canAcquire(long nowMicros, long timeoutMicros) &#123; return queryEarliestAvailable(nowMicros) - timeoutMicros &lt;= nowMicros; &#125; @Override final long queryEarliestAvailable(long nowMicros) &#123; return nextFreeTicketMicros; &#125;tryAcquire 会先去判断是否能够在 timeout 的等待时间内能够获取到令牌，如果可以就阻塞等待，如果不能则直接返回false。总结Guava 的 RateLimiter 是一个高效低耗，简单易用，优秀的限流工具，它基于令牌桶算法，并且提供了一个很好的实现参考。参考资料https://blog.wangqi.love/articles/Java/Guava%20RateLimiter%E5%88%86%E6%9E%90.htmlhttps://segmentfault.com/a/1190000012875897https://www.jianshu.com/p/3dfae5c15eb9]]></content>
      <categories>
        <category>java</category>
        <category>guava</category>
      </categories>
      <tags>
        <tag>guava</tag>
        <tag>ratelimiter</tag>
        <tag>限流</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DelayQueue实现原理]]></title>
    <url>%2Fposts%2F255bd548%2F</url>
    <content type="text"><![CDATA[概要任务调度和缓存框架的都会用到DelayQueu作为底层实现，了解它可以让我们更好理解这些框架的本质。背景如果要判断一个缓存对象超时没有，一种笨笨的办法就是，使用一个后台线程，遍历所有对象，挨个检查。这种笨笨的办法简单好用，但是对象数量过多时，可能存在性能问题，检查间隔时间不好设置，间隔时间过大，影响精确度，多小则存在效率问题。而且做不到按超时的时间顺序处理。那么DelayQueue就是用来解决这类问题。实现原理如果看过 PriorityQueue 的源码，就会发现 DelayQueue 的源码实现起来很简答，基本都是调用 PriorityQueue 的插入和取出。不过 DelayQueue 支持高并发，即每个方法开头和结尾都有用 ReentrantLock。take方法我们重点来看看 take 方法：12345678910111213141516171819202122232425262728293031323334353637383940/** * Retrieves and removes the head of this queue, waiting if necessary * until an element with an expired delay is available on this queue. * * @return the head of this queue * @throws InterruptedException &#123;@inheritDoc&#125; */ public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; for (;;) &#123; E first = q.peek(); if (first == null) available.await(); else &#123; long delay = first.getDelay(NANOSECONDS); if (delay &lt;= 0) return q.poll(); first = null; // don't retain ref while waiting if (leader != null) available.await(); else &#123; Thread thisThread = Thread.currentThread(); leader = thisThread; try &#123; available.awaitNanos(delay); &#125; finally &#123; if (leader == thisThread) leader = null; &#125; &#125; &#125; &#125; &#125; finally &#123; if (leader == null &amp;&amp; q.peek() != null) available.signal(); lock.unlock(); &#125; &#125;可以看出延迟的实现原理就是用到了 Condition.awaitNanos(delay) 方法。先 peek 看看有没有元素，再看看元素有没有过期，过期就 poll 取出，还没过期就是 await 等待。这里有两点需要注意：leader线程的作用先看看官方注释：1234567891011121314151617/** * Thread designated to wait for the element at the head of * the queue. This variant of the Leader-Follower pattern * (http://www.cs.wustl.edu/~schmidt/POSA/POSA2/) serves to * minimize unnecessary timed waiting. When a thread becomes * the leader, it waits only for the next delay to elapse, but * other threads await indefinitely. The leader thread must * signal some other thread before returning from take() or * poll(...), unless some other thread becomes leader in the * interim. Whenever the head of the queue is replaced with * an element with an earlier expiration time, the leader * field is invalidated by being reset to null, and some * waiting thread, but not necessarily the current leader, is * signalled. So waiting threads must be prepared to acquire * and lose leadership while waiting. */ private Thread leader = null;说了是用到 Leader-Follower 模式。如果一个线程是 leader 线程，那么它只会等待 available.awaitNanos(delay) 这么多时间，其他后来的 follower 线程只能干等。意思就是一定是 leader 线程先取到头元素，其他线程需要等待 leader 线程的唤醒。这样就可以简化竞争的操作，直接让后面的线程等待，把竞争交给 Condition 来做。first == null目的是为了做 GC。假设没有这一句，那么这里很有可能是 follower 线程在等待的过程中一直持有 first 的引用，而 leader 线程已经完成任务了，都把 first 都释放了，原来希望被回收的 first 却一直没有被回收。在极端的情况下，在一瞬间高并发，会有大量的 follower 线程持有 first，而需要等这些线程都会唤醒后，first 才会被释放回收。offer方法offer 方法，add 和 put 最终还是调到 offer 方法。123456789101112131415161718192021/** * Inserts the specified element into this delay queue. * * @param e the element to add * @return &#123;@code true&#125; * @throws NullPointerException if the specified element is null */ public boolean offer(E e) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; q.offer(e); if (q.peek() == e) &#123; leader = null; available.signal(); &#125; return true; &#125; finally &#123; lock.unlock(); &#125; &#125;放入元素，如果插入的元素是放在了头部的话：把 leader 线程置为 null因为 leader 的意义就是想要取头元素的那个线程，那么旧的 leader 将没有意义。唤醒在等待的线程原本线程都在等待头元素，但是头元素改变了，就唤醒一个线程让它重新取出头元素，并成为新的 leader （看 take 方法里面是一个 for 的死循环）。总结无界队列 - 因为本质是PriorityQueue，PriorityQueue会无限扩展；item 需要实现 Delayed 接口，实现 compareTo 和 getDelay 方法，前者用于放入队列时排序，后者用于如果返回小于 0 且在队列头，则可以取出来；注意 getDelay 返回的是 NANOSECONDS；poll 头元素还没过期则会返回 null；重入锁是非公平的；是实现定时任务的关键；关于 compareTo 和 getDelay，我之前有点混淆，compareTo 是决定放到队列的位置，getDelay 是觉得取出来时的延迟时间；compareTo 和 getDelay 是没有关系的，就是说，队列头的元素可能 getDelay 很大，它后面的元素 getDelay 很小，不一定是说 getDelay 小是放在队列前面的；一般实际使用，我们会用使用相同的属性来做 compareTo 和 getDelay，使到它们是一致的。参考资料http://cmsblogs.com/?p=2413https://www.zybuluo.com/mikumikulch/note/712598]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>DelayQueue</tag>
        <tag>延迟队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PriorityQueue实现原理]]></title>
    <url>%2Fposts%2F49dd368f%2F</url>
    <content type="text"><![CDATA[概要PriorityQueue是一个重要数据结构，是DelayQueue的底层实现，为例如任务调度的实现提供底层的数据结构。PriorityQueue原理分析如果你了解堆排序的话，它的实现对你而言就显得很简单。先看看PriorityQueue有什么属性1234567891011121314151617181920/** * Priority queue represented as a balanced binary heap: the two * children of queue[n] are queue[2*n+1] and queue[2*(n+1)]. The * priority queue is ordered by comparator, or by the elements' * natural ordering, if comparator is null: For each node n in the * heap and each descendant d of n, n &lt;= d. The element with the * lowest value is in queue[0], assuming the queue is nonempty. */ transient Object[] queue; // non-private to simplify nested class access /** * The number of elements in the priority queue. */ private int size = 0; /** * The comparator, or null if priority queue uses elements' * natural ordering. */ private final Comparator&lt;? super E&gt; comparator;主要属性有 queue 一个数组，Comparator 比较器。添加元素的 add/offer 方法：1234567891011121314151617181920212223/** * Inserts the specified element into this priority queue. * * @return &#123;@code true&#125; (as specified by &#123;@link Queue#offer&#125;) * @throws ClassCastException if the specified element cannot be * compared with elements currently in this priority queue * according to the priority queue's ordering * @throws NullPointerException if the specified element is null */ public boolean offer(E e) &#123; if (e == null) throw new NullPointerException(); modCount++; int i = size; if (i &gt;= queue.length) grow(i + 1); size = i + 1; if (i == 0) queue[0] = e; else siftUp(i, e); return true; &#125;加入元素，grow是扩容，元素的插入主要看siftUp。先看看grow方法：12345678910111213141516/** * Increases the capacity of the array. * * @param minCapacity the desired minimum capacity */ private void grow(int minCapacity) &#123; int oldCapacity = queue.length; // Double size if small; else grow by 50% int newCapacity = oldCapacity + ((oldCapacity &lt; 64) ? (oldCapacity + 2) : (oldCapacity &gt;&gt; 1)); // overflow-conscious code if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); queue = Arrays.copyOf(queue, newCapacity); &#125;奇怪的 grow，就如注释所说的，小于 64 时扩容 2 倍，大于 64 时扩容 50%。siftUp方法：1234567891011121314151617181920212223242526272829303132/** * Inserts item x at position k, maintaining heap invariant by * promoting x up the tree until it is greater than or equal to * its parent, or is the root. * * To simplify and speed up coercions and comparisons. the * Comparable and Comparator versions are separated into different * methods that are otherwise identical. (Similarly for siftDown.) * * @param k the position to fill * @param x the item to insert */ private void siftUp(int k, E x) &#123; if (comparator != null) siftUpUsingComparator(k, x); else siftUpComparable(k, x); &#125; @SuppressWarnings("unchecked") private void siftUpComparable(int k, E x) &#123; Comparable&lt;? super E&gt; key = (Comparable&lt;? super E&gt;) x; while (k &gt; 0) &#123; int parent = (k - 1) &gt;&gt;&gt; 1; Object e = queue[parent]; if (key.compareTo((E) e) &gt;= 0) break; queue[k] = e; k = parent; &#125; queue[k] = key; &#125;siftUp 方法，为什么叫 up 呢，因为插入的位置是数组的最后，也就是二叉树的最后一个节点，所以要向上调整，这里就涉及堆排序的调整。comparator 为空时，用 compareTo 比较，直到 parent 比插入的元素大，否则交换，就是这么简单。取出元素的poll方法：123456789101112public E poll() &#123; if (size == 0) return null; int s = --size; modCount++; E result = (E) queue[0]; E x = (E) queue[s]; queue[s] = null; if (s != 0) siftDown(0, x); return result; &#125;取出元素，然后把最后的元素放在第一个的位置，然后调整，本质也是涉及堆排序的调整。总结利用堆排序实现插入、取出等操作时的重排序，目的是效率较高（我一开始认为是一个线性 array，然后通过 shift - 类似插入排序的样子，但是想想这是个 O(n) 的操作，堆排序是 O(logn)快多了）；默认实现是最小堆，当然也可以传入相反比较结果的 Comparator 实现最大堆；没有传入 Comparator 的话，默认使用元素的 compareTo 方法，所以元素要是 Comparable 的，不然会报错；全程没有锁，不支持高并发，不过有PriorityBlockingQueue；不允许null元素；参考资料https://www.cnblogs.com/CarpenterLee/p/5488070.html]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>PriorityQueue</tag>
        <tag>优先级队列</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[堆排序]]></title>
    <url>%2Fposts%2Fc2a5fdc5%2F</url>
    <content type="text"><![CDATA[概要堆排序是一种重要数据结构+算法，一般作为优先级队列的底层数据结构，对它的理解有助于我们更好，更快速的对上层工具的使用。堆排序原理堆排序算法介绍堆是一种重要的数据结构，为一棵完全二叉树, 底层如果用数组存储数据的话，假设某个元素为序号为i(Java数组从0开始,i为0到n-1)。如果它有左子树，那么左子树的位置是2i+1；如果有右子树，右子树的位置是2i+2；如果有父节点，父节点的位置是(n-1)/2取整；分为最大堆和最小堆，最大堆的任意子树根节点不小于任意子结点，最小堆的根节点不大于任意子结点。所谓堆排序就是利用堆这种数据结构来对数组排序，我们使用的是最大堆。处理的思想和冒泡排序，选择排序非常的类似，一层层封顶，只是最大元素的选取使用了最大堆。最大堆的最大元素一定在第0位置，构建好堆之后，交换0位置元素与顶即可。堆排序为原位排序(空间小), 且最坏运行时间是O(nlgn)，是渐进最优的比较排序算法。堆排序的条件1、是一棵完全二叉树（除了最后一层之外的其他每一层都被完全填充，并且所有结点都保持向左对齐）2、最大堆要求节点的元素都要不小于其孩子，最小堆要求节点元素都不大于其左右孩子构造堆的过程（以最大堆为例）假设初始数组为 [1,2,3,4,5,6,7]1、从 array.length / 2 开始，即节点42、节点4没有子节点，结束3、到节点3，3和孩子6和7比较，7比较大，和3交换，变成了图24、到节点2，2和5交换，变成了图35、到节点1，1和7交换后，破坏了原来 7 -&gt; 6, 3 的顺序，需要继续调整，于是1和6交换，变成了图4，结束堆排序的步骤（以最大堆为例）1、对数组 n 个元素构建最大堆 （就是上面的过程）2、将堆顶最大值和数组最后的元素进行替换3、由于步骤2的的交换可能破环了最大堆的性质，第0个不再是最大元素，就对当前元素进行调整，调整的方法跟上面说的是一样的，最终的结果会得到一个最大堆。代码及说明123456789101112131415161718192021222324252627282930313233343536373839404142public static void heapSort(int[] array) &#123; if (array == null || array.length &lt;= 1) &#123; return; &#125; buildMaxHeap(array); for (int i = array.length - 1; i &gt;= 1; i--) &#123; ArrayUtils.exchangeElements(array, 0, i); maxHeap(array, i, 0); &#125; &#125; private static void buildMaxHeap(int[] array) &#123; if (array == null || array.length &lt;= 1) &#123; return; &#125; int half = array.length / 2; for (int i = half; i &gt;= 0; i--) &#123; maxHeap(array, array.length, i); &#125; &#125; private static void maxHeap(int[] array, int heapSize, int index) &#123; int left = index * 2 + 1; int right = index * 2 + 2; int largest = index; if (left &lt; heapSize &amp;&amp; array[left] &gt; array[index]) &#123; largest = left; &#125; if (right &lt; heapSize &amp;&amp; array[right] &gt; array[largest]) &#123; largest = right; &#125; if (index != largest) &#123; ArrayUtils.exchangeElements(array, index, largest); maxHeap(array, heapSize, largest); &#125; &#125;heapSort是入口方法，buildMaxHeap是构建最大堆，maxHeap是每次对节点的调整。可以看出，我们一开始构建堆，从 array.length / 2 开始，直到第0个，这样就把最大堆构建好了。maxHeap是核心算法，它的作用是跟两个子节点比较，如果发现有比它大的，就交换，如果发生交换，就从交换的节点继续调整。总结用一个数组代表一棵完全二叉树：左节点在 2*i + 1 的位置右节点在 2*i + 2 的位置父节点在（i - 1）/2 的位置如果要做升序排序则要构造最大堆，因为根节点会输出在数组的最后。一开始是一个无序的数组，要先构造最大堆，构造最大堆的逻辑就是从 i = （array.length - 1）/ 2 开始，i – ，即从半数开始即可（因为根据完全二叉树的性质，半数之后的都是叶子结点），然后去构造这些子树为最大堆，直到根节点。当构造好最大堆后，这时根节点肯定为最大值，将根节点与数组最后的数交换，即将最大值输出到最后，这时最大堆被破坏了，需要重新调整，让其符合最大堆的性质，就是从交换后的位置开始，因为如果发生交换了，就说明比较大的节点“上去了”，原来小的父节点“下来了”，但是原来的父节点下来后，是否满足要求呢，要从这个节点继续做调整（整个过程相当于大的节点不停的“浮上去”，小的节点不停的“沉下去”）。那么完成这一操作后，数组就是按照升序排列。既然是一个二叉树，堆排序为什么不用链表实现？其实也是可以的，不过我认为还有几点考虑：1、链表的结构消耗更多的内存2、数组可以提供索引来快速检索3、链表的优势在插入，但堆的数组在插入后的调整也是O(log n)，也不差参考资料https://www.cnblogs.com/Java3y/p/8639937.html]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
        <tag>排序</tag>
        <tag>算法</tag>
        <tag>HeapSort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于HashMap的一些理解]]></title>
    <url>%2Fposts%2Fdf45eaf1%2F</url>
    <content type="text"><![CDATA[概要本文主要补充对HashMap的一些理解、分析。相信大家对HashMap都很熟悉，但是其中的一些细节上的设计、思想，往往会被大家忽略，这些都是构成HashMap的重要组成部分，包括有“如何做hash”，“resize后如何保证key的位置”，“resize在高并发下引发的死循环”，“为什么 TREEIFY_THRESHOLD = 8？”，“允许null值的原因”等等，希望有你感兴趣的。补充对HashMap的几点理解为什么JDK 1.8后链表改为红黑树当 HashMap 中有大量的元素都存放到同一个桶中时，这个桶下有一条长长的链表，这个时候 HashMap 就相当于一个单链表，假如单链表有 n 个元素，遍历的时间复杂度就是 O(n)，如果 hash 冲突严重，由这里产生的性能问题尤为突显。JDK 1.8 中引入了红黑树，当链表长度 &gt;= TREEIFY_THRESHOLD（8） &amp; tab.length &gt;= MIN_TREEIFY_CAPACITY（64）时，链表就会转化为红黑树，它的查找时间复杂度为 O(logn)，以此来优化这个问题。如何做hash这是JDK1.8优化之后的样子，key.hashCode() 是个 int 即 32位；h &gt;&gt;&gt; 16 表示无符号右移 16 位，即保留高16位；（&gt;&gt;&gt; 意思是右移时无论是正数还是负数，高位统一补0；&gt;&gt; 遇到负数时高位是补1的）然后，用高16位异或低16位，得到新的低16位，得到的结果就是高16位是原来的高16位，低16位是原来高16位和原来低16位的异或结果。为什么要这样做？我们再看看取出数组下标的方法再说。定位到 table[] 的下标就是 (length - 1 ) &amp; hash（原来这一行代码在JDK1.7是一个叫做 indexFor 的方法，JDK1.8把这个方法删掉了）。没错就是通过 &amp; 的操作，通过 &amp; 运算可以获得一个小于 length - 1 的值。size 是保证等于 2 的 N 次方，所以 hash &amp; (size -1 ) 就相当于做取模运算。那么我们回答一下刚刚的问题：既然取模会忽略高位，那么在 size 比较小的情况下，取模结果就取决于低位，譬如 241（11110001） 和 1009（1111110001） 这两个 hashcode 对 size 为16（1111） 的取模结果都是 1，但是这两个数还是相差比较大的嘛，我们的本意是希望尽量的分散。那么 (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16) 的做法就是把高16位加入到低16位去，以此来让低位16位保留高16位的“特征”（高16位是这个 hashcode 的主要特征，这样做法就是可以让低16位也可以表现出这个数的主要特征），同时也加大低16位的随机性。这样做的目的主要是为了提高运算的速度和 hash 的效率，防止 hash 冲突。JDK1.7的hash算法由于“不怎么随机”，发生过类似 DOS 的攻击HASH COLLISION DOS 问题putVal的思路大概思路：对key的hashCode()做hash，然后再计算index；如果没碰撞直接放到bucket里；如果碰撞了，以链表的形式存在buckets后；如果碰撞导致链表过长(大于等于TREEIFY_THRESHOLD)，就把链表转换成红黑树；如果节点已经存在就替换old value(保证key的唯一性)如果bucket满了(超过load factor * current capacity)，就要resize。关于threshold和loadFactor大家都知道 threshold 的作用是当 size 大于 threshold 时就会进行 resize，但是 threshold 的值是多少呢？threshold = capacity * load factorloadFactor 默认为 0.75 是时间和空间上折中考虑。如果太大，虽然会减少空间的占用，但是会增加查询的时间度，因为发生碰撞的几率会提高，从而从 O(1) 退化为链表或者红黑树的查询。resize后如何保证key的位置JDK1.8由于 hash 方法的优化，所以 resize 也受到影响。官方的注释说，经过 rehash 之后，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。为什么会这样？我盗一下图元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化：上面的图说的很明白，如果原来的 hashcode 在高1位有值，那么在“取模”的运算中，这个“1”会被保留下来，所以 new index = old index + oldCap，如果高1位是0，结果还是跟原来一样。这个设计巧妙在于，整体容量扩容了1倍的意义是对每一个 table[i] 都公平的扩容了1倍，而对每个元素是否需要挪到新的 table[i + oldCap]就随机性般的取决于“高1位”是0还是1，在平均的情况下各占50%。我又盗一个图这个图说的很明白，原来在 15 的位置，在 resize 后，蓝色的还是在 15 的位置，绿色就变成在 31 的位置了（31 = 15 + 16）。还有一点注意就是，JDK1.7中rehash的时候，旧链表迁移新链表的时候，如果在新表的数组索引位置相同，则链表元素会倒置，但是在JDK1.8不会倒置。resize在高并发下引发的死循环这是在JDK1.7之前才会出现的问题，简单来说就是在高并发下，在内部操作时导致链表死循环引用。参考老生常谈，HashMap的死循环这根本原因是在 rehash 时，链表以倒序进行重新排列。但是在JDK1.8后，这个问题得到了优化这里的代码需要对应到上面有蓝色和绿色两个链表的图。loHead 和 loTail 代表蓝色的那个链表，也即“高1位”不为1的 hashcode 的那些节点，它们 resize 后还是放在原来的位置上。hiHead 和 hiTail 代表绿色的那个链表，也即“高1位”位1的 hashcode 的那些节点，它们 resize 后会放在 oldIndex + oldCap 的位置上。这里可以看出链表是以原来的顺序排列的，tail 节点不停往后追加，head 没有改变，遍历完之后就让 tab[i] 指向 head 就好了。JDK1.8 之后不仅解决了死循环的问题（虽然在并发下还有其他问题），而且代码也更加简洁易懂。为什么TREEIFY_THRESHOLD=8？我们看看官方的注释TREEIFY_THRESHOLD 的作用是链表转为红黑树的阈值，这个之前已经说了。那么为什么是8呢？继续看官方的注释大概意思是如果 hash 很理想，分布就会很平均，tree bins 就会很少用到。在理想的情况下，节点的分布符合柏松分布（Poisson distribution）。我们来分析一下，先看看柏松分布的概率函数我们假设事件 X=k 为某一个 bucket 有 k 个节点。柏松分布只有一个参数就是 λ，那么 λ 为多少呢？官方的说法是Ideally, the frequency of nodes in bins follows a Poisson distribution (http://en.wikipedia.org/wiki/Poisson_distribution) with a parameter of about 0.5 on average, given the resizing threshold of 0.75它说 λ = 0.5，但是我想了大半天都没想明白为什么是 0.5（如果有人知道的话，恳请您告诉我），我觉得有可能它是统计出来的。我说一下我的想法：二项分布的极限是柏松分布，我们可以根据二项分布的期望 λ=np 求出 λ（n 是实验的次数，p 是单次的概率）。如果 n 比较大，p 比较小，所以我们才说满足泊松分布的条件。我们知道如果 hash 很理想，那么分散在每个 bucket 的概率看作一样，p = 1 / s，s 为 bucket 的长度，如果进行了 n 次实验，那么 s = n / 0.75，所以代进去得出 λ = 0.75于是我们可以根据柏松分布得出事件 X=0，X=1 … 的概率分布0: 0.47241: 0.35432: 0.13293: 0.03324: 0.00625: 0.00096: 0.0001可以看出得到的结果跟官方的差不多，X=8 之前的概率累积接近1。也就是说在某一个 bucket 存在多于 8 个节点的概率极低，这就是 TREEIFY_THRESHOLD = 8 的原因。允许 null 值的原因ConcurrentHashmap 和 Hashtable 都是不允许 null 的 key 和 value 的，而 HashMap 允许，这是为什么呢？这样一对比，就很容易联想到是由于并发问题引起的。Doug Lea 是这么说的：The main reason that nulls aren’t allowed in ConcurrentMaps(ConcurrentHashMaps, ConcurrentSkipListMaps) is thatambiguities that may be just barely tolerable in non-concurrentmaps can’t be accommodated. The main one is that ifmap.get(key) returns null, you can’t detect whether thekey explicitly maps to null vs the key isn’t mapped.In a non-concurrent map, you can check this via map.contains(key),but in a concurrent one, the map might have changed between calls.大概意思是，在并发下，如果 map.get(key) = null，ConcurrentMap 无法判断 key 的 value 为null，还是 key 不存在。但是 HashMap 只考虑在非并发下运行，可以用 map.contains(key) 来做判断。大师还说I personally think that allowingnulls in Maps (also Sets) is an open invitation for programsto contain errors that remain undetected untilthey break at just the wrong time. (Whether to allow nulls evenin non-concurrent Maps/Sets is one of the few design issues surroundingCollections that Josh Bloch and I have long disagreed about.)Collections that Josh Bloch and I have long disagreed about.)Doug Lea 大师也说了，自己对 HashMap 允许 null 也是有争议的。这样做只能等到程序报错才发现错误。参考资料https://tech.meituan.com/java_hashmap.htmlhttps://www.jianshu.com/p/281137bdc223]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>源码</tag>
        <tag>hashmap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ScheduledThreadPoolExecutor原理]]></title>
    <url>%2Fposts%2F68efda44%2F</url>
    <content type="text"><![CDATA[概要ScheduledThreadPoolExecutor 是实现任务调度好工具，它的特点是提供了线程池。ScheduledThreadPoolExecutor原理相关类继承关系首先我们看看 ScheduledThreadPoolExecutor 是什么可以看出它是一个 ThreadPoolExecutor，还继承了 ScheduledExecutorService，这个接口定义了诸如 schedule，scheduleAtFixedRate，scheduleWithFixedDelay 等方法。ScheduledThreadPoolExecutor的创建先看看构造函数直接调用 super 的构造方法，即 ThreadPoolExecutor 的，只不过 maximumPoolSize 写死了是 Integer.MAX_VALUE，keepAliveTime 是 0，workQueue 是 DelayedWorkQueue（这个是 ScheduledThreadPoolExecutor 的专用内部 queue，等下会讲到）。为什么 maximumPoolSize = Integer.MAX_VALUE ？我看到网上有的说法是，如果对线程数做了限制，就会对定时任务的调度产生延时（假设任务太多，线程忙不过来），这种说法听上去挺合理的，但是是不正确的。可能 ScheduledThreadPoolExecutor 从一开始设计就没有说要严格准时的执行定时任务，所以压根儿就没有考虑这个问题。通过源码发现，maximumPoolSize 是根本没起作用的，线程的数量不会大于 corePoolSize。为什么 maximumPoolSize 没用？是因为 ScheduledThreadPoolExecutor 的 queue 是无界的（每次达到上限会增长50%，跟 DelayQueue 也即 PriorityQueue 一样；如果对这个答案不明白，你可能需要看看 ThreadPoolExecutor ）。为什么要用无界 queue ？我猜想是 queue 里面的 task 是延迟或周期性的，会长期驻留，对队列的长度有要求，如果公开给调用者设置或者给一个固定的值，都不合适，会产生问题，所以干脆无界。还有另外一个原因，设置了 maximumPoolSize 且有效，如果此时 wc &gt; corePoolSize，且队列头的任务 delay 很大，那么在高并发的情况下，会不断有 worker 新建和销毁，造成性能问题，甚至 GC。为什么 keepAliveTime = 0 ？一般情况下 maximumPoolSize 不起作用，那么 keepAliveTime 也是不起作用的。但是也可以通过 allowCoreThreadTimeOut 令到 keepAliveTime 生效（通过调用 allowCoreThreadTimeOut(true) 方法设置），但是这个 keepAliveTime 确实不好设置，试想如果 keepAliveTime 小于队列头的 delay，那么这个线程就会被回收掉，然后在下次又创建一个新的线程，这不是很多余吗，所以干脆 keepAliveTime = 0。定时任务的执行schedule方法ScheduledThreadPoolExecutor 覆盖了 AbstractExecutorService 的 submit 方法，submit 也是直接调用 schedule 方法，我们一般使用也是调用 schedule，我们看看 schedulescheduleWithFixedDelay 和 scheduleAtFixedRate 都是类似的，只有一个参数的区别，所以我一起讲scheduleWithFixedDelay 和 scheduleAtFixedRate 两个方法的区别，相信大家都知道，前者是上一次任务执行完，再延迟 delay 的时间再执行下一次，后者是上一次任务的执行开始时间加上 period 就是下一次任务的执行时间。我们看到 scheduleWithFixedDelay 和 scheduleAtFixedRate 基本是一样的，就只有当传到 ScheduledFutureTask 的入参时，delay 变成了一个负数，period 还是一样，这一点大家先记住，后面会用到。继续讲 schedule 方法decorateTask 方法只是让 ScheduledFutureTask 变成 RunnableScheduledFuture，使得 delayedExecute 更加通用ScheduledFutureTask 是 ScheduledThreadPoolExecutor 内部定义的任务类，从结构看，简单来说它就是一个 FutureTask + Delayed我们看看 ScheduledFutureTask 构造方法如果是 schedule 则 period 为0，scheduleWithFixedDelay 和 scheduleAtFixedRate 则等于入参，这就是一次性任务和周期性任务的区别如果是 schedule 则 period 为0，scheduleWithFixedDelay 和 scheduleAtFixedRate 则等于入参，这就是一次性任务和周期性任务的区别继续看看 delayedExecuteshutdown 就直接 reject；否则加入到队列，再发现是 shutdown 的话，就 remove 掉，中断 task；这里为什么直接加入队列？因为任务的延迟的，一定要确保从延迟队列中取出来运行。最后调用 ensurePrestart 确保有 worker 在运行；这里回应上面的， wc &lt; corePoolSize，所以 maximumPoolSize 是没用的。把任务加到队列了，注意由于队列 DelayedWorkQueue 是类似 DealyQueue，这涉及到 task 的 getDelay 和 compareTo （还记得上面说 ScheduledFutureTask 是一个 Delayed 吗 ），还有这个 queue 是一个二叉堆，涉及 siftUp 和 siftDown 的堆操作，这部分都跟 DealyQueue 比较相关，这里就不展开了。接下来就是 worker 从队列取出任务，取法跟 ThreadPoolExecutor 一样。run方法接下来就是 task 的运行ScheduledFutureTask 是一个 FutureTask，它覆盖了 run 方法canRunInCurrentRunState，刚刚我们在 delayedExecute 也遇到，它使用来判断线程池是否在运行 RUNNING，如果是 SHUTDOWN，是否允许终止任务；continueExistingPeriodicTasksAfterShutdown 意思是，对于周期性任务，在 SHUTDOWN 下，是否允许继续执行，默认是 false；executeExistingDelayedTasksAfterShutdown 意思是，对于非周期性任务，在 SHUTDOWN 下，是否允许继续执行，默认是 true；我们回到重点来，看红箭头。如果是非周期性任务，那么就调用 FutureTask 的 run 方法；如果是周期性任务，那么就调用 FutureTask 的 runAndReset 方法（runAndReset 跟 FutureTask 相关，这里不展开了），简单说就是这个 future 执行完之后会重置为 NEW 状态；setNextRunTime方法setNextRunTime 方法，计算任务下一次的执行时间（还记得上面我们说 delay 是负数，period 是原值吗？这里用到了，这两个值都是对应到这里的 period）如果 p &gt; 0 ，则在原来的时间上 time 直接追加 period，否则在 now() 的基础上追加triggerTime 获取下次执行任务的时间triggerTime防溢出这里还有一个巧妙的地方，我得说一下为什么 delay 要跟 Long.MAX_VALUE 右移一位比较？不急，我们先看看 overflowFree 方法注释已经把大意说清楚了，就是为了防止溢出。因为 head 的 getDealy 有可能是负数（一直没有出队运行），那么当前 task 加入队列时做 compareTo 就有可能溢出（减去一个负数得到一个大于 Long.MAX_VALUE 的数），那么这时比较的结果就不对了。首先 delay 肯定不为负数，我们分情况看一下：1、如果 headDealy 为正数（含0），两个正数相减不会溢出，这没问题2、如果 headDealy 为负数，那么只要 delay - headDealy &gt; Long.MAX_VALUE 就不是我们想要的结果，所以要对 delay 或 headDealy 做一下限制。我们回到刚刚提出的问题（ delay &lt; (Long.MAX_VALUE &gt;&gt; 1) ？）。之所以有这个做法，是因为对 delay 和 headDealy 的值做了一个折中。如果 delay &lt; (Long.MAX_VALUE &gt;&gt; 1) （Long.MAX_VALUE &gt;&gt; 1 就是 Long.MAX_VALUE 的一半），那么就直接用这个 delay 进队；如果大于的话，那就认为它做 compareTo 时极有可能会溢出（这个是人为的认为），那么就取出 headDealy 来试一下，真溢出了，就做调整。这里巧妙的地方在于，它给了 delay 和 headDealy 的值 Long.MAX_VALUE 的一半这么多的预留空间（各占一半），试想如果把 delay &lt; (Long.MAX_VALUE &gt;&gt; 1) 改为 delay &lt; Long.MAX_VALUE（极端为 delay = Long.MAX_VALUE 的情况），那么 headDealy 只要小于 0 就会溢出。所以只要 headDealy 大于 Long.MIN_VALUE &gt;&gt; 1 就不会溢出。当然，headDealy 是有可能小于 Long.MIN_VALUE &gt;&gt; 1 的，所以为了万一，最后还是会做调整。reExecutePeriodic方法我们继续回到重点 reExecutePeriodic 方法跟之前讲解的代码有点像，相信大家都看的明白了，主要就是把 task 加回到 queue 里。关闭线程池ScheduledThreadPoolExecutor 的 shutdown 和 shutdownNow 都是直接调用 ThreadPoolExecutor 的。至此，ScheduledThreadPoolExecutor 的大概流程和原理讲得7788了。Why DelayedWorkQueue?这里补充一下我在看 ScheduledThreadPoolExecutor 源码时心里最大的一个疑问。为什么不直接用 DealyQueue ，而是另外写了一个 DelayedWorkQueue？不过还好不用我们自己瞎猜，官方的注释给出了说明简单来说就是 DelayedWorkQueue 其实跟 DealyQueue 差不多，不过里面的元素 ScheduledFutureTask 会记录在堆的下标，做 remove 的时候时间复杂度从 O(n) 提升到 O(log n)。 所以 DelayedWorkQueue 重写了remove 方法，直接取出元素的 index。原来 DealyQueue 的做法是遍历数组找出元素的下标（如果元素不是 ScheduledFutureTask 类型也是这样做）+ 堆操作：O(n) + O(log n) 约等于 O(n) .DelayedWorkQueue 的操作变为直接取出下标 + 堆操作：O(1) + O(log n) 约等于 O(log n)总的时间复杂度从 O(n) -&gt; O(log n)总结ScheduledThreadPoolExecutor的实现跟 ThreadPoolExecutor类似，它利用了延迟队列 DealyQueue 对任务进行延迟运行。参考资料https://www.jianshu.com/p/2756fd08d0cdhttps://www.jianshu.com/p/d96e9f67dba5Java多线程复习与巩固（七）–任务调度线程池ScheduledThreadPoolExecutor]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>ScheduledThreadPoolExecutor</tag>
        <tag>调度线程池</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程池ThreadPoolExecutor实现原理]]></title>
    <url>%2Fposts%2Ff5cda8d1%2F</url>
    <content type="text"><![CDATA[概要线程池，大家都很熟悉了，我们在平时应用中也用的很多。对线程池，ThreadPoolExecutor 的实现原理有一定理解后，我们可以把它用的更好，对它的参数有更加深刻的理解，甚至我们可以扩展，监控自己的线程池。ThreadPoolExecutor实现原理本文代码基于JDK1.8线程池相关的类的关系我们先看看主要的类ThreadPoolExecutor的继承关系平时可能还有用到的 Executors 类，这是一个工具类，提供newFixedThreadPoolnewCachedThreadPoolnewScheduledThreadPool等静态方法方便我们创建线程池，最终还是调用 ThreadPoolExecutor 来创建的，一般规范不建议直接使用 Executors 来创建线程池。线程池创建的主流程线程池的状态先看看线程池的状态有哪些，对它有初步的理解线程池的状态和运行的线程数只用了一个 int，其中高3位表示状态，低29位表示线程数。状态表示的意思和状态之间的转换：RUNNING - 可以接受新的任务，及执行队列中的任务SHUTDOWN - 不接受新的任务，但会继续执行队列中的任务STOP - 不接受新的任务，既不会执行队列中的任务，还会中断执行中的任务TIDYING - 全部任务已经终止，且线程数为0TERMINATED - 线程池完全终止RUNNING -&gt; SHUTDOWN - 执行了 shutdown()(RUNNING or SHUTDOWN) -&gt; STOP - 执行了shutdownNow()SHUTDOWN -&gt; TIDYING - 队列和线程为空STOP -&gt; TIDYING - 线程为空TIDYING -&gt; TERMINATED - terminated() 这个勾子方法执行完毕线程池的创建ThreadPoolExecutor 的构造函数线程池的创建只是初始化了一些参数，但理解好这些参数对我们使用线程池很有帮助。corePoolSize - 核心线程数，除非 allowCoreThreadTimeOut 为 true（默认false），否则即使没有任务，也会维持这么多线程。maximumPoolSize - 最大线程数，corePoolSize 满了的话，会把任务放到队列，如果队列满了的话（假设队列有界），就会继续创建线程直到 maximumPoolSize，如果超过 maximumPoolSize 则会执行 reject 策略。workQueue - 用来存放任务的队列，是一个 BlockingQueue，常用的有 LinkedBlockingQueue，ArrayBlockingQueue，SynchronousQueue。keepAliveTime - 空闲线程的存活时间，如果当前线程数 &gt; corePoolSize，且某个线程空闲了这么多时间（没有获取到任务并运行），那么这个线程会被 remove 掉。unit - keepAliveTime 的单位，内部会统一转换成 nanosthreadFactory - 用来创建线程的 ThreadFactory，主要用来给线程命名（方便查看日志），设置 daemon，优先级和 group 等，Executors 有 DefaultThreadFactory 这个默认实现。handler - reject 具体执行策略，reject 的条件上面已经说了，一般内置有以下几个，也可以自己实现CallerRunsPolicy - 不使用线程池的线程执行该任务，直接用当前执行任务（例如 main 线程）AbortPolicy - 直接抛异常DiscardPolicy - 无视不做处理，相当于抛弃掉DiscardOldestPolicy - 将队列头的任务取出来抛弃掉，然后运行当前任务线程池的执行一般我们使用 ExecutorService 的 submit 方法来使用线程池执行一个任务，这个方法调用到 AbstractExecutorService这里我们看到所有 task 无论是 Callable 还是 Runnable 的都会包装成一个 RunnableFuture 也就是 FutureTask，返回给我们。execute方法重点看 execute 方法，调用了 ThreadPoolExecutor 的 execute我们分三种情形来看，每个是一个 if 条件：第一，当 workCount &lt; corePoolSize 时，直接创建 worker 线程；第二，如果上面创建失败（可能是线程池正在处于关闭状态，可能是 workCount &gt; corePoolSize 了 - 并发场景），那么这时把任务放入 workQueue 队列；下面的判断是用来防止，线程池不在运行了，就把任务删掉；如果没有线程了就加一个；第三，来到这步说明上面放队列不成功（可能是队列是有界的，满了），那么就继续创建线程来满足，如果这都创建失败（可能是 &gt; maximumPoolSize）就 reject 了；addWorker方法继续看看重点的 addWorker 方法，addWorker 分开两部分来看。这一步是判断是否可以增加 worker 的重点：第一，首先开始的判断有点奇怪，我也不是很明白，先认为它是如果状态是 SHUTDOWN 则不允许创建线程；第二，下面有个 core 参数，true 使用 corePoolSize，false 使用 maximumPoolSize，我们上面说的 execute 方法第一次就是传 true 的，第二次就传 false。所以这里就是对 size 做判断， 如果 &gt;= size 则返回 false，否则 cas 一下，成功了就 break 执行下面的代码；第三，如果 cas 失败，说明有其他并发竞争，则 cintinue 循环上面的步骤判断。来到这一步说明可以创建 worker 了，这里用了一个全局 lock，来控制创建线程和关闭线程的不能同时做。可以看到步骤就是 new 一个 worker，add 到 workers 里，workers 是一个 HashSet。largestPoolSize 来用记录最大的线程数。如果 workerStarted == false（线程池在关闭或创建 worker 时异常），则会 addWorkerFailed 方法。主要就是 remove 掉 worker，扣减计数，这里还会调用 tryTerminate 。这个方法会在很多地方用到，它的作用就是防止线程池在终止状态这种情形，去终止线程。Worker是什么我们刚刚一直说 worker，那到底 Worker 究竟是什么？我们现在来看看我们可以看到 Worker 是一个 AQS 和 Runnable。为什么是一个 AQS ？我们可以结合注释和代码可以得到，worker 在跑任务的时候会 lock 住，在被中断时会 tryLock，利用上锁这一点来区分这个 worker 是否空闲。Worker 中重写 AQS 的方法。（感概：AQS 真是个简单易用，用于并发控制的好工具！）为什么是一个 Runnable ？我们看看 Worker 的构造函数，在创建 Thread 时把自己 this 传到 thread 的参数，说明 worker 的 thread 跑的是自己，这时我们就知道 worker 的入口了。Worker 的 run 方法runWorker方法重点的 runWorker 方法task 可能是传进来的 firstTask 或者 getTask() 获取到的，getTask 也是重点方法，等下讲到；运行 task 时会上锁，锁的作用我刚刚已经说了；如果线程池状态是 STOP 则中断线程；这里放了两个勾子 beforeExecute 和 afterExecute 方法来提供给子类做点事情，一般用于监控或统计线程池的执行情况；执行任务就直接 task.run() 了，还记得我说过这个 task 是一个 FutureTask，如果run 的时候抛出异常，FutureTask 会 catch 掉不会再 throw（如果大家对 FutureTask 不熟悉就先这样理解），所以这里不会进入 catch，也就是不会 throw x 了。如果 task 不像 FutureTask 一样自己处理掉异常，那就会 throw x 了，那么 worker 的线程就会跳出 while 循环，完成使命，结束自己；获取不到 task （task 为null）或者循环过程中异常，最后都会执行 processWorkerExit。processWorkerExit 的作用主要就是 remove 掉 worker，那么扣减 workCount 呢？好像没有看到。这里用了 completedAbruptly 这一变量来控制是否在 processWorkerExit 扣减 workCount，因为有可能是在 getTask 已经扣减了，那么在 processWorkerExit 就不用重复扣减。我们结合 runWorker 来看看，分两种情况：1、如果 firstTask 为 null，那么会走到 getTask 方法，如果 getTask 返回 null，那么说明已经是扣减了，这时退出循环，completedAbruptly = false，不用重复扣减。2、如果 firstTask 不为 null（1）执行 firstTask 正常结束，然后循环，走到 getTask，如果返回 task 为 null，那么 completedAbruptly = false，不用重复扣减。（2）执行 firstTask 执行异常，这时 completedAbruptly = true，需要扣减这里我们又看到 tryTerminate 了；下面的判断主要是尝试去增加一个 worker，因为你 remove 掉了一个，如果条件允许，那就加回一个呗。getTask方法看看重点的 getTask 方法在 getTask 时如果发现时线程池在关闭状态，那么就需要停止获取任务了；如果 wc &gt; maximumPoolSize，超过了最大 size 了，就去 cas 扣减 workCount 一下，成功就返回 null；如果 wc &gt; corePoolSize（小于 maximumPoolSize），且 timedOut 的话，说明这个 worker 也有点“多余”，也去扣减 workCount。注意这里对 timedOut 的判断，通过 queue 的定时 poll 方法，时间是线程池的构造参数 keepAliveTime，如果过了这么久都还没获取 task，说明 queue 是空的，有空闲的线程，那就把这个 worker remove 掉吧；如果 wc &lt; corePoolSize 的话，那就调用 queue 的 take 方法一直阻塞获取 task；还有 allowCoreThreadTimeOut 参数，它的意思是忽略对 corePoolSize 的判断。关闭线程池上面已经把线程的创建和执行基本说得7788了，我们看看关闭线程池是如何做的，其实在上面的很多方法中，都看到很多对如 SHUTDOWN 的判断了。主要有 shutdown 和 shutdownNow 这两个方法。这两个方法很相似，从名字来看 shutdown 显得更加的柔性，实际也是。shutdown –不接受新的 task，在运行和已经在队列的 task 可以继续运行；把状态改为 SHUTDOWN；中断空闲 worker，这个在上面已经提到过了，用锁对是否空闲做判断。interruptIdleWorkers 打断空闲的线程这里还有个 onShutdown 勾子方法。shutdownNow –不接受新的 task，中断已经在运行的线程，清空队列；把状态改为 STOP；强制中断所有在运行 worker 的线程；drainQueue，相当于把队列的 task 丢弃掉；总结线程池ThreadPoolExecutor实现的原理，就是用 Worker 线程不停得取出队列中的任务来执行，根据参数对任务队列和 Workers 做限制，回收，调整。参考资料http://www.jianshu.com/p/87bff5cc8d8chttps://javadoop.com/post/java-thread-pool]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>源码</tag>
        <tag>线程池</tag>
        <tag>ThreadPoolExecutor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则回溯分析]]></title>
    <url>%2Fposts%2F2fa47d3c%2F</url>
    <content type="text"><![CDATA[概要这是对一次线上正则回溯引起的问题的分析，文章对当时问题进行了简化，从而深入源码分析正则引擎是如何进行回溯以及回溯的时间复杂度。正则回溯分析排查过程zabbix接受到警告之后在 zabbix 看到 cpu 直飚 100%，当堂一惊！（我是CPU，现在慌得一比）。看到是 5.27 后开始飚升，首先怀疑代码问题，认真翻了一下 5.27 前 commit 到 master 的代码，没有发现明显的死循环或者死锁。于是叫运维帮忙看一下机器状态和 dump 出 jstack。top &amp; jstack线上机器 top：dump：定位问题可以看出跟正则有关的调用栈很长，于是把问题定位在 validateUrl 方法上。这是一个用正则去校验一个外部电子发票链接url的方法，其中 url=1http://www.fapiao.com/dzfp-web/pdf/download?request=6e7JGmpM5neXWMVrv4ILd-kEn64HcUX4qL4a4qJ4-CEk7Azg.Vjit92m74H5oxkjgdsYazxcUmdJjKscGXhaJw__%5EHGabjgEIe其中，正则 pattern =1^([hH][tT]&#123;2&#125;[pP]://|[hH][tT]&#123;2&#125;[pP][sS]://)(([A-Za-z0-9-~]+).)+([A-Za-z0-9-~\/])+$原因分析阅读前提阅读下文时，我希望你对正则的基本用法、基本概念，正则的贪婪、懒惰、独占都有一定的理解。之前，我的一个同事已经对这个做了一定的分析，大家可以先阅读一下 藏在正则表达式里的陷阱回溯的定义在网上看了一下大致都说这个是跟正则的回溯有关，那究竟什么是正则的回溯呢？下面是我在网上找到一个比较好解释，可能看了之后还是懵逼，不怕，接下来会有详细解释使用 NFA 引擎的模式匹配由正则表达式中的语言元素驱动，而不是由输入字符串中要匹配的字符驱动。 因此，正则表达式引擎将尝试完全匹配可选或可替换的子表达式。 当它前进到子表达式中的下一个语言元素并且匹配不成功时，正则表达式引擎可放弃其成功匹配的一部分，并返回以前保存的与将正则表达式作为一个整体与输入字符串匹配有关的状态。 返回到以前保存状态以查找匹配的这一过程称为回溯。简化还原分析由于原来的url和pattern太长有点复杂，不好做分析，所以我进行了简化，方便做调试和分析。根据正则的贪婪和回溯特性，我做了如下的简化。（如果你对正则有一定的理解，相信你也会对原来url和pattern做到如下的简化）url=1aaaaaaaaaaaa_ （只是想表示有 n 个 a）pattern=1(a+)+以下的分析都是基于上面的ur和pattern。（基于JDK8）通过调试代码，我发现匹配字符的类最后是在 CharProperty 的 match 方法；其中通过 Character.codePointAt(seq, i) 这个方法获取需要匹配的字符，其实这个方法终于还是调用 CharSequence 的 charAt 这个方法123456789101112131415161718192021222324252627/** * Abstract node class to match one character satisfying some * boolean property. */private static abstract class CharProperty extends Node &#123; abstract boolean isSatisfiedBy(int ch); CharProperty complement() &#123; return new CharProperty() &#123; boolean isSatisfiedBy(int ch) &#123; return ! CharProperty.this.isSatisfiedBy(ch);&#125;&#125;; &#125; boolean match(Matcher matcher, int i, CharSequence seq) &#123; if (i &lt; matcher.to) &#123; int ch = Character.codePointAt(seq, i); return isSatisfiedBy(ch) &amp;&amp; next.match(matcher, i+Character.charCount(ch), seq); &#125; else &#123; matcher.hitEnd = true; return false; &#125; &#125; boolean study(TreeInfo info) &#123; info.minLength++; info.maxLength++; return next.study(info); &#125;&#125;于是我在 stackoverflow 找到一个继承 CharSequence 的类来做一些辅助 InterruptableCharSequence ，主要是打印当前匹配的字符和匹配次数，还有后面要做的中断。12345678910111213141516171819202122232425262728293031323334353637383940414243public class InterruptableCharSequence implements CharSequence&#123; CharSequence inner; public long counter = 0; public InterruptableCharSequence(CharSequence inner) &#123; super(); this.inner = inner; &#125; public long getCounter()&#123; return counter; &#125; @Override public char charAt(int index) &#123; boolean isInterrupt = Thread.currentThread().isInterrupted(); if(isInterrupt)&#123; System.out.println("currentThread has been set interrupt"); &#125; if (Thread.interrupted()) &#123; // clears flag if set System.out.println("interrupt !!!"); throw new RuntimeException(new InterruptedException("occur from InterruptableCharSequence")); &#125; counter++; System.out.println("charAt = " + inner.charAt(index)); return inner.charAt(index); &#125; @Override public int length() &#123; return inner.length(); &#125; @Override public CharSequence subSequence(int start, int end) &#123; return new InterruptableCharSequence(inner.subSequence(start, end)); &#125; @Override public String toString() &#123; return inner.toString(); &#125;&#125;推出时间复杂度通过调试代码和根据打印信息，可以得出正则回溯的匹配过程：假设 url=a_，pattern=(a+)+(1) a 匹配，继续(2) _ 不匹配以上两步是第一个 + 的匹配过程(3) 尝试匹配 _ 看看是不是可以结束以上这一步是第二个 + 的匹配过程(4) 没有回溯，结束（没有回溯是没有发生贪婪，发生贪婪的条件是从第一个字符匹配成功后，下一个字符又匹配成功）所以这时一共匹配了 3 步，匹配顺序为：1a _ _假设 url=aa_，pattern=(a+)+(1) ~ (3) 匹配到了 aa_(4) 尝试匹配 _ 看看是不是可以结束(5) 发生回溯，后退一步，递归 a_ 的匹配过程(n) 最终还是匹配不成功，结束所以这时一共匹配了 7 步，匹配顺序为：1a a _ _ a _ _假设 url=aaa_，pattern=(a+)+(1) ~ (4) 匹配到了 aaa_(5) 尝试匹配 _ 看看是不是可以结束(6) 发生回溯，后退一步，递归 a_ 的匹配过程(…) 上一步最终还是匹配不成功的，于是又后退一步，递归 aa_ 的匹配过程(n-1) 直到回退到第一个 a，回溯结束，已经遍历了所有的情况(n) 最终还是匹配不成功，结束所以一共匹配了 15 步，匹配顺序为：1a a a _ _ a _ _ a a _ _ a _ _根据上面我们可以推断出时间复杂度：1234567f(1) = 1f(2) = 3 = 2 + f(1)f(3) = 7 = 3 + f(2) + f(1)f(4) = 15 = 4 + f(3) + f(2) + f(1)f(n) = n + f(n-1) + f(n-2) + ... + f(1)所以 f(n) = 2 的N 次方 - 1可见恐怖！！回溯源码分析现在我们来回头看看正则回溯的相关代码，主要是在 Curly 的 match0 方法1234567891011121314151617181920212223242526272829303132333435363738394041// Greedy match.// i is the index to start matching at// j is the number of atoms that have matchedboolean match0(Matcher matcher, int i, int j, CharSequence seq) &#123; if (j &gt;= cmax) &#123; // We have matched the maximum... continue with the rest of // the regular expression return next.match(matcher, i, seq); &#125; int backLimit = j; while (atom.match(matcher, i, seq)) &#123; // k is the length of this match int k = matcher.last - i; if (k == 0) // Zero length match break; // Move up index and number matched i = matcher.last; j++; // We are greedy so match as many as we can while (j &lt; cmax) &#123; if (!atom.match(matcher, i, seq)) break; if (i + k != matcher.last) &#123; if (match0(matcher, matcher.last, j+1, seq)) return true; break; &#125; i += k; j++; &#125; // Handle backing off if match fails while (j &gt;= backLimit) &#123; if (next.match(matcher, i, seq)) return true; i -= k; j--; &#125; return false; &#125; return next.match(matcher, i, seq);&#125;从代码和注释得知，开始匹配成功后，就会进入贪婪模式，直到匹配不成功，然后开始发生回溯，用 backLimit 这个变量记录最开始匹配成功的下标，即允许回溯最后的地方。开始发生回溯的地方，即第33行的 next.match 方法，这个 next 指的是下一个节点（因为 java 实现 NFA 用了类似图（graph）的数据结构，匹配的地方，group开始和结束的地方等等都抽象成一个个 Node），由于第二个 + 的原因，构成了一个有环的图，于是发生递归。以下是我调试时根据 Node 的关系，画出来的图：线上问题的url分析&amp;解决现在回过头来看看导致线上问题的原因：先把正则简化一下， pattern=1^(http://)(([A-Za-z0-9-~]+).)+$加点打印信息，可以看出从第24行开始发生回溯 ：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741758 ww.fapiao.com/dzfp-web/pdf/download?request=6e7JGmpM5neXWMVrv4ILd-kEn64HcUX4qL4a4qJ4-CEk7Azg.Vjit92m74H5oxkjgdsYazxcUmdJjKscGXhaJw__%5EHGabjgEIe 12 apiao.com/dzfp-web/pdf/download?request=6e7JGmpM5neXWMVrv4ILd-kEn64HcUX4qL4a4qJ4-CEk7Azg.Vjit92m74H5oxkjgdsYazxcUmdJjKscGXhaJw__%5EHGabjgEIe 19 om/dzfp-web/pdf/download?request=6e7JGmpM5neXWMVrv4ILd-kEn64HcUX4qL4a4qJ4-CEk7Azg.Vjit92m74H5oxkjgdsYazxcUmdJjKscGXhaJw__%5EHGabjgEIe 23 zfp-web/pdf/download?request=6e7JGmpM5neXWMVrv4ILd-kEn64HcUX4qL4a4qJ4-CEk7Azg.Vjit92m74H5oxkjgdsYazxcUmdJjKscGXhaJw__%5EHGabjgEIe 32 df/download?request=6e7JGmpM5neXWMVrv4ILd-kEn64HcUX4qL4a4qJ4-CEk7Azg.Vjit92m74H5oxkjgdsYazxcUmdJjKscGXhaJw__%5EHGabjgEIe 36 ownload?request=6e7JGmpM5neXWMVrv4ILd-kEn64HcUX4qL4a4qJ4-CEk7Azg.Vjit92m74H5oxkjgdsYazxcUmdJjKscGXhaJw__%5EHGabjgEIe 45 equest=6e7JGmpM5neXWMVrv4ILd-kEn64HcUX4qL4a4qJ4-CEk7Azg.Vjit92m74H5oxkjgdsYazxcUmdJjKscGXhaJw__%5EHGabjgEIe 53 e7JGmpM5neXWMVrv4ILd-kEn64HcUX4qL4a4qJ4-CEk7Azg.Vjit92m74H5oxkjgdsYazxcUmdJjKscGXhaJw__%5EHGabjgEIe 102 jit92m74H5oxkjgdsYazxcUmdJjKscGXhaJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 136 Jw__%5EHGabjgEIe 138 __%5EHGabjgEIe 135 aJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 134 haJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 136 Jw__%5EHGabjgEIe 138 __%5EHGabjgEIe 133 XhaJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 136 Jw__%5EHGabjgEIe 138 __%5EHGabjgEIe 135 aJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 132 GXhaJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 136 Jw__%5EHGabjgEIe 138 __%5EHGabjgEIe 135 aJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 134 haJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 136 Jw__%5EHGabjgEIe 138 __%5EHGabjgEIe 131 cGXhaJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 136 Jw__%5EHGabjgEIe 138 __%5EHGabjgEIe 135 aJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 134 haJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 136 Jw__%5EHGabjgEIe 138 __%5EHGabjgEIe 133 XhaJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 136 Jw__%5EHGabjgEIe 138 __%5EHGabjgEIe 135 aJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 130 scGXhaJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 136 Jw__%5EHGabjgEIe 138 __%5EHGabjgEIe 135 aJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 134 haJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 136 Jw__%5EHGabjgEIe 138 __%5EHGabjgEIe 133 XhaJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 136 Jw__%5EHGabjgEIe 138 __%5EHGabjgEIe 135 aJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 132 GXhaJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 136 Jw__%5EHGabjgEIe于是，可选的解决方案有：使用可选限定符或替换构造的回溯123(http://)(([\\S]+).)(http://)(([\\S]+?).) (http://)(([A-Za-z0-9-~_%]+?).)非回溯子表达式1^(http://)(?&gt;([A-Za-z0-9-~]+).)+$如何避免综上，我个人总结以下四点来规避上面的正则回溯问题。充分考虑输入除了考虑正确的输入外，更重要的是考虑不匹配的输入！发生回溯都是因为不匹配导致的，正则会不停的尝试匹配，直到所有可能的情况。推荐一个探测工具：https://regex101.com/控制回溯发生回溯是因为正则用到了量词（quantifier）和 替换（alternation）（因为这两者为正则的匹配提供了可能性）。可以加上使用断言（assertions）或 独占模式（possessive），这样可以减少回溯的次数或者避免回溯，但是加上了断言和独占就要考虑对原来的匹配有没有产生影响，匹配结果是否还是一致。量词：?, *, +, {n，m}替换：[x|y] 类似这种断言：(?=exp), (?!exp) 类似这种独占模式：在量词后面再加上一个 +，表示匹配到此为止，不会回吐字符，即不会回溯。使用超时机制但是本人认为回溯是不能避免的，那么就可以使用超时机制，用中断线程的方法来强制结束线程，不要让它在死跑，耗尽CPU资源以下是本人写的一个小测试：12345678910111213141516171819202122232425262728293031323334public class RegexBug &#123; private static String regex3 = "(a+)+"; private static String harmful_url = "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa_"; private static Pattern URL_PATTERN; static ExecutorService threadPool = Executors.newCachedThreadPool(); public static void main(String[] args)throws Exception &#123; URL_PATTERN = Pattern.compile(regex3, Pattern.MULTILINE); long l1 = System.nanoTime(); CharSequence cs = new InterruptableCharSequence(harmful_url); Future&lt;Boolean&gt; future = null; future = threadPool.submit(() -&gt; validateUrl(cs)); try&#123; Boolean matchResult = future.get(5, TimeUnit.SECONDS); System.out.println("matchResult = " + matchResult); &#125;catch (TimeoutException e)&#123; e.printStackTrace(); future.cancel(true); &#125;catch (Exception e1)&#123; e1.printStackTrace(); &#125; System.out.println("pattern耗时 = " + (System.nanoTime() - l1) / (1000000)); System.out.println("counter = " + ((InterruptableCharSequence) cs).getCounter()); &#125; public static boolean validateUrl(CharSequence url) &#123; Matcher matcher = URL_PATTERN.matcher(url); return matcher.matches(); &#125; &#125;日志：使用现成工具校验与其自己写正则担心写出bug，不如用现成的工具。apache common-validator 了解一下参考资料https://www.cnblogs.com/study-everyday/p/7426862.htmlhttp://wwaw.cnblogs.com/chanshuyi/archive/2018/06/19/9197164.html7164.html]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>正则</tag>
        <tag>回溯</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo高级玩法]]></title>
    <url>%2Fposts%2Fbe8242cc%2F</url>
    <content type="text"><![CDATA[概要添加一些高级功能，可以让我们的网站显得更加丰富，多样性，简单说就是更高逼格。高级功能文章阅读统计我选择了 LeanCloud，这也是官方推荐使用的。网上有很多选择不蒜子的，也是可以的。注册 LeanCloud 账号Leancloud官网创建一个应用名字你喜欢就行创建一个Class点击进去应用注意名字必须为 Counter，勾选无限制的权限。修改主题配置修改 next 主题的_config.yml ，找到 leancloud_visitors ，修改为1234leancloud_visitors: enable: true app_id: xxx app_key: xxx其中 app_id 和 app_key 在 LeanCloud 的设置 -&gt; 应用 Key 可以找到重启查看这样就配置好了，重新生成 hexo 并发布，我们就可以看到文章阅读次数的统计。需要特别说明的是：记录文章访问量的唯一标识符是文章的发布日期以及文章的标题，因此请确保这两个数值组合的唯一性，如果你更改了这两个数值，会造成文章阅读数值的清零重计。在 LeanCloud 的后台我们可以看到一个整体的统计量，其中 time 字段就是统计数字，可以修改的哦。安全因为AppID以及AppKey是暴露在外的，因此如果一些别用用心之人知道了之后用于其它目的是得不偿失的，为了确保只用于我们自己的博客，建议开启Web安全选项，这样就只能通过我们自己的域名才有权访问后台的数据了，可以进一步提升安全性。评论功能在网上找了很多，有多说，畅言，来必力，gticomment，valine，选择 valine 是因为搞阅读统计的时候已经注册了 LeanCloud，可以顺手用上，而且 next 已经支持了 valine，可以简单快速用起来。在 LeanCloud 注册和创建应用上面已经做了修改主题配置文件找到 valine 配置项打开 enable，输入 appid 和 appkey ，其他自己设置。12345678910valine: enable: true appid: xxx appkey: xxx notify: false # mail notifier , https://github.com/xCss/Valine/wiki verify: false # Verification code placeholder: 走过路过，不留下点什么吗？ # comment box placeholder avatar: mm # gravatar style guest_info: nick,mail,link # custom comment header pageSize: 10 # pagination size效果这样就我们已经配置好了，重启hexo，看到文章底部出现评论框测试一下hexo d 发布后测试评论一条然后在 LeanCloud 后台可以看到，可以进行删除等操作。关闭评论如需取消某个 页面/文章 的评论，在 md 文件的 front-matter 中增加1comments: false字数统计使用 hexo-wordcount 插件，因为 next 主题已经支持了在 hexo 目录执行安装1npm i --save hexo-wordcount修改主题配置找到 post_wordcount 项123456post_wordcount: item_text: true wordcount: true # 单篇 字数统计 min2read: true # 单篇 阅读时长 totalcount: false # 网站 字数统计 separated_meta: true修改显示文字字数统计和阅读时长是没有单位，需要补上才比较清晰。修改以下文件1themes/next/layout/_macro/post.swig修改【字数统计】，找到如下代码：123&lt;span title=&quot;&#123;&#123; __(&apos;post.wordcount&apos;) &#125;&#125;&quot;&gt; &#123;&#123; wordcount(post.content) &#125;&#125;&lt;/span&gt;修改后为：123&lt;span title=&quot;&#123;&#123; __(&apos;post.wordcount&apos;) &#125;&#125;&quot;&gt; &#123;&#123; wordcount(post.content) &#125;&#125; 字&lt;/span&gt;同理，我们修改【阅读时长】，修改后如下：123&lt;span title=&quot;&#123;&#123; __(&apos;post.min2read&apos;) &#125;&#125;&quot;&gt; &#123;&#123; min2read(post.content) &#125;&#125; 分钟&lt;/span&gt;修改完成后，重新执行启动服务预览就可以了。如下：这个阅读的速度是可以修改的，默认是中文300，英文160字/每分钟，详细可以看 hexo-wordcount。站内搜索就是可以在你的网站搜索你网站内的内容安装 hexo-generator-searchdb在站点的根目录下执行1npm install hexo-generator-searchdb --save修改站点配置文件添加12345search: path: search.xml field: post format: html limit: 10000修改 next 主题配置文件找到 local_search 修改为 true12local_search: enable: true效果重启 hexo，可以看到在目录栏最下方出现了“搜索”菜单点击弹出框，就可以搜索被Google和百度收录google登陆 google search consolegoogle search console添加你的网站地址（需要google账号）进行验证google 需要验证你拥有该网站的权限，默认推荐的验证方式是在你的网站添加一个它提供的 html，但是由于 hexo 的静态文件是生成的，我们 clean 之后就没了，所以我们不适用这种方式（其实也可以做到）。我们使用另一种更加方便的方式。使用 meta 标签做法是修改主题配置文件，找到 google_site_verification，值修改为 google 提供的 meta 中 content 的内容1google_site_verification: xxxxx加了这个配置后 next 会自动帮我们插入 meta 标签了。我们重启，发布。然后点击上图的验证按钮，成功的话，就会看到以下提示然后我们点击“前往资源页面”，对我们网站其中一个页面进行检查，会提示站点不适用增加站点地图安装插件1npm install hexo-generator-sitemap --save在站点配置文件添加12sitemap: path: sitemap.xml修改站点配置文件，找到 url 项，改为你网站地址。默认是1http://yoursite.com如果你不修改这个，sitemap.xml 生成内容不正确。1url: https://albenw.github.io重新生成、发布，可以看到在 public 目录下生成了 sitemap.xml 文件。在 google search console 提交站点地图提交后结果，看到成功的状态在覆盖率可以看到 google 抓取你的页面，但是我们刚刚添加的网站还没被抓取，要等搜索引擎下一次更新索引你才能在 google 上搜到，请耐性等待。添加 robot.txt原来我是漏掉这一步，了解后发现原来这个文件对爬虫的抓取有一定的帮助，这也是SEO的优化，所以加上。在站点 source 目录下创建 robots.txt，内容如下：1234567891011121314# hexo robots.txtUser-agent: *Allow: /Allow: /archives/Disallow: /vendors/Disallow: /js/Disallow: /css/Disallow: /fonts/Disallow: /vendors/Disallow: /fancybox/Sitemap: https://albenw.github.io/sitemap.xmlSitemap: https://albenw.github.io/baidusitemap.xmlbaidu打开百度的站点管理百度站点管理添加一个站点验证同样我们使用 meta 标签验证修改主题配置文件，添加 baidu_site_verification 项，值为 content 内容。1baidu_site_verification: xxx注意，原来配置文件是没有 baidu_site_verification 这个项的，但是通过查看 layout/_partials/head.swig，我们发现其实 hexo 是支持的，如果 head.swig 没有，则需要我们手动在 head.swig 增加123&#123;% if theme.baidu_site_verification %&#125; &lt;meta name=&quot;baidu-site-verification&quot; content=&quot;&#123;&#123; theme.baidu_site_verification &#125;&#125;&quot; /&gt;&#123;% endif %&#125;配置好后，重新生成，发布，在点击百度站点页面的验证按钮。主动推送由于 github 禁止了百度的爬虫，所以我们不能像对 google 那样通过 sitemap 的方式被抓取到链接，即使你配置了也是没用的。除了 sitemap 还有主动推动和自动推送这两种方式，主动推动的原理是每次 deploy 的时候都把所有链接推送给百度，自动则是每次网站被访问时都把该链接推送给百度。通过对比，我觉得主动推动比价好，所以选用这种方式插件安装1npm install hexo-baidu-url-submit --save修改站点配置文件在 _config.yml，添加以下内容12345baidu_url_submit: count: 5 host: your_site token: your_token path: baidu_urls.txt其中 count 表示一次推送提交最新的N个链接；host 和 token 可以在百度站点页面-&gt;数据引入-&gt;链接提交可以找到；path 为生成的文件名，里面存有推送的，我们网站的链接地址。确保站点配置文件中的 url 项跟百度注册的站点一致同样修改站点配置文件的 deploy 项，我们原来已经有 git 的 deploy，现在增加对 baidu 的推送，最终是这样子的12345deploy:- type: git repo: git@github.com:albenw/albenw.github.io.git branch: master- type: baidu_url_submitter重新生成，发布 hexo d，可以看到推送给百度成功我们可以在百度站点页面-&gt;数据引入-&gt;链接提交看到成交推送的链接数量，不过还不能看当天的，要等明天。（一天后）可以看到提交量了。虽然推送成功了，但是百度不是马上抓取的，需要耐心等待，具体可以查看数据监控-&gt;索引量页面。留言板所谓留言板其实就是开一个空的 page ，然后可以有评论这样子。添加留言板的 page1hexo new page guestbook修改主题配置文件找到 next 的 _config.yml 文件里面的 menu 项，增加1guestbook: /guestbook因为这里使用的是中文，找到 next 主题的 languages 目录里面的zh-Hans.yml文件，menu子项中添加1guestbook: 留言设置留言板的图标next 主题的默认是 page 的名字就是图标 icon 的名字，由于没有 “guestbook” 这个 icon ，所以留言板左边的小图标是一个问号。由于 next 支持 Font Awesome 的所有图标，所以只需要到 Font Awesome 的网站找到你想要的图标，然后还是在主题配置文件的 menu 项，最终修改为1guestbook: /guestbook || comment效果page 默认是开了 comments 的，所以直接用就可以了。参考资料为NexT主题添加文章阅读量统计功能https://blog.csdn.net/blue_zy/article/details/79071414https://www.jianshu.com/p/baea8c95e39bhttp://theme-next.iissnan.com/third-party-services.html#local-searchhttps://www.jianshu.com/p/25145964abf3https://www.jianshu.com/p/5e68f78c7791Hexo插件之百度主动提交链接Hexo博客提交百度和Google收录]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>hexo高级</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo优化]]></title>
    <url>%2Fposts%2F3460d887%2F</url>
    <content type="text"><![CDATA[概要按照我之前hexo的安装部署，可以正常使用，但是或者存在性能或效率的问题，又或者在操作上不便，这篇文章希望能做一点优化和改善。优化图片插入与存放问题一般来说有一下两种方式图床就是图片的云存储，图片存放在云上，这种方式一般是先把图片上传上去，获取到链接，然后在 MD 中引用。我个人觉得这种做法操作麻烦，使用图床麻烦，要先上传图片又麻烦，而且如果图床不稳定，你的图片就可能显示不出来了，甚至图床挂了，你的图片就没了。本地可能我习惯用云笔记，我个人偏向使用在本地的。本地的做法一般是先把图片放在 hexo 站点的目录下，然后在 MD 中引用，这样也可以把图片上传到 github 做备份保存。但我觉得还是有两个问题，一是操作麻烦，二是管理图片。第一，我个人喜欢用 hexo-admin，直接在页面复制图片就行了。第二，hexo-admin 默认是放在 images 目录下的，但是如果文章越来越多，图片会很乱。关于这点 hexo 提供 post_asset_folder 参数配置，为 true 的话，在新建 post 时会在 _post 建一个同名文件夹（仅此而已），hexo 的初衷是想我们把图片放在里面，可惜 hexo-admin 对这个配置还不支持，我看它还是在 issue 里。所以到这里，我觉得还是没有好的做法，我自己的做法是放 images 目录，图片的命名要有规范，例如 post_name + “__“ + index 这样，方便做管理。这里提醒大家一点，编辑时使用的图片的路径和生成 html 时的是不一样的。html，js，css，images 压缩使用 hexo-all-minifier 插件，在站点目录执行1npm install hexo-all-minifier --save在站点配置文件 _config.yml ，增加一行即可1all_minifier: true在 hexo g 生成的时候会看到打印输出 xx% saved 这样的字眼，表示成功了。我觉得感觉是好像是。。快了一点。。吧。。文章唯一link更改文章题目或者变更文章发布时间，在默认设置下，文章链接都会改变，不利于搜索引擎收录，也不利于分享。这里还是涉及爬虫的知识点，如果链接的层级太深，则对SEO不友好。所以简短的、唯一永久链接才是更好的选择。安装插件1npm install hexo-abbrlink --save在站点配置文件中查找代码permalink，将其更改为1permalink: posts/:abbrlink/ # “posts/” 可自行更换修改配置然后在站点配置文件中添加如下代码1234# abbrlink configabbrlink: alg: crc32 # 算法：crc16(default) and crc32 rep: hex # 进制：dec(default) and hex效果重启 hexo 生效后，可以看到文章的链接不再是“日期+文章名”，而是配置的 permalink，后面的一串字符就是 abbrlink。特别的说明：由于加了这个配置之后文章的链接URL变了，所以之前如果有做“评论”或“访问计数”配置的，就会全部失效。预览首页进去是对每一篇文章都显示了所有内容，需要把当前文章滚动到末尾才能看到下一篇文章，这样不能让读者快速浏览到大概有哪些文章，不能一下子吸引到读者。在主题配置文件中找到 auto_excerpt 属性，将enable设置为true ，将length设置为想要预览到的字数123auto_excerpt:enable: true #将原有的false改为truelength: 300 #设置预览的字数在首页看到的效果图，它的摘要只是把文本存粹的按照 length 截取出来。SEO优化做seo优化有利于搜索引擎对你网站的索引，根据关键字提高你网站的排名，提高曝光率。title 优化使首页改为“网站名称-网站描述”这样的显示方式。打开 seo 项在主题配置文件找到 seo 项1seo: true修改 post 模版在站点目录 scaffolds\post.md 文件，添加 keywords 和 description 字段，用于生成的文章中添加关键字和描述。123456title: &#123;&#123; title &#125;&#125;date: &#123;&#123; date &#125;&#125;tags:keywords:description:---这样在首页文章的预览中就会变成 description，利于 SEO。添加 “nofollow” 标签nofollow是HTML的一个属性，用于告诉搜索引擎不要追踪特定的网页链接。可以用于阻止在PR值高的网站上以留言等方式添加链接从而提高自身网站排名的行为，以改善搜索结果的质量，防止垃圾链接的蔓延。网站站长也可对其网页中的付费链接使用nofollow来防止该链接降低搜索排名。对一些重要度低的网页内容使用nofollow，还可以使搜索引擎以不同的优先级别来抓取网页内容。by 维基百科修改footer.swig文件在 next 目录 layout_partials，找到两处 a标签加上 rel=”external nofollow” 属性。1&#123;&#123; __(&apos;footer.powered&apos;, &apos;&lt;a rel=&quot;external nofollow&quot; class=&quot;theme-link&quot; target=&quot;_blank&quot; href=&quot;https://hexo.io&quot;&gt;Hexo&lt;/a&gt;&apos;) &#125;&#125;1&lt;a rel=&quot;external nofollow&quot; class=&quot;theme-link&quot; target=&quot;_blank&quot; href=&quot;https://github.com/iissnan/hexo-theme-next&quot;&gt;修改sidebar.swig文件在 next 目录 layout_macro，将下面代码中的a标签加上rel=”external nofollow”属性，顺序如下。1&lt;a rel=&quot;external nofollow&quot; href=&quot;&#123;&#123; link.split(&apos;||&apos;)[0] | trim &#125;&#125;&quot; target=&quot;_blank&quot; title=&quot;&#123;&#123; name &#125;&#125;&quot;&gt;1&lt;a href=&quot;https://creativecommons.org/&#123;% if theme.creative_commons === &apos;zero&apos; %&#125;publicdomain/zero/1.0&#123;% else %&#125;licenses/&#123;&#123; theme.creative_commons &#125;&#125;/4.0&#123;% endif %&#125;/&quot; rel=&quot;external nofollow&quot; class=&quot;cc-opacity&quot; target=&quot;_blank&quot;&gt;1&lt;a href=&quot;&#123;&#123; link &#125;&#125;&quot; title=&quot;&#123;&#123; name &#125;&#125;&quot; rel=&quot;external nofollow&quot; target=&quot;_blank&quot;&gt;&#123;&#123; name &#125;&#125;&lt;/a&gt;其实就是把一些含有 target=”_blank” 或 链去其他网站的超链接给加上 nofollow ，提升 SEO 效率。唯一链接 permalink这个我们在上面已经做了。小技巧文章内引用自己的文章这是hexo的标签语法1234&#123;% post_link 文章文件名（不要后缀） 文章标题（可选） %&#125;&#123;% post_link Hello-World %&#125;&#123;% post_link Hello-World 你好世界 %&#125;注意文章名字和文章标题不能有空格，有的话不能生效，还不知怎么解决。直到我增加了站内搜索功能后，好奇搜索结果是怎么链接到文章的呢，于是我看了一下，如下1&lt;a href=&quot;/2018/09/04/Hexo-Github-Pages安装部署/&quot; class=&quot;search-result-title&quot;&gt;&lt;b class=&quot;search-keyword&quot;&gt;Hexo&lt;/b&gt;+Github Pages安装部署&lt;/a&gt;可以看出原来 post 的名字是 “Hexo+Github Pages安装部署”，但是生成静态页面就变成了 “Hexo-Github-Pages安装部署”。然后我拿这个 “Hexo-Github-Pages安装部署”放到上面一试，发现可以了！看来生成后 post 的名字如果单词之间有特殊符号会统一变成“-”？？插入图片在 hexo-admin 直接复制图片会是这样子1![upload successful](/images/hexo优化__0.png)但是这样直接显示在页面不适合，我们一般需要调整大小或位置调整图片的显示hexo 支持的标签语法1&#123;% img [class names] /path/to/image [width] [height] [title text [alt text]] %&#125;不过不能在 hexo-amdin 看到。img 标签1&lt;img src=&quot;/images/hexo-admin安装使用__0.png&quot; width=&quot;600px&quot; height=&quot;200px&quot; align=center&gt;这样可以在直接 hexo-admin 中显示，路径也兼容生成后的 html。]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo-admin安装使用]]></title>
    <url>%2Fposts%2F4ffa5bc6%2F</url>
    <content type="text"><![CDATA[概要如果自己编辑 MD 文件的话，确实比较麻烦，你可以用一些 MD 的编辑器，但是在管理 MD 文件上还是操作不方便。这里推荐使用 hexo-admin，而且编辑完之后可以马上看到效果呢。需要说明的是，hexo-admin 管理是本地用的，就是你需要在本地编辑完之后再上传到 github，而不能直接在线编辑保存，因为 github pages 只支持静态页面的。安装过程安装过程中可能涉及到一些前提或内容，请参考我的另一篇文章Hexo-Github-Pages安装部署前提基于版本”hexo”: “^3.7.0”，”hexo-admin”: “^2.3.0”。安装 hexo-admincd hexo 目录1npm install --save hexo-admin启动 hexo1hexo s然后打开 http://localhost:4000/admin/ 就可以看到管理页面。在 hexo-admin 你可以Pages - 新加 page；Posts - 新加或删除 post；双击一个 post，你可以编辑，预览，新增修改 tags、categories，选择发布或不发布；Settings - 一些配置；Deploy - 可以直接部署到 github。问题minimatch1npm WARN deprecated minimatch@2.0.10: Please update to minimatch 3.0.2 or higher to avoid a RegExp DoS issue当你安装 hexo-admin，执行 npm install –save hexo-admin 时，可能会遇到上面的错误提示，是因为你缺少了一些依赖，执行下面的就好了。12npm install minimatch@&quot;3.0.2&quot; npm update -dConfig value “admin.deployCommand” not found当你第一次点击 Deploy 按钮时，可能会遇到上述的错误，因为缺少了执行 deploy 的命令，这个问题已经有人提了 issue 并且解决了https://github.com/jaredly/hexo-admin/issues/70还需要注意的是，issue 中的脚本只是 hexo deploy，只是做 deploy 操作，但是一般我们的使用习惯是编辑完之后 deploy，所以是要 deploy 最新的，需要把脚本改为即可123#!/usr/bin/env shhexo ghexo ddeploy 后你可能看到1234Std Error(node:83411) [DEP0061] DeprecationWarning: fs.SyncWriteStream is deprecated.Warning: Permanently added the RSA host key for IP address &apos;13.229.188.59&apos; to the list of known hosts.Everything up-to-date这不是错误，你可以不用管。说明已经 deploy 成功。复制图片时的一个小问题hexo-admin 编辑时支持直接复制图片（截图）到内容，这点是我比较喜欢的。但是有个问题，复制进去后是加载不出来的，会出现图裂的小图标。这时你只需要点击别的页面，再点回来就可以看到了，就是“刷”一下就好了，最简单的就是点击右上角打勾的按钮，这个按钮的作用是拼写检查，点一下再点回来，就可以看到你刚复制进去的图片了。这大概是因为 hexo-admin 对图片做了延迟加载，具体可以看看这篇文章说的https://htchz.me/2018/03/10/Hexo/参考资料https://www.jianshu.com/p/68e727dda16dhttps://blog.kinpzz.com/2016/12/31/hexo-admin-backend-management/https://github.com/jaredly/hexo-admin]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo-admin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo+Github Pages安装部署]]></title>
    <url>%2Fposts%2F3454819c%2F</url>
    <content type="text"><![CDATA[概要想低成本的搞一个博客，在网上找了很多参考资料，于是尝试 Hexo+Github Pages 折腾一下。我把自己的搭建过程记录下来，把其中遇到的一些问题也跟大家分享。安装过程前提我用的是 macOS 系统；node、npm、git 等的安装，还有 github 的配置就不多讲了；基于 hexo 的 3.7.0 版本。安装 hexo 客户端1npm install -g hexo-cli创建一个用来放 hexo 的文件夹（假设为 hexo）cd 进去，创建 hexo 站点1hexo init使用 next 主题为了博客的美观和使用上方面，我使用的大众的 next 主题。cd themes 目录。下载 next 主题1git clone https://github.com/iissnan/hexo-theme-next修改 theme编辑 hexo/_config.yml，找到 theme 那一行配置，修改为 next本地启动看看安装完之后，我们可以在本地启动看看博客初始化的效果。生成静态文件1hexo ghexo 最终运行的是静态文件，包括js，css和html等，这些文件统一放在 public 文件夹。安装 hexo-server1npm install hexo-server --save启动 server1hexo s在浏览器打开 localhost:4000，会看到一个 Hello World的页面。恭喜你，部署成功。部署到 github把 hexo 生成的静态文件上传到 github，别人就可以在 github 的网站上看到你的博客了。创建 repo在 github 上创建一个仓库，repo的名字为 username.github.io安装 deploy 插件cd 到 hexo 目录，执行1npm install hexo-deployer-git --save修改 deploy 相关配置编辑 hexo/_config.yml，修改 deploy 下几个属性123type: gitrepo: （git地址）branch: masterpush 到 github1hexo d就会自动把 public 文件夹下所有内容 push 到 master。注意这里看一下 git config user.name\email 是否正确。打开网页打开 username.github.io 就可以看到了添加“分类”，“关于”和“标签”菜单到此已经把博客基本的安装和部署好了。但是我们还需要做一些基本配置，让我们可以维护博客。打开 tags，about，categories在主题配置文件 next/_config.yml 在 menu 下去掉 tags，about，categories 注释。注意这里“主题配置文件”指的是 themes/next 目录的下的 _config.yml。创建 tags，about，categories在 hexo 文件夹1hexo new page tags会在 source 文件夹生成 tags 文件夹，编辑里面的 index.md ，添加12type: "tags"comments: false同样的方法添加 categories；添加 about 不需要修改 md 文件的 type，因为 tags，categories 是特殊目录类型，about 只是简单的一个 md。为文章添加标签和分类在文章 md 文件开头 title 的下面，增加类似，就可以归类到 tag 和 category1234tag:- a_tagcategories:- a_category添加头像图片在 hexo/_config.yml 找到配置 avatar，增加图片路径1avatar: /images/avatar.jpeg新建文章1hexo new post new1就会在 source/_post 文件夹下生成 new1.md 文件，编辑 md 文件即可。这里为什么是 post ？这里涉及 hexo 的模版行为，在 scaffolds 目录下初始定义了3个模板，draft、page、post，文章就是用到了 post。代码管理首先要搞清楚，hexo d 会把 public 文件夹 push 到 username.github.io 这个 repo 的 master 分支。但是这些文件都是一些生成出来的html，css，js 等，对我们没用，所以我们需要把原始文件如 md，images，_config.yml 等文件也需要保存下来，说白了就是把上述的文件也上传到 github，但是我们已经把 public push 到 master了，这时我们可以在 github 上再建一个 repo 来放我们的代码，我的选择是在 username.github.io 上建一个分支放，其实操作是差不多的。其实，我们可以发现在 hexo 文件夹下有一个 .gitignore 文件，这时 hexo 帮我们准备好的，里面的内容：1234567.DS_StoreThumbs.dbdb.json*.lognode_modules/public/.deploy*/可以看出 hexo 已经为我们想好了，public、node_modules、.deploy_git 等非源码文件都忽略了。具体自己看情况，这个 .gitignore 我没动。有个坑下载下来的是一个 git 库，如果你等下把整个 next 文件夹 push 的话，那么在 github 上 next 文件夹是灰色的，你是操作不了，这可能跟 github 权限有关。所以你要先把 next 下的 .git 文件夹删掉。在 hexo 文件夹执行12345678git init git add .git commit -m "hexo-src init"git branch hexo-srcgit checkout hexo-srcgit remote add origin （username.github.io 的 repo git 地址）git push -f origin hexo-src - 强推上去git branch --set-upstream hexo-src origin/hexo-src - 关联上好了，以后改完文章或者修改完主题配置，就可以 push 到 github 了。参考资料https://blog.csdn.net/u012195214/article/details/79204088http://www.wuxubj.cn/2016/08/Hexo-nexT-build-personal-blog/#https://zhiho.github.io/2015/09/29/hexo-next/http://theme-next.iissnan.com/getting-started.htmlhttp://www.lzblog.cn/2016/04/07/Hexo%E7%AB%99%E7%82%B9%E3%80%81NexT%E4%B8%BB%E9%A2%98%E4%BF%AE%E6%94%B9%E5%85%A8%E8%AE%B0%E5%BD%95/https://codezjx.com/2017/07/31/hexo-guide/]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fposts%2F4a17b156%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.Quick StartCreate a new post1$ hexo new "My New Post"More info: WritingRun server1$ hexo serverMore info: ServerGenerate static files1$ hexo generateMore info: GeneratingDeploy to remote sites1$ hexo deployMore info: Deployment]]></content>
      <categories>
        <category>index</category>
      </categories>
      <tags>
        <tag>index</tag>
      </tags>
  </entry>
</search>

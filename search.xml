<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[堆排序]]></title>
    <url>%2Fposts%2Fc2a5fdc5%2F</url>
    <content type="text"><![CDATA[概要堆排序是一种重要数据结构+算法，一般作为优先级队列的底层数据结构，对它的理解有助于我们更好，更快速的对上层工具的使用。堆排序原理堆排序算法介绍堆是一种重要的数据结构，为一棵完全二叉树, 底层如果用数组存储数据的话，假设某个元素为序号为i(Java数组从0开始,i为0到n-1)。如果它有左子树，那么左子树的位置是2i+1；如果有右子树，右子树的位置是2i+2；如果有父节点，父节点的位置是(n-1)/2取整；分为最大堆和最小堆，最大堆的任意子树根节点不小于任意子结点，最小堆的根节点不大于任意子结点。所谓堆排序就是利用堆这种数据结构来对数组排序，我们使用的是最大堆。处理的思想和冒泡排序，选择排序非常的类似，一层层封顶，只是最大元素的选取使用了最大堆。最大堆的最大元素一定在第0位置，构建好堆之后，交换0位置元素与顶即可。堆排序为原位排序(空间小), 且最坏运行时间是O(nlgn)，是渐进最优的比较排序算法。堆排序的条件1、是一棵完全二叉树（除了最后一层之外的其他每一层都被完全填充，并且所有结点都保持向左对齐）2、最大堆要求节点的元素都要不小于其孩子，最小堆要求节点元素都不大于其左右孩子构造堆的过程（以最大堆为例）假设初始数组为 [1,2,3,4,5,6,7]1、从 array.length / 2 开始，即节点42、节点4没有子节点，结束3、到节点3，3和孩子6和7比较，7比较大，和3交换，变成了图24、到节点2，2和5交换，变成了图35、到节点1，1和7交换后，破坏了原来 7 -&gt; 6, 3 的顺序，需要继续调整，于是1和6交换，变成了图4，结束堆排序的步骤（以最大堆为例）1、对数组 n 个元素构建最大堆 （就是上面的过程）2、将堆顶最大值和数组最后的元素进行替换3、由于步骤2的的交换可能破环了最大堆的性质，第0个不再是最大元素，就对当前元素进行调整，调整的方法跟上面说的是一样的，最终的结果会得到一个最大堆。代码及说明123456789101112131415161718192021222324252627282930313233343536373839404142public static void heapSort(int[] array) &#123; if (array == null || array.length &lt;= 1) &#123; return; &#125; buildMaxHeap(array); for (int i = array.length - 1; i &gt;= 1; i--) &#123; ArrayUtils.exchangeElements(array, 0, i); maxHeap(array, i, 0); &#125; &#125; private static void buildMaxHeap(int[] array) &#123; if (array == null || array.length &lt;= 1) &#123; return; &#125; int half = array.length / 2; for (int i = half; i &gt;= 0; i--) &#123; maxHeap(array, array.length, i); &#125; &#125; private static void maxHeap(int[] array, int heapSize, int index) &#123; int left = index * 2 + 1; int right = index * 2 + 2; int largest = index; if (left &lt; heapSize &amp;&amp; array[left] &gt; array[index]) &#123; largest = left; &#125; if (right &lt; heapSize &amp;&amp; array[right] &gt; array[largest]) &#123; largest = right; &#125; if (index != largest) &#123; ArrayUtils.exchangeElements(array, index, largest); maxHeap(array, heapSize, largest); &#125; &#125;heapSort是入口方法，buildMaxHeap是构建最大堆，maxHeap是每次对节点的调整。可以看出，我们一开始构建堆，从 array.length / 2 开始，直到第0个，这样就把最大堆构建好了。maxHeap是核心算法，它的作用是跟两个子节点比较，如果发现有比它大的，就交换，如果发生交换，就从交换的节点继续调整。总结用一个数组代表一棵完全二叉树：左节点在 2*i + 1 的位置右节点在 2*i + 2 的位置父节点在（i - 1）/2 的位置如果要做升序排序则要构造最大堆，因为根节点会输出在数组的最后。一开始是一个无序的数组，要先构造最大堆，构造最大堆的逻辑就是从 i = （array.length - 1）/ 2 开始，i – ，即从半数开始即可（因为根据完全二叉树的性质，半数之后的都是叶子结点），然后去构造这些子树为最大堆，直到根节点。当构造好最大堆后，这时根节点肯定为最大值，将根节点与数组最后的数交换，即将最大值输出到最后，这时最大堆被破坏了，需要重新调整，让其符合最大堆的性质，就是从交换后的位置开始，因为如果发生交换了，就说明比较大的节点“上去了”，原来小的父节点“下来了”，但是原来的父节点下来后，是否满足要求呢，要从这个节点继续做调整（整个过程相当于大的节点不停的“浮上去”，小的节点不停的“沉下去”）。那么完成这一操作后，数组就是按照升序排列。既然是一个二叉树，堆排序为什么不用链表实现？其实也是可以的，不过我认为还有几点考虑：1、链表的结构消耗更多的内存2、数组可以提供索引来快速检索3、链表的优势在插入，但堆的数组在插入后的调整也是O(log n)，也不差参考资料https://www.cnblogs.com/Java3y/p/8639937.html]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>排序</tag>
        <tag>算法</tag>
        <tag>数据结构</tag>
        <tag>HeapSort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于HashMap的一些理解]]></title>
    <url>%2Fposts%2Fdf45eaf1%2F</url>
    <content type="text"><![CDATA[概要本文主要补充对HashMap的一些理解、分析。相信大家对HashMap都很熟悉，但是其中的一些细节上的设计、思想，往往会被大家忽略，这些都是构成HashMap的重要组成部分，包括有“如何做hash”，“resize后如何保证key的位置”，“resize在高并发下引发的死循环”，“为什么 TREEIFY_THRESHOLD = 8？”，“允许null值的原因”等等，希望有你感兴趣的。补充对HashMap的几点理解为什么JDK 1.8后链表改为红黑树当 HashMap 中有大量的元素都存放到同一个桶中时，这个桶下有一条长长的链表，这个时候 HashMap 就相当于一个单链表，假如单链表有 n 个元素，遍历的时间复杂度就是 O(n)，如果 hash 冲突严重，由这里产生的性能问题尤为突显。JDK 1.8 中引入了红黑树，当链表长度 &gt;= TREEIFY_THRESHOLD（8） &amp; tab.length &gt;= MIN_TREEIFY_CAPACITY（64）时，链表就会转化为红黑树，它的查找时间复杂度为 O(logn)，以此来优化这个问题。如何做hash这是JDK1.8优化之后的样子，key.hashCode() 是个 int 即 32位；h &gt;&gt;&gt; 16 表示无符号右移 16 位，即保留高16位；（&gt;&gt;&gt; 意思是右移时无论是正数还是负数，高位统一补0；&gt;&gt; 遇到负数时高位是补1的）然后，用高16位异或低16位，得到新的低16位，得到的结果就是高16位是原来的高16位，低16位是原来高16位和原来低16位的异或结果。为什么要这样做？我们再看看取出数组下标的方法再说。定位到 table[] 的下标就是 (length - 1 ) &amp; hash（原来这一行代码在JDK1.7是一个叫做 indexFor 的方法，JDK1.8把这个方法删掉了）。没错就是通过 &amp; 的操作，通过 &amp; 运算可以获得一个小于 length - 1 的值。hash &amp; (size -1 ) 相当于做模运算，不过这里的 size 是保证等于 2 的 N 次方，这样“取模”比 % 效率更高。原理很简单，试想任意一个数（11010），与（size -1 ）一个二进制全都是1的数（1111），那么高位与0等于0，低位与1等于自己，然后就会得出比（1111）小的数，相当于模运算，注意这里只是“相当于”，意思是这样的运算与模运算相似，但是两者在结果上是不等的。那么我们回答一下刚刚的问题：既然“取模”会忽略高位，那么在 size 比较小的情况下，“取模”结果就取决于低位，譬如 241（11110001） 和 1009（1111110001） 这两个 hashcode 对 size 为16（1111） 的“取模”结果都是 1，但是这两个数还是相差比较大的嘛，我们的本意是希望尽量的分散。那么 (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16) 的做法就是把高16位加入到低16位去，以此来让低位16位保留高16位的“特征”（高16位是这个 hashcode 的主要特征，这样做法就是可以让低16位也可以表现出这个数的主要特征），同时也加大低16位的随机性。这样做的目的主要是为了提高运算的速度和 hash 的效率，防止 hash 冲突。JDK1.7的hash算法由于“不怎么随机”，发生过类似 DOS 的攻击HASH COLLISION DOS 问题putVal的思路大概思路：对key的hashCode()做hash，然后再计算index；如果没碰撞直接放到bucket里；如果碰撞了，以链表的形式存在buckets后；如果碰撞导致链表过长(大于等于TREEIFY_THRESHOLD)，就把链表转换成红黑树；如果节点已经存在就替换old value(保证key的唯一性)如果bucket满了(超过load factor * current capacity)，就要resize。关于threshold和loadFactor大家都知道 threshold 的作用是当 size 大于 threshold 时就会进行 resize，但是 threshold 的值是多少呢？threshold = capacity * load factorloadFactor 默认为 0.75 是时间和空间上折中考虑。如果太大，虽然会减少空间的占用，但是会增加查询的时间度，因为发生碰撞的几率会提高，从而从 O(1) 退化为链表或者红黑树的查询。resize后如何保证key的位置JDK1.8由于 hash 方法的优化，所以 resize 也受到影响。官方的注释说，经过 rehash 之后，元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置。为什么会这样？我盗一下图元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化：上面的图说的很明白，如果原来的 hashcode 在高1位有值，那么在“取模”的运算中，这个“1”会被保留下来，所以 new index = old index + oldCap，如果高1位是0，结果还是跟原来一样。这个设计巧妙在于，整体容量扩容了1倍的意义是对每一个 table[i] 都公平的扩容了1倍，而对每个元素是否需要挪到新的 table[i + oldCap]就随机性般的取决于“高1位”是0还是1，在平均的情况下各占50%。我又盗一个图这个图说的很明白，原来在 15 的位置，在 resize 后，蓝色的还是在 15 的位置，绿色就变成在 31 的位置了（31 = 15 + 16）。还有一点注意就是，JDK1.7中rehash的时候，旧链表迁移新链表的时候，如果在新表的数组索引位置相同，则链表元素会倒置，但是在JDK1.8不会倒置。resize在高并发下引发的死循环这是在JDK1.7之前才会出现的问题，简单来说就是在高并发下，在内部操作时导致链表死循环引用。参考老生常谈，HashMap的死循环这根本原因是在 rehash 时，链表以倒序进行重新排列。但是在JDK1.8后，这个问题得到了优化这里的代码需要对应到上面有蓝色和绿色两个链表的图。loHead 和 loTail 代表蓝色的那个链表，也即“高1位”不为1的 hashcode 的那些节点，它们 resize 后还是放在原来的位置上。hiHead 和 hiTail 代表绿色的那个链表，也即“高1位”位1的 hashcode 的那些节点，它们 resize 后会放在 oldIndex + oldCap 的位置上。这里可以看出链表是以原来的顺序排列的，tail 节点不停往后追加，head 没有改变，遍历完之后就让 tab[i] 指向 head 就好了。JDK1.8 之后不仅解决了死循环的问题（虽然在并发下还有其他问题），而且代码也更加简洁易懂。为什么TREEIFY_THRESHOLD=8？我们看看官方的注释TREEIFY_THRESHOLD 的作用是链表转为红黑树的阈值，这个之前已经说了。那么为什么是8呢？继续看官方的注释大概意思是如果 hash 很理想，分布就会很平均，tree bins 就会很少用到。在理想的情况下，节点的分布符合柏松分布（Poisson distribution）。我们来分析一下，先看看柏松分布的概率函数我们假设事件 X=k 为某一个 bucket 有 k 个节点。柏松分布只有一个参数就是 λ，那么 λ 为多少呢？官方的说法是Ideally, the frequency of nodes in bins follows a Poisson distribution (http://en.wikipedia.org/wiki/Poisson_distribution) with a parameter of about 0.5 on average, given the resizing threshold of 0.75它说 λ = 0.5，但是我想了大半天都没想明白为什么是 0.5（如果有人知道的话，恳请您告诉我），我觉得有可能它是统计出来的。我说一下我的想法：二项分布的极限是柏松分布，我们可以根据二项分布的期望 λ=np 求出 λ（n 是实验的次数，p 是单次的概率）。如果 n 比较大，p 比较小，所以我们才说满足泊松分布的条件。我们知道如果 hash 很理想，那么分散在每个 bucket 的概率看作一样，p = 1 / s，s 为 bucket 的长度，如果进行了 n 次实验，那么 s = n / 0.75，所以代进去得出 λ = 0.75于是我们可以根据柏松分布得出事件 X=0，X=1 … 的概率分布0: 0.47241: 0.35432: 0.13293: 0.03324: 0.00625: 0.00096: 0.0001可以看出得到的结果跟官方的差不多，X=8 之前的概率累积接近1。也就是说在某一个 bucket 存在多于 8 个节点的概率极低，这就是 TREEIFY_THRESHOLD = 8 的原因。允许 null 值的原因ConcurrentHashmap 和 Hashtable 都是不允许 null 的 key 和 value 的，而 HashMap 允许，这是为什么呢？这样一对比，就很容易联想到是由于并发问题引起的。Doug Lea 是这么说的：The main reason that nulls aren’t allowed in ConcurrentMaps(ConcurrentHashMaps, ConcurrentSkipListMaps) is thatambiguities that may be just barely tolerable in non-concurrentmaps can’t be accommodated. The main one is that ifmap.get(key) returns null, you can’t detect whether thekey explicitly maps to null vs the key isn’t mapped.In a non-concurrent map, you can check this via map.contains(key),but in a concurrent one, the map might have changed between calls.大概意思是，在并发下，如果 map.get(key) = null，ConcurrentMap 无法判断 key 的 value 为null，还是 key 不存在。但是 HashMap 只考虑在非并发下运行，可以用 map.contains(key) 来做判断。大师还说I personally think that allowingnulls in Maps (also Sets) is an open invitation for programsto contain errors that remain undetected untilthey break at just the wrong time. (Whether to allow nulls evenin non-concurrent Maps/Sets is one of the few design issues surroundingCollections that Josh Bloch and I have long disagreed about.)Collections that Josh Bloch and I have long disagreed about.)Doug Lea 大师也说了，自己对 HashMap 允许 null 也是有争议的。这样做只能等到程序报错才发现错误。参考资料https://tech.meituan.com/java_hashmap.htmlhttps://www.jianshu.com/p/281137bdc223]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>源码</tag>
        <tag>hashmap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ScheduledThreadPoolExecutor原理]]></title>
    <url>%2Fposts%2F68efda44%2F</url>
    <content type="text"><![CDATA[概要ScheduledThreadPoolExecutor 是实现任务调度好工具，它的特点是提供了线程池。ScheduledThreadPoolExecutor原理相关类继承关系首先我们看看 ScheduledThreadPoolExecutor 是什么可以看出它是一个 ThreadPoolExecutor，还继承了 ScheduledExecutorService，这个接口定义了诸如 schedule，scheduleAtFixedRate，scheduleWithFixedDelay 等方法。ScheduledThreadPoolExecutor的创建先看看构造函数直接调用 super 的构造方法，即 ThreadPoolExecutor 的，只不过 maximumPoolSize 写死了是 Integer.MAX_VALUE，keepAliveTime 是 0，workQueue 是 DelayedWorkQueue（这个是 ScheduledThreadPoolExecutor 的专用内部 queue，等下会讲到）。为什么 maximumPoolSize = Integer.MAX_VALUE ？我看到网上有的说法是，如果对线程数做了限制，就会对定时任务的调度产生延时（假设任务太多，线程忙不过来），这种说法听上去挺合理的，但是是不正确的。可能 ScheduledThreadPoolExecutor 从一开始设计就没有说要严格准时的执行定时任务，所以压根儿就没有考虑这个问题。通过源码发现，maximumPoolSize 是根本没起作用的，线程的数量不会大于 corePoolSize。为什么 maximumPoolSize 没用？是因为 ScheduledThreadPoolExecutor 的 queue 是无界的（每次达到上限会增长50%，跟 DelayQueue 也即 PriorityQueue 一样；如果对这个答案不明白，你可能需要看看 ThreadPoolExecutor ）。为什么要用无界 queue ？我猜想是 queue 里面的 task 是延迟或周期性的，会长期驻留，对队列的长度有要求，如果公开给调用者设置或者给一个固定的值，都不合适，会产生问题，所以干脆无界。还有另外一个原因，设置了 maximumPoolSize 且有效，如果此时 wc &gt; corePoolSize，且队列头的任务 delay 很大，那么在高并发的情况下，会不断有 worker 新建和销毁，造成性能问题，甚至 GC。为什么 keepAliveTime = 0 ？一般情况下 maximumPoolSize 不起作用，那么 keepAliveTime 也是不起作用的。但是也可以通过 allowCoreThreadTimeOut 令到 keepAliveTime 生效（通过调用 allowCoreThreadTimeOut(true) 方法设置），但是这个 keepAliveTime 确实不好设置，试想如果 keepAliveTime 小于队列头的 delay，那么这个线程就会被回收掉，然后在下次又创建一个新的线程，这不是很多余吗，所以干脆 keepAliveTime = 0。定时任务的执行schedule方法ScheduledThreadPoolExecutor 覆盖了 AbstractExecutorService 的 submit 方法，submit 也是直接调用 schedule 方法，我们一般使用也是调用 schedule，我们看看 schedulescheduleWithFixedDelay 和 scheduleAtFixedRate 都是类似的，只有一个参数的区别，所以我一起讲scheduleWithFixedDelay 和 scheduleAtFixedRate 两个方法的区别，相信大家都知道，前者是上一次任务执行完，再延迟 delay 的时间再执行下一次，后者是上一次任务的执行开始时间加上 period 就是下一次任务的执行时间。我们看到 scheduleWithFixedDelay 和 scheduleAtFixedRate 基本是一样的，就只有当传到 ScheduledFutureTask 的入参时，delay 变成了一个负数，period 还是一样，这一点大家先记住，后面会用到。继续讲 schedule 方法decorateTask 方法只是让 ScheduledFutureTask 变成 RunnableScheduledFuture，使得 delayedExecute 更加通用ScheduledFutureTask 是 ScheduledThreadPoolExecutor 内部定义的任务类，从结构看，简单来说它就是一个 FutureTask + Delayed我们看看 ScheduledFutureTask 构造方法如果是 schedule 则 period 为0，scheduleWithFixedDelay 和 scheduleAtFixedRate 则等于入参，这就是一次性任务和周期性任务的区别如果是 schedule 则 period 为0，scheduleWithFixedDelay 和 scheduleAtFixedRate 则等于入参，这就是一次性任务和周期性任务的区别继续看看 delayedExecuteshutdown 就直接 reject；否则加入到队列，再发现是 shutdown 的话，就 remove 掉，中断 task；这里为什么直接加入队列？因为任务的延迟的，一定要确保从延迟队列中取出来运行。最后调用 ensurePrestart 确保有 worker 在运行；这里回应上面的， wc &lt; corePoolSize，所以 maximumPoolSize 是没用的。把任务加到队列了，注意由于队列 DelayedWorkQueue 是类似 DealyQueue，这涉及到 task 的 getDelay 和 compareTo （还记得上面说 ScheduledFutureTask 是一个 Delayed 吗 ），还有这个 queue 是一个二叉堆，涉及 siftUp 和 siftDown 的堆操作，这部分都跟 DealyQueue 比较相关，这里就不展开了。接下来就是 worker 从队列取出任务，取法跟 ThreadPoolExecutor 一样。run方法接下来就是 task 的运行ScheduledFutureTask 是一个 FutureTask，它覆盖了 run 方法canRunInCurrentRunState，刚刚我们在 delayedExecute 也遇到，它使用来判断线程池是否在运行 RUNNING，如果是 SHUTDOWN，是否允许终止任务；continueExistingPeriodicTasksAfterShutdown 意思是，对于周期性任务，在 SHUTDOWN 下，是否允许继续执行，默认是 false；executeExistingDelayedTasksAfterShutdown 意思是，对于非周期性任务，在 SHUTDOWN 下，是否允许继续执行，默认是 true；我们回到重点来，看红箭头。如果是非周期性任务，那么就调用 FutureTask 的 run 方法；如果是周期性任务，那么就调用 FutureTask 的 runAndReset 方法（runAndReset 跟 FutureTask 相关，这里不展开了），简单说就是这个 future 执行完之后会重置为 NEW 状态；setNextRunTime方法setNextRunTime 方法，计算任务下一次的执行时间（还记得上面我们说 delay 是负数，period 是原值吗？这里用到了，这两个值都是对应到这里的 period）如果 p &gt; 0 ，则在原来的时间上 time 直接追加 period，否则在 now() 的基础上追加triggerTime 获取下次执行任务的时间triggerTime防溢出这里还有一个巧妙的地方，我得说一下为什么 delay 要跟 Long.MAX_VALUE 右移一位比较？不急，我们先看看 overflowFree 方法注释已经把大意说清楚了，就是为了防止溢出。因为 head 的 getDealy 有可能是负数（一直没有出队运行），那么当前 task 加入队列时做 compareTo 就有可能溢出（减去一个负数得到一个大于 Long.MAX_VALUE 的数），那么这时比较的结果就不对了。首先 delay 肯定不为负数，我们分情况看一下：1、如果 headDealy 为正数（含0），两个正数相减不会溢出，这没问题2、如果 headDealy 为负数，那么只要 delay - headDealy &gt; Long.MAX_VALUE 就不是我们想要的结果，所以要对 delay 或 headDealy 做一下限制。我们回到刚刚提出的问题（ delay &lt; (Long.MAX_VALUE &gt;&gt; 1) ？）。之所以有这个做法，是因为对 delay 和 headDealy 的值做了一个折中。如果 delay &lt; (Long.MAX_VALUE &gt;&gt; 1) （Long.MAX_VALUE &gt;&gt; 1 就是 Long.MAX_VALUE 的一半），那么就直接用这个 delay 进队；如果大于的话，那就认为它做 compareTo 时极有可能会溢出（这个是人为的认为），那么就取出 headDealy 来试一下，真溢出了，就做调整。这里巧妙的地方在于，它给了 delay 和 headDealy 的值 Long.MAX_VALUE 的一半这么多的预留空间（各占一半），试想如果把 delay &lt; (Long.MAX_VALUE &gt;&gt; 1) 改为 delay &lt; Long.MAX_VALUE（极端为 delay = Long.MAX_VALUE 的情况），那么 headDealy 只要小于 0 就会溢出。所以只要 headDealy 大于 Long.MIN_VALUE &gt;&gt; 1 就不会溢出。当然，headDealy 是有可能小于 Long.MIN_VALUE &gt;&gt; 1 的，所以为了万一，最后还是会做调整。reExecutePeriodic方法我们继续回到重点 reExecutePeriodic 方法跟之前讲解的代码有点像，相信大家都看的明白了，主要就是把 task 加回到 queue 里。关闭线程池ScheduledThreadPoolExecutor 的 shutdown 和 shutdownNow 都是直接调用 ThreadPoolExecutor 的。至此，ScheduledThreadPoolExecutor 的大概流程和原理讲得7788了。Why DelayedWorkQueue?这里补充一下我在看 ScheduledThreadPoolExecutor 源码时心里最大的一个疑问。为什么不直接用 DealyQueue ，而是另外写了一个 DelayedWorkQueue？不过还好不用我们自己瞎猜，官方的注释给出了说明简单来说就是 DelayedWorkQueue 其实跟 DealyQueue 差不多，不过里面的元素 ScheduledFutureTask 会记录在堆的下标，做 remove 的时候时间复杂度从 O(n) 提升到 O(log n)。 所以 DelayedWorkQueue 重写了remove 方法，直接取出元素的 index。原来 DealyQueue 的做法是遍历数组找出元素的下标（如果元素不是 ScheduledFutureTask 类型也是这样做）+ 堆操作：O(n) + O(log n) 约等于 O(n) .DelayedWorkQueue 的操作变为直接取出下标 + 堆操作：O(1) + O(log n) 约等于 O(log n)总的时间复杂度从 O(n) -&gt; O(log n)总结ScheduledThreadPoolExecutor的实现跟 ThreadPoolExecutor类似，它利用了延迟队列 DealyQueue 对任务进行延迟运行。参考资料https://www.jianshu.com/p/2756fd08d0cdhttps://www.jianshu.com/p/d96e9f67dba5Java多线程复习与巩固（七）–任务调度线程池ScheduledThreadPoolExecutor]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>ScheduledThreadPoolExecutor</tag>
        <tag>调度线程池</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程池ThreadPoolExecutor实现原理]]></title>
    <url>%2Fposts%2Ff5cda8d1%2F</url>
    <content type="text"><![CDATA[概要线程池，大家都很熟悉了，我们在平时应用中也用的很多。对线程池，ThreadPoolExecutor 的实现原理有一定理解后，我们可以把它用的更好，对它的参数有更加深刻的理解，甚至我们可以扩展，监控自己的线程池。ThreadPoolExecutor实现原理本文代码基于JDK1.8线程池相关的类的关系我们先看看主要的类ThreadPoolExecutor的继承关系平时可能还有用到的 Executors 类，这是一个工具类，提供newFixedThreadPoolnewCachedThreadPoolnewScheduledThreadPool等静态方法方便我们创建线程池，最终还是调用 ThreadPoolExecutor 来创建的，一般规范不建议直接使用 Executors 来创建线程池。线程池创建的主流程线程池的状态先看看线程池的状态有哪些，对它有初步的理解线程池的状态和运行的线程数只用了一个 int，其中高3位表示状态，低29位表示线程数。状态表示的意思和状态之间的转换：RUNNING - 可以接受新的任务，及执行队列中的任务SHUTDOWN - 不接受新的任务，但会继续执行队列中的任务STOP - 不接受新的任务，既不会执行队列中的任务，还会中断执行中的任务TIDYING - 全部任务已经终止，且线程数为0TERMINATED - 线程池完全终止RUNNING -&gt; SHUTDOWN - 执行了 shutdown()(RUNNING or SHUTDOWN) -&gt; STOP - 执行了shutdownNow()SHUTDOWN -&gt; TIDYING - 队列和线程为空STOP -&gt; TIDYING - 线程为空TIDYING -&gt; TERMINATED - terminated() 这个勾子方法执行完毕线程池的创建ThreadPoolExecutor 的构造函数线程池的创建只是初始化了一些参数，但理解好这些参数对我们使用线程池很有帮助。corePoolSize - 核心线程数，除非 allowCoreThreadTimeOut 为 true（默认false），否则即使没有任务，也会维持这么多线程。maximumPoolSize - 最大线程数，corePoolSize 满了的话，会把任务放到队列，如果队列满了的话（假设队列有界），就会继续创建线程直到 maximumPoolSize，如果超过 maximumPoolSize 则会执行 reject 策略。workQueue - 用来存放任务的队列，是一个 BlockingQueue，常用的有 LinkedBlockingQueue，ArrayBlockingQueue，SynchronousQueue。keepAliveTime - 空闲线程的存活时间，如果当前线程数 &gt; corePoolSize，且某个线程空闲了这么多时间（没有获取到任务并运行），那么这个线程会被 remove 掉。unit - keepAliveTime 的单位，内部会统一转换成 nanosthreadFactory - 用来创建线程的 ThreadFactory，主要用来给线程命名（方便查看日志），设置 daemon，优先级和 group 等，Executors 有 DefaultThreadFactory 这个默认实现。handler - reject 具体执行策略，reject 的条件上面已经说了，一般内置有以下几个，也可以自己实现CallerRunsPolicy - 不使用线程池的线程执行该任务，直接用当前执行任务（例如 main 线程）AbortPolicy - 直接抛异常DiscardPolicy - 无视不做处理，相当于抛弃掉DiscardOldestPolicy - 将队列头的任务取出来抛弃掉，然后运行当前任务线程池的执行一般我们使用 ExecutorService 的 submit 方法来使用线程池执行一个任务，这个方法调用到 AbstractExecutorService这里我们看到所有 task 无论是 Callable 还是 Runnable 的都会包装成一个 RunnableFuture 也就是 FutureTask，返回给我们。execute方法重点看 execute 方法，调用了 ThreadPoolExecutor 的 execute我们分三种情形来看，每个是一个 if 条件：第一，当 workCount &lt; corePoolSize 时，直接创建 worker 线程；第二，如果上面创建失败（可能是线程池正在处于关闭状态，可能是 workCount &gt; corePoolSize 了 - 并发场景），那么这时把任务放入 workQueue 队列；下面的判断是用来防止，线程池不在运行了，就把任务删掉；如果没有线程了就加一个；第三，来到这步说明上面放队列不成功（可能是队列是有界的，满了），那么就继续创建线程来满足，如果这都创建失败（可能是 &gt; maximumPoolSize）就 reject 了；addWorker方法继续看看重点的 addWorker 方法，addWorker 分开两部分来看。这一步是判断是否可以增加 worker 的重点：第一，首先开始的判断有点奇怪，我也不是很明白，先认为它是如果状态是 SHUTDOWN 则不允许创建线程；第二，下面有个 core 参数，true 使用 corePoolSize，false 使用 maximumPoolSize，我们上面说的 execute 方法第一次就是传 true 的，第二次就传 false。所以这里就是对 size 做判断， 如果 &gt;= size 则返回 false，否则 cas 一下，成功了就 break 执行下面的代码；第三，如果 cas 失败，说明有其他并发竞争，则 cintinue 循环上面的步骤判断。来到这一步说明可以创建 worker 了，这里用了一个全局 lock，来控制创建线程和关闭线程的不能同时做。可以看到步骤就是 new 一个 worker，add 到 workers 里，workers 是一个 HashSet。largestPoolSize 来用记录最大的线程数。如果 workerStarted == false（线程池在关闭或创建 worker 时异常），则会 addWorkerFailed 方法。主要就是 remove 掉 worker，扣减计数，这里还会调用 tryTerminate 。这个方法会在很多地方用到，它的作用就是防止线程池在终止状态这种情形，去终止线程。Worker是什么我们刚刚一直说 worker，那到底 Worker 究竟是什么？我们现在来看看我们可以看到 Worker 是一个 AQS 和 Runnable。为什么是一个 AQS ？我们可以结合注释和代码可以得到，worker 在跑任务的时候会 lock 住，在被中断时会 tryLock，利用上锁这一点来区分这个 worker 是否空闲。Worker 中重写 AQS 的方法。（感概：AQS 真是个简单易用，用于并发控制的好工具！）为什么是一个 Runnable ？我们看看 Worker 的构造函数，在创建 Thread 时把自己 this 传到 thread 的参数，说明 worker 的 thread 跑的是自己，这时我们就知道 worker 的入口了。Worker 的 run 方法runWorker方法重点的 runWorker 方法task 可能是传进来的 firstTask 或者 getTask() 获取到的，getTask 也是重点方法，等下讲到；运行 task 时会上锁，锁的作用我刚刚已经说了；如果线程池状态是 STOP 则中断线程；这里放了两个勾子 beforeExecute 和 afterExecute 方法来提供给子类做点事情，一般用于监控或统计线程池的执行情况；执行任务就直接 task.run() 了，还记得我说过这个 task 是一个 FutureTask，如果run 的时候抛出异常，FutureTask 会 catch 掉不会再 throw（如果大家对 FutureTask 不熟悉就先这样理解），所以这里不会进入 catch，也就是不会 throw x 了。如果 task 不像 FutureTask 一样自己处理掉异常，那就会 throw x 了，那么 worker 的线程就会跳出 while 循环，完成使命，结束自己；获取不到 task （task 为null）或者循环过程中异常，最后都会执行 processWorkerExit。processWorkerExit 的作用主要就是 remove 掉 worker，那么扣减 workCount 呢？好像没有看到。这里用了 completedAbruptly 这一变量来控制是否在 processWorkerExit 扣减 workCount，因为有可能是在 getTask 已经扣减了，那么在 processWorkerExit 就不用重复扣减。我们结合 runWorker 来看看，分两种情况：1、如果 firstTask 为 null，那么会走到 getTask 方法，如果 getTask 返回 null，那么说明已经是扣减了，这时退出循环，completedAbruptly = false，不用重复扣减。2、如果 firstTask 不为 null（1）执行 firstTask 正常结束，然后循环，走到 getTask，如果返回 task 为 null，那么 completedAbruptly = false，不用重复扣减。（2）执行 firstTask 执行异常，这时 completedAbruptly = true，需要扣减这里我们又看到 tryTerminate 了；下面的判断主要是尝试去增加一个 worker，因为你 remove 掉了一个，如果条件允许，那就加回一个呗。getTask方法看看重点的 getTask 方法在 getTask 时如果发现时线程池在关闭状态，那么就需要停止获取任务了；如果 wc &gt; maximumPoolSize，超过了最大 size 了，就去 cas 扣减 workCount 一下，成功就返回 null；如果 wc &gt; corePoolSize（小于 maximumPoolSize），且 timedOut 的话，说明这个 worker 也有点“多余”，也去扣减 workCount。注意这里对 timedOut 的判断，通过 queue 的定时 poll 方法，时间是线程池的构造参数 keepAliveTime，如果过了这么久都还没获取 task，说明 queue 是空的，有空闲的线程，那就把这个 worker remove 掉吧；如果 wc &lt; corePoolSize 的话，那就调用 queue 的 take 方法一直阻塞获取 task；还有 allowCoreThreadTimeOut 参数，它的意思是忽略对 corePoolSize 的判断。关闭线程池上面已经把线程的创建和执行基本说得7788了，我们看看关闭线程池是如何做的，其实在上面的很多方法中，都看到很多对如 SHUTDOWN 的判断了。主要有 shutdown 和 shutdownNow 这两个方法。这两个方法很相似，从名字来看 shutdown 显得更加的柔性，实际也是。shutdown –不接受新的 task，在运行和已经在队列的 task 可以继续运行；把状态改为 SHUTDOWN；中断空闲 worker，这个在上面已经提到过了，用锁对是否空闲做判断。interruptIdleWorkers 打断空闲的线程这里还有个 onShutdown 勾子方法。shutdownNow –不接受新的 task，中断已经在运行的线程，清空队列；把状态改为 STOP；强制中断所有在运行 worker 的线程；drainQueue，相当于把队列的 task 丢弃掉；总结线程池ThreadPoolExecutor实现的原理，就是用 Worker 线程不停得取出队列中的任务来执行，根据参数对任务队列和 Workers 做限制，回收，调整。参考资料http://www.jianshu.com/p/87bff5cc8d8chttps://javadoop.com/post/java-thread-pool]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>源码</tag>
        <tag>线程池</tag>
        <tag>ThreadPoolExecutor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则回溯分析]]></title>
    <url>%2Fposts%2F2fa47d3c%2F</url>
    <content type="text"><![CDATA[概要这是对一次线上正则回溯引起的问题的分析，文章对当时问题进行了简化，从而深入源码分析正则引擎是如何进行回溯以及回溯的时间复杂度。正则回溯分析排查过程zabbix接受到警告之后在 zabbix 看到 cpu 直飚 100%，当堂一惊！（我是CPU，现在慌得一比）。看到是 5.27 后开始飚升，首先怀疑代码问题，认真翻了一下 5.27 前 commit 到 master 的代码，没有发现明显的死循环或者死锁。于是叫运维帮忙看一下机器状态和 dump 出 jstack。top &amp; jstack线上机器 top：dump：定位问题可以看出跟正则有关的调用栈很长，于是把问题定位在 validateUrl 方法上。这是一个用正则去校验一个外部电子发票链接url的方法，其中 url=1http://www.fapiao.com/dzfp-web/pdf/download?request=6e7JGmpM5neXWMVrv4ILd-kEn64HcUX4qL4a4qJ4-CEk7Azg.Vjit92m74H5oxkjgdsYazxcUmdJjKscGXhaJw__%5EHGabjgEIe其中，正则 pattern =1^([hH][tT]&#123;2&#125;[pP]://|[hH][tT]&#123;2&#125;[pP][sS]://)(([A-Za-z0-9-~]+).)+([A-Za-z0-9-~\/])+$原因分析阅读前提阅读下文时，我希望你对正则的基本用法、基本概念，正则的贪婪、懒惰、独占都有一定的理解。之前，我的一个同事已经对这个做了一定的分析，大家可以先阅读一下 藏在正则表达式里的陷阱回溯的定义在网上看了一下大致都说这个是跟正则的回溯有关，那究竟什么是正则的回溯呢？下面是我在网上找到一个比较好解释，可能看了之后还是懵逼，不怕，接下来会有详细解释使用 NFA 引擎的模式匹配由正则表达式中的语言元素驱动，而不是由输入字符串中要匹配的字符驱动。 因此，正则表达式引擎将尝试完全匹配可选或可替换的子表达式。 当它前进到子表达式中的下一个语言元素并且匹配不成功时，正则表达式引擎可放弃其成功匹配的一部分，并返回以前保存的与将正则表达式作为一个整体与输入字符串匹配有关的状态。 返回到以前保存状态以查找匹配的这一过程称为回溯。简化还原分析由于原来的url和pattern太长有点复杂，不好做分析，所以我进行了简化，方便做调试和分析。根据正则的贪婪和回溯特性，我做了如下的简化。（如果你对正则有一定的理解，相信你也会对原来url和pattern做到如下的简化）url=1aaaaaaaaaaaa_ （只是想表示有 n 个 a）pattern=1(a+)+以下的分析都是基于上面的ur和pattern。（基于JDK8）通过调试代码，我发现匹配字符的类最后是在 CharProperty 的 match 方法；其中通过 Character.codePointAt(seq, i) 这个方法获取需要匹配的字符，其实这个方法终于还是调用 CharSequence 的 charAt 这个方法123456789101112131415161718192021222324252627/** * Abstract node class to match one character satisfying some * boolean property. */private static abstract class CharProperty extends Node &#123; abstract boolean isSatisfiedBy(int ch); CharProperty complement() &#123; return new CharProperty() &#123; boolean isSatisfiedBy(int ch) &#123; return ! CharProperty.this.isSatisfiedBy(ch);&#125;&#125;; &#125; boolean match(Matcher matcher, int i, CharSequence seq) &#123; if (i &lt; matcher.to) &#123; int ch = Character.codePointAt(seq, i); return isSatisfiedBy(ch) &amp;&amp; next.match(matcher, i+Character.charCount(ch), seq); &#125; else &#123; matcher.hitEnd = true; return false; &#125; &#125; boolean study(TreeInfo info) &#123; info.minLength++; info.maxLength++; return next.study(info); &#125;&#125;于是我在 stackoverflow 找到一个继承 CharSequence 的类来做一些辅助 InterruptableCharSequence ，主要是打印当前匹配的字符和匹配次数，还有后面要做的中断。12345678910111213141516171819202122232425262728293031323334353637383940414243public class InterruptableCharSequence implements CharSequence&#123; CharSequence inner; public long counter = 0; public InterruptableCharSequence(CharSequence inner) &#123; super(); this.inner = inner; &#125; public long getCounter()&#123; return counter; &#125; @Override public char charAt(int index) &#123; boolean isInterrupt = Thread.currentThread().isInterrupted(); if(isInterrupt)&#123; System.out.println("currentThread has been set interrupt"); &#125; if (Thread.interrupted()) &#123; // clears flag if set System.out.println("interrupt !!!"); throw new RuntimeException(new InterruptedException("occur from InterruptableCharSequence")); &#125; counter++; System.out.println("charAt = " + inner.charAt(index)); return inner.charAt(index); &#125; @Override public int length() &#123; return inner.length(); &#125; @Override public CharSequence subSequence(int start, int end) &#123; return new InterruptableCharSequence(inner.subSequence(start, end)); &#125; @Override public String toString() &#123; return inner.toString(); &#125;&#125;推出时间复杂度通过调试代码和根据打印信息，可以得出正则回溯的匹配过程：假设 url=a_，pattern=(a+)+(1) a 匹配，继续(2) _ 不匹配以上两步是第一个 + 的匹配过程(3) 尝试匹配 _ 看看是不是可以结束以上这一步是第二个 + 的匹配过程(4) 没有回溯，结束（没有回溯是没有发生贪婪，发生贪婪的条件是从第一个字符匹配成功后，下一个字符又匹配成功）所以这时一共匹配了 3 步，匹配顺序为：1a _ _假设 url=aa_，pattern=(a+)+(1) ~ (3) 匹配到了 aa_(4) 尝试匹配 _ 看看是不是可以结束(5) 发生回溯，后退一步，递归 a_ 的匹配过程(n) 最终还是匹配不成功，结束所以这时一共匹配了 7 步，匹配顺序为：1a a _ _ a _ _假设 url=aaa_，pattern=(a+)+(1) ~ (4) 匹配到了 aaa_(5) 尝试匹配 _ 看看是不是可以结束(6) 发生回溯，后退一步，递归 a_ 的匹配过程(…) 上一步最终还是匹配不成功的，于是又后退一步，递归 aa_ 的匹配过程(n-1) 直到回退到第一个 a，回溯结束，已经遍历了所有的情况(n) 最终还是匹配不成功，结束所以一共匹配了 15 步，匹配顺序为：1a a a _ _ a _ _ a a _ _ a _ _根据上面我们可以推断出时间复杂度：1234567f(1) = 1f(2) = 3 = 2 + f(1)f(3) = 7 = 3 + f(2) + f(1)f(4) = 15 = 4 + f(3) + f(2) + f(1)f(n) = n + f(n-1) + f(n-2) + ... + f(1)所以 f(n) = 2 的N 次方 - 1可见恐怖！！回溯源码分析现在我们来回头看看正则回溯的相关代码，主要是在 Curly 的 match0 方法1234567891011121314151617181920212223242526272829303132333435363738394041// Greedy match.// i is the index to start matching at// j is the number of atoms that have matchedboolean match0(Matcher matcher, int i, int j, CharSequence seq) &#123; if (j &gt;= cmax) &#123; // We have matched the maximum... continue with the rest of // the regular expression return next.match(matcher, i, seq); &#125; int backLimit = j; while (atom.match(matcher, i, seq)) &#123; // k is the length of this match int k = matcher.last - i; if (k == 0) // Zero length match break; // Move up index and number matched i = matcher.last; j++; // We are greedy so match as many as we can while (j &lt; cmax) &#123; if (!atom.match(matcher, i, seq)) break; if (i + k != matcher.last) &#123; if (match0(matcher, matcher.last, j+1, seq)) return true; break; &#125; i += k; j++; &#125; // Handle backing off if match fails while (j &gt;= backLimit) &#123; if (next.match(matcher, i, seq)) return true; i -= k; j--; &#125; return false; &#125; return next.match(matcher, i, seq);&#125;从代码和注释得知，开始匹配成功后，就会进入贪婪模式，直到匹配不成功，然后开始发生回溯，用 backLimit 这个变量记录最开始匹配成功的下标，即允许回溯最后的地方。开始发生回溯的地方，即第33行的 next.match 方法，这个 next 指的是下一个节点（因为 java 实现 NFA 用了类似图（graph）的数据结构，匹配的地方，group开始和结束的地方等等都抽象成一个个 Node），由于第二个 + 的原因，构成了一个有环的图，于是发生递归。以下是我调试时根据 Node 的关系，画出来的图：线上问题的url分析&amp;解决现在回过头来看看导致线上问题的原因：先把正则简化一下， pattern=1^(http://)(([A-Za-z0-9-~]+).)+$加点打印信息，可以看出从第24行开始发生回溯 ：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741758 ww.fapiao.com/dzfp-web/pdf/download?request=6e7JGmpM5neXWMVrv4ILd-kEn64HcUX4qL4a4qJ4-CEk7Azg.Vjit92m74H5oxkjgdsYazxcUmdJjKscGXhaJw__%5EHGabjgEIe 12 apiao.com/dzfp-web/pdf/download?request=6e7JGmpM5neXWMVrv4ILd-kEn64HcUX4qL4a4qJ4-CEk7Azg.Vjit92m74H5oxkjgdsYazxcUmdJjKscGXhaJw__%5EHGabjgEIe 19 om/dzfp-web/pdf/download?request=6e7JGmpM5neXWMVrv4ILd-kEn64HcUX4qL4a4qJ4-CEk7Azg.Vjit92m74H5oxkjgdsYazxcUmdJjKscGXhaJw__%5EHGabjgEIe 23 zfp-web/pdf/download?request=6e7JGmpM5neXWMVrv4ILd-kEn64HcUX4qL4a4qJ4-CEk7Azg.Vjit92m74H5oxkjgdsYazxcUmdJjKscGXhaJw__%5EHGabjgEIe 32 df/download?request=6e7JGmpM5neXWMVrv4ILd-kEn64HcUX4qL4a4qJ4-CEk7Azg.Vjit92m74H5oxkjgdsYazxcUmdJjKscGXhaJw__%5EHGabjgEIe 36 ownload?request=6e7JGmpM5neXWMVrv4ILd-kEn64HcUX4qL4a4qJ4-CEk7Azg.Vjit92m74H5oxkjgdsYazxcUmdJjKscGXhaJw__%5EHGabjgEIe 45 equest=6e7JGmpM5neXWMVrv4ILd-kEn64HcUX4qL4a4qJ4-CEk7Azg.Vjit92m74H5oxkjgdsYazxcUmdJjKscGXhaJw__%5EHGabjgEIe 53 e7JGmpM5neXWMVrv4ILd-kEn64HcUX4qL4a4qJ4-CEk7Azg.Vjit92m74H5oxkjgdsYazxcUmdJjKscGXhaJw__%5EHGabjgEIe 102 jit92m74H5oxkjgdsYazxcUmdJjKscGXhaJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 136 Jw__%5EHGabjgEIe 138 __%5EHGabjgEIe 135 aJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 134 haJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 136 Jw__%5EHGabjgEIe 138 __%5EHGabjgEIe 133 XhaJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 136 Jw__%5EHGabjgEIe 138 __%5EHGabjgEIe 135 aJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 132 GXhaJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 136 Jw__%5EHGabjgEIe 138 __%5EHGabjgEIe 135 aJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 134 haJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 136 Jw__%5EHGabjgEIe 138 __%5EHGabjgEIe 131 cGXhaJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 136 Jw__%5EHGabjgEIe 138 __%5EHGabjgEIe 135 aJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 134 haJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 136 Jw__%5EHGabjgEIe 138 __%5EHGabjgEIe 133 XhaJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 136 Jw__%5EHGabjgEIe 138 __%5EHGabjgEIe 135 aJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 130 scGXhaJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 136 Jw__%5EHGabjgEIe 138 __%5EHGabjgEIe 135 aJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 134 haJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 136 Jw__%5EHGabjgEIe 138 __%5EHGabjgEIe 133 XhaJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 136 Jw__%5EHGabjgEIe 138 __%5EHGabjgEIe 135 aJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 132 GXhaJw__%5EHGabjgEIe 138 __%5EHGabjgEIe 137 w__%5EHGabjgEIe 136 Jw__%5EHGabjgEIe于是，可选的解决方案有：使用可选限定符或替换构造的回溯123(http://)(([\\S]+).)(http://)(([\\S]+?).) (http://)(([A-Za-z0-9-~_%]+?).)非回溯子表达式1^(http://)(?&gt;([A-Za-z0-9-~]+).)+$如何避免综上，我个人总结以下四点来规避上面的正则回溯问题。充分考虑输入除了考虑正确的输入外，更重要的是考虑不匹配的输入！发生回溯都是因为不匹配导致的，正则会不停的尝试匹配，直到所有可能的情况。推荐一个探测工具：https://regex101.com/控制回溯发生回溯是因为正则用到了量词（quantifier）和 替换（alternation）（因为这两者为正则的匹配提供了可能性）。可以加上使用断言（assertions）或 独占模式（possessive），这样可以减少回溯的次数或者避免回溯，但是加上了断言和独占就要考虑对原来的匹配有没有产生影响，匹配结果是否还是一致。量词：?, *, +, {n，m}替换：[x|y] 类似这种断言：(?=exp), (?!exp) 类似这种独占模式：在量词后面再加上一个 +，表示匹配到此为止，不会回吐字符，即不会回溯。使用超时机制但是本人认为回溯是不能避免的，那么就可以使用超时机制，用中断线程的方法来强制结束线程，不要让它在死跑，耗尽CPU资源以下是本人写的一个小测试：12345678910111213141516171819202122232425262728293031323334public class RegexBug &#123; private static String regex3 = "(a+)+"; private static String harmful_url = "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa_"; private static Pattern URL_PATTERN; static ExecutorService threadPool = Executors.newCachedThreadPool(); public static void main(String[] args)throws Exception &#123; URL_PATTERN = Pattern.compile(regex3, Pattern.MULTILINE); long l1 = System.nanoTime(); CharSequence cs = new InterruptableCharSequence(harmful_url); Future&lt;Boolean&gt; future = null; future = threadPool.submit(() -&gt; validateUrl(cs)); try&#123; Boolean matchResult = future.get(5, TimeUnit.SECONDS); System.out.println("matchResult = " + matchResult); &#125;catch (TimeoutException e)&#123; e.printStackTrace(); future.cancel(true); &#125;catch (Exception e1)&#123; e1.printStackTrace(); &#125; System.out.println("pattern耗时 = " + (System.nanoTime() - l1) / (1000000)); System.out.println("counter = " + ((InterruptableCharSequence) cs).getCounter()); &#125; public static boolean validateUrl(CharSequence url) &#123; Matcher matcher = URL_PATTERN.matcher(url); return matcher.matches(); &#125; &#125;日志：使用现成工具校验与其自己写正则担心写出bug，不如用现成的工具。apache common-validator 了解一下参考资料https://www.cnblogs.com/study-everyday/p/7426862.htmlhttp://wwaw.cnblogs.com/chanshuyi/archive/2018/06/19/9197164.html7164.html]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>正则</tag>
        <tag>回溯</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo高级玩法]]></title>
    <url>%2Fposts%2Fbe8242cc%2F</url>
    <content type="text"><![CDATA[概要添加一些高级功能，可以让我们的网站显得更加丰富，多样性，简单说就是更高逼格。高级功能文章阅读统计我选择了 LeanCloud，这也是官方推荐使用的。网上有很多选择不蒜子的，也是可以的。注册 LeanCloud 账号Leancloud官网创建一个应用名字你喜欢就行创建一个Class点击进去应用注意名字必须为 Counter，勾选无限制的权限。修改主题配置修改 next 主题的_config.yml ，找到 leancloud_visitors ，修改为1234leancloud_visitors: enable: true app_id: xxx app_key: xxx其中 app_id 和 app_key 在 LeanCloud 的设置 -&gt; 应用 Key 可以找到重启查看这样就配置好了，重新生成 hexo 并发布，我们就可以看到文章阅读次数的统计。需要特别说明的是：记录文章访问量的唯一标识符是文章的发布日期以及文章的标题，因此请确保这两个数值组合的唯一性，如果你更改了这两个数值，会造成文章阅读数值的清零重计。在 LeanCloud 的后台我们可以看到一个整体的统计量，其中 time 字段就是统计数字，可以修改的哦。安全因为AppID以及AppKey是暴露在外的，因此如果一些别用用心之人知道了之后用于其它目的是得不偿失的，为了确保只用于我们自己的博客，建议开启Web安全选项，这样就只能通过我们自己的域名才有权访问后台的数据了，可以进一步提升安全性。评论功能在网上找了很多，有多说，畅言，来必力，gticomment，valine，选择 valine 是因为搞阅读统计的时候已经注册了 LeanCloud，可以顺手用上，而且 next 已经支持了 valine，可以简单快速用起来。在 LeanCloud 注册和创建应用上面已经做了修改主题配置文件找到 valine 配置项打开 enable，输入 appid 和 appkey ，其他自己设置。12345678910valine: enable: true appid: xxx appkey: xxx notify: false # mail notifier , https://github.com/xCss/Valine/wiki verify: false # Verification code placeholder: 走过路过，不留下点什么吗？ # comment box placeholder avatar: mm # gravatar style guest_info: nick,mail,link # custom comment header pageSize: 10 # pagination size效果这样就我们已经配置好了，重启hexo，看到文章底部出现评论框测试一下hexo d 发布后测试评论一条然后在 LeanCloud 后台可以看到，可以进行删除等操作。关闭评论如需取消某个 页面/文章 的评论，在 md 文件的 front-matter 中增加1comments: false字数统计使用 hexo-wordcount 插件，因为 next 主题已经支持了在 hexo 目录执行安装1npm i --save hexo-wordcount修改主题配置找到 post_wordcount 项123456post_wordcount: item_text: true wordcount: true # 单篇 字数统计 min2read: true # 单篇 阅读时长 totalcount: false # 网站 字数统计 separated_meta: true修改显示文字字数统计和阅读时长是没有单位，需要补上才比较清晰。修改以下文件1themes/next/layout/_macro/post.swig修改【字数统计】，找到如下代码：123&lt;span title=&quot;&#123;&#123; __(&apos;post.wordcount&apos;) &#125;&#125;&quot;&gt; &#123;&#123; wordcount(post.content) &#125;&#125;&lt;/span&gt;修改后为：123&lt;span title=&quot;&#123;&#123; __(&apos;post.wordcount&apos;) &#125;&#125;&quot;&gt; &#123;&#123; wordcount(post.content) &#125;&#125; 字&lt;/span&gt;同理，我们修改【阅读时长】，修改后如下：123&lt;span title=&quot;&#123;&#123; __(&apos;post.min2read&apos;) &#125;&#125;&quot;&gt; &#123;&#123; min2read(post.content) &#125;&#125; 分钟&lt;/span&gt;修改完成后，重新执行启动服务预览就可以了。如下：这个阅读的速度是可以修改的，默认是中文300，英文160字/每分钟，详细可以看 hexo-wordcount。站内搜索就是可以在你的网站搜索你网站内的内容安装 hexo-generator-searchdb在站点的根目录下执行1npm install hexo-generator-searchdb --save修改站点配置文件添加12345search: path: search.xml field: post format: html limit: 10000修改 next 主题配置文件找到 local_search 修改为 true12local_search: enable: true效果重启 hexo，可以看到在目录栏最下方出现了“搜索”菜单点击弹出框，就可以搜索被Google和百度收录google登陆 google search consolegoogle search console添加你的网站地址（需要google账号）进行验证google 需要验证你拥有该网站的权限，默认推荐的验证方式是在你的网站添加一个它提供的 html，但是由于 hexo 的静态文件是生成的，我们 clean 之后就没了，所以我们不适用这种方式（其实也可以做到）。我们使用另一种更加方便的方式。使用 meta 标签做法是修改主题配置文件，找到 google_site_verification，值修改为 google 提供的 meta 中 content 的内容1google_site_verification: xxxxx加了这个配置后 next 会自动帮我们插入 meta 标签了。我们重启，发布。然后点击上图的验证按钮，成功的话，就会看到以下提示然后我们点击“前往资源页面”，对我们网站其中一个页面进行检查，会提示站点不适用增加站点地图安装插件1npm install hexo-generator-sitemap --save在站点配置文件添加12sitemap: path: sitemap.xml修改站点配置文件，找到 url 项，改为你网站地址。默认是1http://yoursite.com如果你不修改这个，sitemap.xml 生成内容不正确。1url: https://albenw.github.io重新生成、发布，可以看到在 public 目录下生成了 sitemap.xml 文件。在 google search console 提交站点地图提交后结果，看到成功的状态在覆盖率可以看到 google 抓取你的页面，但是我们刚刚添加的网站还没被抓取，要等搜索引擎下一次更新索引你才能在 google 上搜到，请耐性等待。添加 robot.txt原来我是漏掉这一步，了解后发现原来这个文件对爬虫的抓取有一定的帮助，这也是SEO的优化，所以加上。在站点 source 目录下创建 robots.txt，内容如下：1234567891011121314# hexo robots.txtUser-agent: *Allow: /Allow: /archives/Disallow: /vendors/Disallow: /js/Disallow: /css/Disallow: /fonts/Disallow: /vendors/Disallow: /fancybox/Sitemap: https://albenw.github.io/sitemap.xmlSitemap: https://albenw.github.io/baidusitemap.xmlbaidu打开百度的站点管理百度站点管理添加一个站点验证同样我们使用 meta 标签验证修改主题配置文件，添加 baidu_site_verification 项，值为 content 内容。1baidu_site_verification: xxx注意，原来配置文件是没有 baidu_site_verification 这个项的，但是通过查看 layout/_partials/head.swig，我们发现其实 hexo 是支持的，如果 head.swig 没有，则需要我们手动在 head.swig 增加123&#123;% if theme.baidu_site_verification %&#125; &lt;meta name=&quot;baidu-site-verification&quot; content=&quot;&#123;&#123; theme.baidu_site_verification &#125;&#125;&quot; /&gt;&#123;% endif %&#125;配置好后，重新生成，发布，在点击百度站点页面的验证按钮。主动推送由于 github 禁止了百度的爬虫，所以我们不能像对 google 那样通过 sitemap 的方式被抓取到链接，即使你配置了也是没用的。除了 sitemap 还有主动推动和自动推送这两种方式，主动推动的原理是每次 deploy 的时候都把所有链接推送给百度，自动则是每次网站被访问时都把该链接推送给百度。通过对比，我觉得主动推动比价好，所以选用这种方式插件安装1npm install hexo-baidu-url-submit --save修改站点配置文件在 _config.yml，添加以下内容12345baidu_url_submit: count: 5 host: your_site token: your_token path: baidu_urls.txt其中 count 表示一次推送提交最新的N个链接；host 和 token 可以在百度站点页面-&gt;数据引入-&gt;链接提交可以找到；path 为生成的文件名，里面存有推送的，我们网站的链接地址。确保站点配置文件中的 url 项跟百度注册的站点一致同样修改站点配置文件的 deploy 项，我们原来已经有 git 的 deploy，现在增加对 baidu 的推送，最终是这样子的12345deploy:- type: git repo: git@github.com:albenw/albenw.github.io.git branch: master- type: baidu_url_submitter重新生成，发布 hexo d，可以看到推送给百度成功我们可以在百度站点页面-&gt;数据引入-&gt;链接提交看到成交推送的链接数量，不过还不能看当天的，要等明天。（一天后）可以看到提交量了。虽然推送成功了，但是百度不是马上抓取的，需要耐心等待，具体可以查看数据监控-&gt;索引量页面。留言板所谓留言板其实就是开一个空的 page ，然后可以有评论这样子。添加留言板的 page1hexo new page guestbook修改主题配置文件找到 next 的 _config.yml 文件里面的 menu 项，增加1guestbook: /guestbook因为这里使用的是中文，找到 next 主题的 languages 目录里面的zh-Hans.yml文件，menu子项中添加1guestbook: 留言设置留言板的图标next 主题的默认是 page 的名字就是图标 icon 的名字，由于没有 “guestbook” 这个 icon ，所以留言板左边的小图标是一个问号。由于 next 支持 Font Awesome 的所有图标，所以只需要到 Font Awesome 的网站找到你想要的图标，然后还是在主题配置文件的 menu 项，最终修改为1guestbook: /guestbook || comment效果page 默认是开了 comments 的，所以直接用就可以了。参考资料为NexT主题添加文章阅读量统计功能https://blog.csdn.net/blue_zy/article/details/79071414https://www.jianshu.com/p/baea8c95e39bhttp://theme-next.iissnan.com/third-party-services.html#local-searchhttps://www.jianshu.com/p/25145964abf3https://www.jianshu.com/p/5e68f78c7791Hexo插件之百度主动提交链接Hexo博客提交百度和Google收录]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>hexo高级</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo优化]]></title>
    <url>%2Fposts%2F3460d887%2F</url>
    <content type="text"><![CDATA[概要按照我之前hexo的安装部署，可以正常使用，但是或者存在性能或效率的问题，又或者在操作上不便，这篇文章希望能做一点优化和改善。优化图片插入与存放问题一般来说有一下两种方式图床就是图片的云存储，图片存放在云上，这种方式一般是先把图片上传上去，获取到链接，然后在 MD 中引用。我个人觉得这种做法操作麻烦，使用图床麻烦，要先上传图片又麻烦，而且如果图床不稳定，你的图片就可能显示不出来了，甚至图床挂了，你的图片就没了。本地可能我习惯用云笔记，我个人偏向使用在本地的。本地的做法一般是先把图片放在 hexo 站点的目录下，然后在 MD 中引用，这样也可以把图片上传到 github 做备份保存。但我觉得还是有两个问题，一是操作麻烦，二是管理图片。第一，我个人喜欢用 hexo-admin，直接在页面复制图片就行了。第二，hexo-admin 默认是放在 images 目录下的，但是如果文章越来越多，图片会很乱。关于这点 hexo 提供 post_asset_folder 参数配置，为 true 的话，在新建 post 时会在 _post 建一个同名文件夹（仅此而已），hexo 的初衷是想我们把图片放在里面，可惜 hexo-admin 对这个配置还不支持，我看它还是在 issue 里。所以到这里，我觉得还是没有好的做法，我自己的做法是放 images 目录，图片的命名要有规范，例如 post_name + “__“ + index 这样，方便做管理。这里提醒大家一点，编辑时使用的图片的路径和生成 html 时的是不一样的。html，js，css，images 压缩使用 hexo-all-minifier 插件，在站点目录执行1npm install hexo-all-minifier --save在站点配置文件 _config.yml ，增加一行即可1all_minifier: true在 hexo g 生成的时候会看到打印输出 xx% saved 这样的字眼，表示成功了。我觉得感觉是好像是。。快了一点。。吧。。文章唯一link更改文章题目或者变更文章发布时间，在默认设置下，文章链接都会改变，不利于搜索引擎收录，也不利于分享。这里还是涉及爬虫的知识点，如果链接的层级太深，则对SEO不友好。所以简短的、唯一永久链接才是更好的选择。安装插件1npm install hexo-abbrlink --save在站点配置文件中查找代码permalink，将其更改为1permalink: posts/:abbrlink/ # “posts/” 可自行更换修改配置然后在站点配置文件中添加如下代码1234# abbrlink configabbrlink: alg: crc32 # 算法：crc16(default) and crc32 rep: hex # 进制：dec(default) and hex效果重启 hexo 生效后，可以看到文章的链接不再是“日期+文章名”，而是配置的 permalink，后面的一串字符就是 abbrlink。特别的说明：由于加了这个配置之后文章的链接URL变了，所以之前如果有做“评论”或“访问计数”配置的，就会全部失效。预览首页进去是对每一篇文章都显示了所有内容，需要把当前文章滚动到末尾才能看到下一篇文章，这样不能让读者快速浏览到大概有哪些文章，不能一下子吸引到读者。在主题配置文件中找到 auto_excerpt 属性，将enable设置为true ，将length设置为想要预览到的字数123auto_excerpt:enable: true #将原有的false改为truelength: 300 #设置预览的字数在首页看到的效果图，它的摘要只是把文本存粹的按照 length 截取出来。SEO优化做seo优化有利于搜索引擎对你网站的索引，根据关键字提高你网站的排名，提高曝光率。title 优化使首页改为“网站名称-网站描述”这样的显示方式。打开 seo 项在主题配置文件找到 seo 项1seo: true修改 post 模版在站点目录 scaffolds\post.md 文件，添加 keywords 和 description 字段，用于生成的文章中添加关键字和描述。123456title: &#123;&#123; title &#125;&#125;date: &#123;&#123; date &#125;&#125;tags:keywords:description:---这样在首页文章的预览中就会变成 description，利于 SEO。添加 “nofollow” 标签nofollow是HTML的一个属性，用于告诉搜索引擎不要追踪特定的网页链接。可以用于阻止在PR值高的网站上以留言等方式添加链接从而提高自身网站排名的行为，以改善搜索结果的质量，防止垃圾链接的蔓延。网站站长也可对其网页中的付费链接使用nofollow来防止该链接降低搜索排名。对一些重要度低的网页内容使用nofollow，还可以使搜索引擎以不同的优先级别来抓取网页内容。by 维基百科修改footer.swig文件在 next 目录 layout_partials，找到两处 a标签加上 rel=”external nofollow” 属性。1&#123;&#123; __(&apos;footer.powered&apos;, &apos;&lt;a rel=&quot;external nofollow&quot; class=&quot;theme-link&quot; target=&quot;_blank&quot; href=&quot;https://hexo.io&quot;&gt;Hexo&lt;/a&gt;&apos;) &#125;&#125;1&lt;a rel=&quot;external nofollow&quot; class=&quot;theme-link&quot; target=&quot;_blank&quot; href=&quot;https://github.com/iissnan/hexo-theme-next&quot;&gt;修改sidebar.swig文件在 next 目录 layout_macro，将下面代码中的a标签加上rel=”external nofollow”属性，顺序如下。1&lt;a rel=&quot;external nofollow&quot; href=&quot;&#123;&#123; link.split(&apos;||&apos;)[0] | trim &#125;&#125;&quot; target=&quot;_blank&quot; title=&quot;&#123;&#123; name &#125;&#125;&quot;&gt;1&lt;a href=&quot;https://creativecommons.org/&#123;% if theme.creative_commons === &apos;zero&apos; %&#125;publicdomain/zero/1.0&#123;% else %&#125;licenses/&#123;&#123; theme.creative_commons &#125;&#125;/4.0&#123;% endif %&#125;/&quot; rel=&quot;external nofollow&quot; class=&quot;cc-opacity&quot; target=&quot;_blank&quot;&gt;1&lt;a href=&quot;&#123;&#123; link &#125;&#125;&quot; title=&quot;&#123;&#123; name &#125;&#125;&quot; rel=&quot;external nofollow&quot; target=&quot;_blank&quot;&gt;&#123;&#123; name &#125;&#125;&lt;/a&gt;其实就是把一些含有 target=”_blank” 或 链去其他网站的超链接给加上 nofollow ，提升 SEO 效率。唯一链接 permalink这个我们在上面已经做了。小技巧文章内引用自己的文章这是hexo的标签语法1234&#123;% post_link 文章文件名（不要后缀） 文章标题（可选） %&#125;&#123;% post_link Hello-World %&#125;&#123;% post_link Hello-World 你好世界 %&#125;注意文章名字和文章标题不能有空格，有的话不能生效，还不知怎么解决。直到我增加了站内搜索功能后，好奇搜索结果是怎么链接到文章的呢，于是我看了一下，如下1&lt;a href=&quot;/2018/09/04/Hexo-Github-Pages安装部署/&quot; class=&quot;search-result-title&quot;&gt;&lt;b class=&quot;search-keyword&quot;&gt;Hexo&lt;/b&gt;+Github Pages安装部署&lt;/a&gt;可以看出原来 post 的名字是 “Hexo+Github Pages安装部署”，但是生成静态页面就变成了 “Hexo-Github-Pages安装部署”。然后我拿这个 “Hexo-Github-Pages安装部署”放到上面一试，发现可以了！看来生成后 post 的名字如果单词之间有特殊符号会统一变成“-”？？插入图片在 hexo-admin 直接复制图片会是这样子1![upload successful](/images/hexo优化__0.png)但是这样直接显示在页面不适合，我们一般需要调整大小或位置调整图片的显示hexo 支持的标签语法1&#123;% img [class names] /path/to/image [width] [height] [title text [alt text]] %&#125;不过不能在 hexo-amdin 看到。img 标签1&lt;img src=&quot;/images/hexo-admin安装使用__0.png&quot; width=&quot;600px&quot; height=&quot;200px&quot; align=center&gt;这样可以在直接 hexo-admin 中显示，路径也兼容生成后的 html。]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo-admin安装使用]]></title>
    <url>%2Fposts%2F4ffa5bc6%2F</url>
    <content type="text"><![CDATA[概要如果自己编辑 MD 文件的话，确实比较麻烦，你可以用一些 MD 的编辑器，但是在管理 MD 文件上还是操作不方便。这里推荐使用 hexo-admin，而且编辑完之后可以马上看到效果呢。需要说明的是，hexo-admin 管理是本地用的，就是你需要在本地编辑完之后再上传到 github，而不能直接在线编辑保存，因为 github pages 只支持静态页面的。安装过程安装过程中可能涉及到一些前提或内容，请参考我的另一篇文章Hexo-Github-Pages安装部署前提基于版本”hexo”: “^3.7.0”，”hexo-admin”: “^2.3.0”。安装 hexo-admincd hexo 目录1npm install --save hexo-admin启动 hexo1hexo s然后打开 http://localhost:4000/admin/ 就可以看到管理页面。在 hexo-admin 你可以Pages - 新加 page；Posts - 新加或删除 post；双击一个 post，你可以编辑，预览，新增修改 tags、categories，选择发布或不发布；Settings - 一些配置；Deploy - 可以直接部署到 github。问题minimatch1npm WARN deprecated minimatch@2.0.10: Please update to minimatch 3.0.2 or higher to avoid a RegExp DoS issue当你安装 hexo-admin，执行 npm install –save hexo-admin 时，可能会遇到上面的错误提示，是因为你缺少了一些依赖，执行下面的就好了。12npm install minimatch@&quot;3.0.2&quot; npm update -dConfig value “admin.deployCommand” not found当你第一次点击 Deploy 按钮时，可能会遇到上述的错误，因为缺少了执行 deploy 的命令，这个问题已经有人提了 issue 并且解决了https://github.com/jaredly/hexo-admin/issues/70还需要注意的是，issue 中的脚本只是 hexo deploy，只是做 deploy 操作，但是一般我们的使用习惯是编辑完之后 deploy，所以是要 deploy 最新的，需要把脚本改为即可123#!/usr/bin/env shhexo ghexo ddeploy 后你可能看到1234Std Error(node:83411) [DEP0061] DeprecationWarning: fs.SyncWriteStream is deprecated.Warning: Permanently added the RSA host key for IP address &apos;13.229.188.59&apos; to the list of known hosts.Everything up-to-date这不是错误，你可以不用管。说明已经 deploy 成功。复制图片时的一个小问题hexo-admin 编辑时支持直接复制图片（截图）到内容，这点是我比较喜欢的。但是有个问题，复制进去后是加载不出来的，会出现图裂的小图标。这时你只需要点击别的页面，再点回来就可以看到了，就是“刷”一下就好了，最简单的就是点击右上角打勾的按钮，这个按钮的作用是拼写检查，点一下再点回来，就可以看到你刚复制进去的图片了。这大概是因为 hexo-admin 对图片做了延迟加载，具体可以看看这篇文章说的https://htchz.me/2018/03/10/Hexo/参考资料https://www.jianshu.com/p/68e727dda16dhttps://blog.kinpzz.com/2016/12/31/hexo-admin-backend-management/https://github.com/jaredly/hexo-admin]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo-admin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo+Github Pages安装部署]]></title>
    <url>%2Fposts%2F3454819c%2F</url>
    <content type="text"><![CDATA[概要想低成本的搞一个博客，在网上找了很多参考资料，于是尝试 Hexo+Github Pages 折腾一下。我把自己的搭建过程记录下来，把其中遇到的一些问题也跟大家分享。安装过程前提我用的是 macOS 系统；node、npm、git 等的安装，还有 github 的配置就不多讲了；基于 hexo 的 3.7.0 版本。安装 hexo 客户端1npm install -g hexo-cli创建一个用来放 hexo 的文件夹（假设为 hexo）cd 进去，创建 hexo 站点1hexo init使用 next 主题为了博客的美观和使用上方面，我使用的大众的 next 主题。cd themes 目录。下载 next 主题1git clone https://github.com/iissnan/hexo-theme-next修改 theme编辑 hexo/_config.yml，找到 theme 那一行配置，修改为 next本地启动看看安装完之后，我们可以在本地启动看看博客初始化的效果。生成静态文件1hexo ghexo 最终运行的是静态文件，包括js，css和html等，这些文件统一放在 public 文件夹。安装 hexo-server1npm install hexo-server --save启动 server1hexo s在浏览器打开 localhost:4000，会看到一个 Hello World的页面。恭喜你，部署成功。部署到 github把 hexo 生成的静态文件上传到 github，别人就可以在 github 的网站上看到你的博客了。创建 repo在 github 上创建一个仓库，repo的名字为 username.github.io安装 deploy 插件cd 到 hexo 目录，执行1npm install hexo-deployer-git --save修改 deploy 相关配置编辑 hexo/_config.yml，修改 deploy 下几个属性123type: gitrepo: （git地址）branch: masterpush 到 github1hexo d就会自动把 public 文件夹下所有内容 push 到 master。注意这里看一下 git config user.name\email 是否正确。打开网页打开 username.github.io 就可以看到了添加“分类”，“关于”和“标签”菜单到此已经把博客基本的安装和部署好了。但是我们还需要做一些基本配置，让我们可以维护博客。打开 tags，about，categories在主题配置文件 next/_config.yml 在 menu 下去掉 tags，about，categories 注释。注意这里“主题配置文件”指的是 themes/next 目录的下的 _config.yml。创建 tags，about，categories在 hexo 文件夹1hexo new page tags会在 source 文件夹生成 tags 文件夹，编辑里面的 index.md ，添加12type: "tags"comments: false同样的方法添加 categories；添加 about 不需要修改 md 文件的 type，因为 tags，categories 是特殊目录类型，about 只是简单的一个 md。为文章添加标签和分类在文章 md 文件开头 title 的下面，增加类似，就可以归类到 tag 和 category1234tag:- a_tagcategories:- a_category添加头像图片在 hexo/_config.yml 找到配置 avatar，增加图片路径1avatar: /images/avatar.jpeg新建文章1hexo new post new1就会在 source/_post 文件夹下生成 new1.md 文件，编辑 md 文件即可。这里为什么是 post ？这里涉及 hexo 的模版行为，在 scaffolds 目录下初始定义了3个模板，draft、page、post，文章就是用到了 post。代码管理首先要搞清楚，hexo d 会把 public 文件夹 push 到 username.github.io 这个 repo 的 master 分支。但是这些文件都是一些生成出来的html，css，js 等，对我们没用，所以我们需要把原始文件如 md，images，_config.yml 等文件也需要保存下来，说白了就是把上述的文件也上传到 github，但是我们已经把 public push 到 master了，这时我们可以在 github 上再建一个 repo 来放我们的代码，我的选择是在 username.github.io 上建一个分支放，其实操作是差不多的。其实，我们可以发现在 hexo 文件夹下有一个 .gitignore 文件，这时 hexo 帮我们准备好的，里面的内容：1234567.DS_StoreThumbs.dbdb.json*.lognode_modules/public/.deploy*/可以看出 hexo 已经为我们想好了，public、node_modules、.deploy_git 等非源码文件都忽略了。具体自己看情况，这个 .gitignore 我没动。有个坑下载下来的是一个 git 库，如果你等下把整个 next 文件夹 push 的话，那么在 github 上 next 文件夹是灰色的，你是操作不了，这可能跟 github 权限有关。所以你要先把 next 下的 .git 文件夹删掉。在 hexo 文件夹执行12345678git init git add .git commit -m "hexo-src init"git branch hexo-srcgit checkout hexo-srcgit remote add origin （username.github.io 的 repo git 地址）git push -f origin hexo-src - 强推上去git branch --set-upstream hexo-src origin/hexo-src - 关联上好了，以后改完文章或者修改完主题配置，就可以 push 到 github 了。参考资料https://blog.csdn.net/u012195214/article/details/79204088http://www.wuxubj.cn/2016/08/Hexo-nexT-build-personal-blog/#https://zhiho.github.io/2015/09/29/hexo-next/http://theme-next.iissnan.com/getting-started.htmlhttp://www.lzblog.cn/2016/04/07/Hexo%E7%AB%99%E7%82%B9%E3%80%81NexT%E4%B8%BB%E9%A2%98%E4%BF%AE%E6%94%B9%E5%85%A8%E8%AE%B0%E5%BD%95/https://codezjx.com/2017/07/31/hexo-guide/]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fposts%2F4a17b156%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.Quick StartCreate a new post1$ hexo new "My New Post"More info: WritingRun server1$ hexo serverMore info: ServerGenerate static files1$ hexo generateMore info: GeneratingDeploy to remote sites1$ hexo deployMore info: Deployment]]></content>
      <categories>
        <category>index</category>
      </categories>
      <tags>
        <tag>index</tag>
      </tags>
  </entry>
</search>
